{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import globo\n",
    "\n",
    "import os , numpy as np , time , tensorflow as tf\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import c3d\n",
    "from utils import get_video_clips\n",
    "\n",
    "'''\n",
    "    Iterates over all UCF Crime video folders (train_0 , train_1 , test)\n",
    "    Divide each video into snippets of 16 frames \n",
    "    Process each snippet trough c3dsports1m model\n",
    "    #l2norm the features\n",
    "    Saves a .npy file per video\n",
    "'''\n",
    "\n",
    "feature_extractor = c3d.c3d_feature_extractor()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def predict(x): return feature_extractor(x, training=False)\n",
    "\n",
    "def l2norm(x): return x / np.linalg.norm(x, ord=2, axis=-1, keepdims=True)  \n",
    "\n",
    "\n",
    "for type, dir in globo.UCFCRIME_VPATHS_LISTS.items():\n",
    "\n",
    "    vpaths = list(open(dir))\n",
    "    fpath = globo.UCFCRIME_C3D_FPATHS[type]\n",
    "\n",
    "    print(f'\\n****************\\n\\nProcessing {type} @ {dir}\\n\\n{len(vpaths)} vids\\nsaving into{fpath}')\n",
    "    \n",
    "    for i, vpath in enumerate(vpaths):\n",
    "        t = time.time()\n",
    "        \n",
    "        vpath = vpath.strip(\"\\n\")\n",
    "        fn = os.path.splitext(os.path.basename(vpath))[0]\n",
    "        print(f'\\n{i} {fn}.mp4')\n",
    "            \n",
    "        out_npy = os.path.join(fpath, fn + \".npy\")\n",
    "        #if os.path.exists(out_npy):\n",
    "        #    print(out_npy,\"already created\")\n",
    "        #    continue\n",
    "            \n",
    "        clips, frames = get_video_clips(vpath) ## divide in2 snippets of 16\n",
    "        \n",
    "        features = []\n",
    "        for clip in clips:\n",
    "            prep_clip = c3d.preprocess_input(np.array(clip))\n",
    "            #print(f'\\tPREP {np.shape(prep_clip)}\\n\\t( {np.shape(prep_clip)[0]} frames , {np.shape(prep_clip)[1:]} resolution )',prep_clip.dtype)\n",
    "\n",
    "            feature = predict(prep_clip)\n",
    "            #print(f'\\tFEAT {np.shape(feature)} ,{feature.dtype} , {isinstance(feature, np.ndarray)}')\n",
    "            \n",
    "            features.append(feature)\n",
    "            \n",
    "        features = np.concatenate(features)\n",
    "        print(f'\\tFEATED ( {np.shape(features)[0]} timesteps , {np.shape(features)[1]} features ) {features.dtype} , numpy ? {isinstance(features, np.ndarray)} , tf ? {isinstance(features, tf.Tensor)}')\n",
    "        \n",
    "        #features2 = normalize(features, axis=1)\n",
    "        #features = l2norm(features)\n",
    "        #print(\"\\tL2NORM same ?\",np.allclose(features,features2))\n",
    "        \n",
    "        #np.save(out_npy, features1)\n",
    "        print(f'\\n\\tsaved @ {out_npy}')\n",
    "        \n",
    "        tt = time.time()\n",
    "        print(f'\\tin @ {int(tt-t)} seconds')\n",
    "        \n",
    "        break\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.image_data_format() channels_last\n",
      "input_shape:  (16, 224, 224, 3)\n",
      "model name:  i3d_inception_rgb_imagenet_and_kinetics.h5\n",
      "weights url:  https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/rgb_inception_i3d_imagenet_and_kinetics_tf_dim_ordering_tf_kernels.h5\n",
      "dlwp:  /home/jtstudents/.keras/models/i3d_inception_rgb_imagenet_and_kinetics.h5\n"
     ]
    }
   ],
   "source": [
    "import globo\n",
    "import numpy as np , cv2\n",
    "import tensorflow as tf\n",
    "import i3d_horse\n",
    "from utils import gerador_clips\n",
    "\n",
    "feature_extractor = i3d_horse.Inception_Inflated3d(\n",
    "    include_top=True,\n",
    "    weights='rgb_imagenet_and_kinetics',\n",
    "    input_shape=(16, 224, 224, 3),\n",
    "    feat_extractor=True )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MOVINET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'trace' from 'tensorflow.python.profiler' (/home/jtstudents/anaconda3/envs/zugpuhub/lib/python3.8/site-packages/tensorflow/python/profiler/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhub\u001b[39;00m\n\u001b[1;32m      4\u001b[0m hub_url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://tfhub.dev/tensorflow/movinet/a5/base/kinetics-600/classification/3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m encoder \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39mKerasLayer(hub_url, trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpuhub/lib/python3.8/site-packages/tensorflow_hub/__init__.py:90\u001b[0m\n\u001b[1;32m     85\u001b[0m _ensure_tf_install()\n\u001b[1;32m     88\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m \u001b[39mimport\u001b[39;00m LatestModuleExporter\n\u001b[1;32m     91\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m \u001b[39mimport\u001b[39;00m register_module_for_export\n\u001b[1;32m     92\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m image_embedding_column\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpuhub/lib/python3.8/site-packages/tensorflow_hub/estimator.py:62\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     56\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mThere is already a module registered to be exported as \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m     57\u001b[0m           export_name)\n\u001b[1;32m     58\u001b[0m   tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39madd_to_collection(_EXPORT_MODULES_COLLECTION,\n\u001b[1;32m     59\u001b[0m                                  (export_name, module))\n\u001b[0;32m---> 62\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mLatestModuleExporter\u001b[39;00m(tf_estimator\u001b[39m.\u001b[39;49mExporter):\n\u001b[1;32m     63\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Regularly exports registered modules into timestamped directories.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m  Warning: Deprecated. This belongs to the hub.Module API and TF1 Hub format.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39m  THIS FUNCTION IS DEPRECATED.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m   \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, serving_input_fn, exports_to_keep\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpuhub/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py:62\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, item):\n\u001b[0;32m---> 62\u001b[0m   module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load()\n\u001b[1;32m     63\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(module, item)\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpuhub/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py:45\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n\u001b[1;32m     48\u001b[0m \u001b[39m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpuhub/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpuhub/lib/python3.8/site-packages/tensorflow_estimator/__init__.py:10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function \u001b[39mas\u001b[39;00m _print_function\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m estimator\n\u001b[1;32m     12\u001b[0m \u001b[39mdel\u001b[39;00m _print_function\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m module_wrapper \u001b[39mas\u001b[39;00m _module_wrapper\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpuhub/lib/python3.8/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py:10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function \u001b[39mas\u001b[39;00m _print_function\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m \u001b[39mimport\u001b[39;00m experimental\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m \u001b[39mimport\u001b[39;00m export\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m \u001b[39mimport\u001b[39;00m inputs\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpuhub/lib/python3.8/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py:10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function \u001b[39mas\u001b[39;00m _print_function\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcanned\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdnn\u001b[39;00m \u001b[39mimport\u001b[39;00m dnn_logit_fn_builder\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcanned\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkmeans\u001b[39;00m \u001b[39mimport\u001b[39;00m KMeansClustering \u001b[39mas\u001b[39;00m KMeans\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcanned\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearSDCA\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpuhub/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf_export\u001b[39;00m \u001b[39mimport\u001b[39;00m estimator_export\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m \u001b[39mimport\u001b[39;00m estimator\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcanned\u001b[39;00m \u001b[39mimport\u001b[39;00m head \u001b[39mas\u001b[39;00m head_lib\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_estimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcanned\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizers\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpuhub/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_logging \u001b[39mas\u001b[39;00m logging\n\u001b[0;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprofiler\u001b[39;00m \u001b[39mimport\u001b[39;00m trace\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m utils_impl \u001b[39mas\u001b[39;00m saved_model_utils\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummary\u001b[39;00m \u001b[39mimport\u001b[39;00m summary\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'trace' from 'tensorflow.python.profiler' (/home/jtstudents/anaconda3/envs/zugpuhub/lib/python3.8/site-packages/tensorflow/python/profiler/__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "hub_url = \"https://tfhub.dev/tensorflow/movinet/a5/base/kinetics-600/classification/3\"\n",
    "\n",
    "encoder = hub.KerasLayer(hub_url, trainable=True)\n",
    "\n",
    "inputs = tf.keras.layers.Input(\n",
    "    shape=[None, None, None, 3],\n",
    "    dtype=tf.float32,\n",
    "    name='image')\n",
    "\n",
    "# [batch_size, 600]\n",
    "outputs = encoder(dict(image=inputs))\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs, name='movinet')\n",
    "\n",
    "example_input = tf.ones([1, 8, 320, 320, 3])\n",
    "example_output = model(example_input)\n",
    "\n",
    "print(example_output)\n",
    "\n",
    "\n",
    "#from official.projects.movinet.modeling import movinet\n",
    "#from official.projects.movinet.modeling import movinet_model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VSWIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import globo , os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils import *\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "'''\n",
    "    Iterates over all UCF Crime video folders (train_0 , train_1 , test)\n",
    "    Divide in each video into snippets of 16 frames \n",
    "    Process each snippet trough c3dsports1m model\n",
    "    Saves a .npy file per video\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_input(batch_clips):\n",
    "    mean = np.array([0.485 * 255, 0.456 * 255, 0.406 * 255], dtype=np.float32)\n",
    "    std = np.array([0.229 * 255, 0.224 * 255, 0.225 * 255], dtype=np.float32)\n",
    "    return (batch_clips - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(globo.VSWIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_of_input = [1,3,32,224,224]\n",
    "video = tf.random.normal(shape_of_input)\n",
    "features= model(video)[0].numpy()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type, dir in globo.UCFCRIME_VPATHS_LISTS.items():\n",
    "\n",
    "    vpaths = list(open(dir))\n",
    "    \n",
    "    print(f'\\n****************\\n\\nProcessing {type} @ {dir}\\n\\n{len(vpaths)} vids')\n",
    "    \n",
    "    features_list = []\n",
    "    for i, vpath in enumerate(vpaths):\n",
    "        \n",
    "        vpath = vpath.strip('\\n')\n",
    "        fn = os.path.splitext(os.path.basename(vpath))[0]\n",
    "        print(f'\\n{i} {fn}.mp4\\n')\n",
    "\n",
    "        ## divide in2 snippets of 32\n",
    "        clips, frames = get_video_clips(vpath , clip_length = 32 , resolution = 224)\n",
    "        print(np.shape(clips) , clips.dtype)\n",
    "        \n",
    "        \n",
    "        features = []\n",
    "        for clip in clips:  \n",
    "            clip_prep = normalize_input(clip)\n",
    "            clip_prep_tf = tf.image.per_image_standardization(clip)\n",
    "            print(np.shape(clip_prep),np.shape(clip_prep_tf))\n",
    "            print(np.allclose(clip_prep , clip_prep_tf))\n",
    "            \n",
    "            clip_prep_tf = np.expand_dims(clip_prep_tf, axis=0)\n",
    "            clip_prep_tf = np.transpose(clip_prep_tf, (0, 4, 1, 2, 3))\n",
    "            print(np.shape(clip_prep_tf))\n",
    "            \n",
    "            feature = model(clip_prep_tf)[0].numpy()\n",
    "            print(np.shape(feature))\n",
    "            features.append(feature)\n",
    "            \n",
    "        print(np.shape(features))\n",
    "        \n",
    "        #features = normalize(features, axis=1)\n",
    "        break\n",
    "\n",
    "    # Save all the features for the current type as a single .npz file\n",
    "    out_npz = os.path.join(globo.UCFCRIME_FEATC3D_BASE_DIR, type + \".npz\")\n",
    "    #np.savez(out_npz, *features_list)\n",
    "    print(f'\\n\\tsaved {type} features @ {out_npz}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zugpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
