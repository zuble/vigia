{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import globo\n",
    "\n",
    "import os , numpy as np , time , tensorflow as tf\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import c3d\n",
    "from utils import get_video_clips\n",
    "\n",
    "'''\n",
    "    Iterates over all UCF Crime video folders (train_0 , train_1 , test)\n",
    "    Divide each video into snippets of 16 frames \n",
    "    Process each snippet trough c3dsports1m model\n",
    "    #l2norm the features\n",
    "    Saves a .npy file per video\n",
    "'''\n",
    "\n",
    "feature_extractor = c3d.c3d_feature_extractor()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def predict(x): return feature_extractor(x, training=False)\n",
    "\n",
    "def l2norm(x): return x / np.linalg.norm(x, ord=2, axis=-1, keepdims=True)  \n",
    "\n",
    "\n",
    "for type, dir in globo.UCFCRIME_VPATHS_LISTS.items():\n",
    "\n",
    "    vpaths = list(open(dir))\n",
    "    fpath = globo.UCFCRIME_C3D_FPATHS[type]\n",
    "\n",
    "    print(f'\\n****************\\n\\nProcessing {type} @ {dir}\\n\\n{len(vpaths)} vids\\nsaving into{fpath}')\n",
    "    \n",
    "    for i, vpath in enumerate(vpaths):\n",
    "        t = time.time()\n",
    "        \n",
    "        vpath = vpath.strip(\"\\n\")\n",
    "        fn = os.path.splitext(os.path.basename(vpath))[0]\n",
    "        print(f'\\n{i} {fn}.mp4')\n",
    "            \n",
    "        out_npy = os.path.join(fpath, fn + \".npy\")\n",
    "        #if os.path.exists(out_npy):\n",
    "        #    print(out_npy,\"already created\")\n",
    "        #    continue\n",
    "            \n",
    "        clips, frames = get_video_clips(vpath) ## divide in2 snippets of 16\n",
    "        \n",
    "        features = []\n",
    "        for clip in clips:\n",
    "            prep_clip = c3d.preprocess_input(np.array(clip))\n",
    "            #print(f'\\tPREP {np.shape(prep_clip)}\\n\\t( {np.shape(prep_clip)[0]} frames , {np.shape(prep_clip)[1:]} resolution )',prep_clip.dtype)\n",
    "\n",
    "            feature = predict(prep_clip)\n",
    "            #print(f'\\tFEAT {np.shape(feature)} ,{feature.dtype} , {isinstance(feature, np.ndarray)}')\n",
    "            \n",
    "            features.append(feature)\n",
    "            \n",
    "        features = np.concatenate(features)\n",
    "        print(f'\\tFEATED ( {np.shape(features)[0]} timesteps , {np.shape(features)[1]} features ) {features.dtype} , numpy ? {isinstance(features, np.ndarray)} , tf ? {isinstance(features, tf.Tensor)}')\n",
    "        \n",
    "        #features2 = normalize(features, axis=1)\n",
    "        #features = l2norm(features)\n",
    "        #print(\"\\tL2NORM same ?\",np.allclose(features,features2))\n",
    "        \n",
    "        #np.save(out_npy, features1)\n",
    "        print(f'\\n\\tsaved @ {out_npy}')\n",
    "        \n",
    "        tt = time.time()\n",
    "        print(f'\\tin @ {int(tt-t)} seconds')\n",
    "        \n",
    "        break\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import globo\n",
    "import numpy as np , cv2\n",
    "import tensorflow as tf\n",
    "import i3d_horse\n",
    "from utils import gerador_clips"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VSWIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import globo , os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils import *\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "'''\n",
    "    Iterates over all UCF Crime video folders (train_0 , train_1 , test)\n",
    "    Divide in each video into snippets of 16 frames \n",
    "    Process each snippet trough c3dsports1m model\n",
    "    Saves a .npy file per video\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_input(batch_clips):\n",
    "    mean = np.array([0.485 * 255, 0.456 * 255, 0.406 * 255], dtype=np.float32)\n",
    "    std = np.array([0.229 * 255, 0.224 * 255, 0.225 * 255], dtype=np.float32)\n",
    "    return (batch_clips - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(globo.VSWIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_of_input = [1,3,32,224,224]\n",
    "video = tf.random.normal(shape_of_input)\n",
    "features= model(video)[0].numpy()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type, dir in globo.UCFCRIME_VPATHS_LISTS.items():\n",
    "\n",
    "    vpaths = list(open(dir))\n",
    "    \n",
    "    print(f'\\n****************\\n\\nProcessing {type} @ {dir}\\n\\n{len(vpaths)} vids')\n",
    "    \n",
    "    features_list = []\n",
    "    for i, vpath in enumerate(vpaths):\n",
    "        \n",
    "        vpath = vpath.strip('\\n')\n",
    "        fn = os.path.splitext(os.path.basename(vpath))[0]\n",
    "        print(f'\\n{i} {fn}.mp4\\n')\n",
    "\n",
    "        ## divide in2 snippets of 32\n",
    "        clips, frames = get_video_clips(vpath , clip_length = 32 , resolution = 224)\n",
    "        print(np.shape(clips) , clips.dtype)\n",
    "        \n",
    "        \n",
    "        features = []\n",
    "        for clip in clips:  \n",
    "            clip_prep = normalize_input(clip)\n",
    "            clip_prep_tf = tf.image.per_image_standardization(clip)\n",
    "            print(np.shape(clip_prep),np.shape(clip_prep_tf))\n",
    "            print(np.allclose(clip_prep , clip_prep_tf))\n",
    "            \n",
    "            clip_prep_tf = np.expand_dims(clip_prep_tf, axis=0)\n",
    "            clip_prep_tf = np.transpose(clip_prep_tf, (0, 4, 1, 2, 3))\n",
    "            print(np.shape(clip_prep_tf))\n",
    "            \n",
    "            feature = model(clip_prep_tf)[0].numpy()\n",
    "            print(np.shape(feature))\n",
    "            features.append(feature)\n",
    "            \n",
    "        print(np.shape(features))\n",
    "        \n",
    "        #features = normalize(features, axis=1)\n",
    "        break\n",
    "\n",
    "    # Save all the features for the current type as a single .npz file\n",
    "    out_npz = os.path.join(globo.UCFCRIME_FEATC3D_BASE_DIR, type + \".npz\")\n",
    "    #np.savez(out_npz, *features_list)\n",
    "    print(f'\\n\\tsaved {type} features @ {out_npz}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zugpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
