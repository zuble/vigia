{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v=ODGDLQ0TT3M__#1_label_A.mp4', '0.7143266', '(1,2138,0.7143266)']\n",
      "(1,2138,0.7143266) \t ['1', '2138', '0.7143266']\n"
     ]
    }
   ],
   "source": [
    "test = [[()]]\n",
    "testtest = ['']\n",
    "line  = \"v=ODGDLQ0TT3M__#1_label_A.mp4|0.7143266|(1, 2138, 0.7143266)\"\n",
    "aux_line = str(line).replace('[','').replace(']','').replace(' ','').split('|')\n",
    "print(aux_line)\n",
    "\n",
    "aux2_line = aux_line[2].replace(\"'\",'').replace('(','').replace(')','').split(',')\n",
    "print(aux_line[2],'\\t',aux2_line)\n",
    "test.append(aux2_line)\n",
    "\n",
    "#aaa = [i for i in range(100)]\n",
    "#for k in range(len(aux2_line)):\n",
    "#    testtest.append(aux2_line[k])\n",
    "#test.append(testtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5, 8]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = [i for i in range(10)]\n",
    "aaa[2::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5,5,100)\n",
    "\n",
    "y = 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
    "\n",
    "# setting the axes at the centre\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.spines['left'].set_position('center')\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.set_ylim([-0.5, 1])\n",
    "# plot the function\n",
    "plt.plot(x,y, 'r')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watch_batch(fn,batch,fps):\n",
    "    print(\"watch_batch\")\n",
    "    #sec = np.shape(batch)/fps\n",
    "\n",
    "    # Syntax: VideoWriter_fourcc(c1, c2, c3, c4) # Concatenates 4 chars to a fourcc code\n",
    "    #  cv2.VideoWriter_fourcc('M','J','P','G') or cv2.VideoWriter_fourcc(*'MJPG)\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # FourCC is a 4-byte code used to specify the video codec.\n",
    "    # A video codec is software or hardware that compresses and decompresses digital video. \n",
    "    # In the context of video compression, codec is a portmanteau of encoder and decoder, \n",
    "    # while a device that only compresses is typically called an encoder, and one that only \n",
    "    # decompresses is a decoder. Source - Wikipedia\n",
    "    \n",
    "    #Syntax: cv2.VideoWriter( filename, fourcc, fps, frameSize )\n",
    "    fn = fn.replace('.mp4','')\n",
    "    print(rslt_path+'/1V/best_batch/'+fn+'BB.mp4')\n",
    "    video = cv2.VideoWriter(rslt_path+'/1V/best_batch/'+fn+'BB.mp4', fourcc, float(fps), (target_width, target_height))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for frame in range(batch.shape[0]):\n",
    "        batch[frame].convertTo(image, np.uint8);\n",
    "        #batch[frame] = batch[frame].astype(np.uint8)\n",
    "        video.write(image)\n",
    "    \n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_type = 1\n",
    "batch_no=0\n",
    "target_height = 120\n",
    "target_width = 160\n",
    "frame_max = 4000\n",
    "\n",
    "base_vigia_dir = \"/media/jtstudents/HDD/.zuble/vigia\"\n",
    "rslt_path = base_vigia_dir+'/zhen++/parameters_results'\n",
    "\n",
    "file_name = '/media/jtstudents/HDD/.zuble/xdviol/test/v=-fOWSLV6Esw__#1_label_B4-0-0.mp4'\n",
    "#file_name = '/raid/DATASETS/anomaly/UCF_Crimes/Videos/Training_Normal_Videos_Anomaly/Normal_Videos308_x264.mp4'\n",
    "video = cv2.VideoCapture(file_name)\n",
    "total_frame = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "#mtcnn_detector = mtcnn.mtcnn.MTCNN()\n",
    "divid_no = 1\n",
    "\n",
    "if total_frame > frame_max:\n",
    "    total_frame_int = int(total_frame)\n",
    "    if total_frame_int % frame_max == 0:\n",
    "        divid_no = int(total_frame / frame_max)\n",
    "    else:\n",
    "        divid_no = int(total_frame / frame_max) + 1\n",
    "\n",
    "passby = 0\n",
    "#updates the start frame to 0,4000,8000... excluding the last batch\n",
    "if batch_no != divid_no - 1:\n",
    "    while video.isOpened and passby < frame_max * batch_no:\n",
    "        passby += 1\n",
    "        success, image = video.read()\n",
    "        if success == False:\n",
    "            break\n",
    "#updates the last batch starting frame \n",
    "else:\n",
    "    if batch_type==1:\n",
    "        #print(\"1\")\n",
    "        while video.isOpened and passby < total_frame - frame_max:\n",
    "            passby += 1\n",
    "            success, image = video.read()\n",
    "            if success == False:\n",
    "                break\n",
    "    #last batch must have >= 400 otherwise it falls back to batch_type 1\n",
    "    if batch_type==2 and total_frame - (frame_max * batch_no) >= frame_max*0.1:\n",
    "        #print(\"2\")\n",
    "        while video.isOpened and passby < frame_max * batch_no:\n",
    "            passby += 1\n",
    "            success, image = video.read()\n",
    "            if success == False:\n",
    "                break\n",
    "    else:\n",
    "        while video.isOpened and passby < total_frame - frame_max:\n",
    "            passby += 1\n",
    "            success, image = video.read()\n",
    "            if success == False:\n",
    "                break\n",
    "\n",
    "        \n",
    "batch_frames = [] \n",
    "batch_imgs = [] \n",
    "counter = 0\n",
    "\n",
    "while video.isOpened:\n",
    "    \n",
    "    success, image = video.read()\n",
    "    if success == False:\n",
    "        break\n",
    "    \n",
    "    #print(np.shape(image)) \n",
    "    \n",
    "    image = cv2.resize(image, (target_width, target_height))\n",
    "    image_array = np.array(image)/255.0 #normalize\n",
    "    batch_frames.append(image_array)\n",
    "    batch_imgs.append(image)\n",
    "    cv2.imshow('frame', image)\n",
    "    \n",
    "    counter += 1\n",
    "    if counter > frame_max:\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "batch_frames = np.array(batch_frames)\n",
    "\n",
    "print(batch_frames[3].shape)\n",
    "\n",
    "print(\"\\t-batch\",batch_no,\"[\",passby,\", ... ] \",batch_frames.shape)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_batch(\"v=-fOWSLV6Esw__#1_label_B4-0-0\",batch_frames,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def quit_key_action(**params):\n",
    "    global is_quit\n",
    "    is_quit = True\n",
    "def rewind_key_action(**params):\n",
    "    global frame_counter\n",
    "    frame_counter = max(0, int(frame_counter - (fps * 5)))\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, frame_counter)\n",
    "def forward_key_action(**params):\n",
    "    global frame_counter\n",
    "    frame_counter = min(int(frame_counter + (fps * 5)), total_frame - 1)\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, frame_counter)\n",
    "def pause_key_action(**params):\n",
    "    global is_paused\n",
    "    is_paused = not is_paused\n",
    "# Map keys to buttons\n",
    "key_action_dict = {\n",
    "    ord('q'): quit_key_action,\n",
    "    ord('a'): rewind_key_action,\n",
    "    ord('d'): forward_key_action,\n",
    "    ord('s'): pause_key_action,\n",
    "    ord(' '): pause_key_action\n",
    "}\n",
    "def key_action(_key):\n",
    "    if _key in key_action_dict:\n",
    "        key_action_dict[_key]()\n",
    "\n",
    "\n",
    "base_vigia_dir = \"/media/jtstudents/HDD/.zuble/vigia\"\n",
    "rslt_path = base_vigia_dir+'/zhen++/parameters_results'\n",
    "        \n",
    "batch_type = 1\n",
    "batch_no=0\n",
    "target_height = 120\n",
    "target_width = 160\n",
    "frame_max = 4000\n",
    "\n",
    "#input\n",
    "file_name = '/media/jtstudents/HDD/.zuble/xdviol/test/v=-fOWSLV6Esw__#1_label_B4-0-0.mp4'\n",
    "video = cv2.VideoCapture(file_name)\n",
    "total_frame = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "#output\n",
    "final_path = rslt_path+'/1V/best_batch/test_BB.mp4'\n",
    "out = cv2.VideoWriter(final_path, cv2.VideoWriter_fourcc(*'mp4v'), int(fps), (target_width,target_height), False)\n",
    "\n",
    "counter = 0\n",
    "batch_frames = [] \n",
    "while video.isOpened:\n",
    "    \n",
    "    success, image = video.read()\n",
    "    if success == False:\n",
    "        break\n",
    "    \n",
    "    print(\"image_shape\",np.shape(image)) \n",
    "    \n",
    "    image = cv2.resize(image, (target_width, target_height))\n",
    "    image_array = np.array(image)/255.0 #normalize\n",
    "    batch_frames.append(image_array)\n",
    "\n",
    "    #cv2.putText(image, strftime(\"%H:%M:%S\"), (10,70), cv2.FONT_HERSHEY_SIMPLEX, 2,(0,255,0),2,cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('frame', image)\n",
    "    # Wait for any key press and pass it to the key action\n",
    "    key = cv2.waitKey(1)\n",
    "    key_action(key)\n",
    "    \n",
    "    counter += 1\n",
    "    if counter > frame_max:\n",
    "        break\n",
    "    \n",
    "print(\"image_shape\",np.shape(batch_frames)) \n",
    "for i in range(len(batch_frames)):\n",
    "    print(\"frame\",i)\n",
    "    data = batch_frames[i].astype('uint8') * 255\n",
    "    data = cv2.cvtColor(data, cv2.COLOR_RGB2BGR)\n",
    "    out.write(data)\n",
    "    \n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 4000, 0.8)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-216ecf36c557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m4000\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0maux2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;36m4000\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m7000\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mauxaux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maux2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "aux3= []\n",
    "auxaux = ()\n",
    "aux = ( 0 , 4000 , 0.8)\n",
    "print(aux)\n",
    "print(aux.strip(' '))\n",
    "aux2 = ( 4000 , 7000 , 0.7)\n",
    "auxaux = aux + aux2 \n",
    "aux3.append(aux)\n",
    "aux3.append(auxaux)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12000):\n",
    "    print(i % 4000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zhen_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6eb85c0477d574fd6bdabb52dbe9212bb7f487155853edb797b76ac4297f2c9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
