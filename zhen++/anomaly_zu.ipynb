{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.predict()** : generates output predictions based on the input you pass it (for example, the predicted characters in the MNIST example)\n",
    "\n",
    "**.evaluate()** : computes the loss based on the input you pass it, along with any other metrics that you requested in the metrics param when you compiled your model (such as accuracy in the MNIST example)\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', \n",
    "        optimizer=RMSprop(), \n",
    "        metrics=['accuracy']) \n",
    "        history = model.fit(x_train, y_train, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs, \n",
    "        verbose=1, \n",
    "        validation_data=(x_test, y_test)) \n",
    "        \n",
    "        predictions = model.predict(x_test) \n",
    "        print('First prediction:', predictions[0]) \n",
    "        \n",
    "        score = model.evaluate(x_test, y_test, verbose=0) \n",
    "        print('Test loss:', score[0]) \n",
    "        print('Test accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#import mtcnn\n",
    "import keras\n",
    "from keras import models, layers\n",
    "import tensorflow as tf\n",
    "import os, time, random, logging\n",
    "from tqdm.keras import TqdmCallback\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vigia_dir = \"/media/jtstudents/HDD/.zuble/vigia\"\n",
    "\n",
    "\n",
    "def set_tf_loglevel(level):\n",
    "    if level >= logging.FATAL:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "    if level >= logging.ERROR:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    if level >= logging.WARNING:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "    else:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "    logging.getLogger('tensorflow').setLevel(level)\n",
    "\n",
    "\n",
    "def input_video_data(file_name):\n",
    "    print(\"\\n\\nINPUT_VIDEO_DATA\\n\")\n",
    "    #file_name = 'C:\\\\Bosch\\\\Anomaly\\\\training\\\\videos\\\\13_007.avi'\n",
    "    #file_name = '/raid/DATASETS/anomaly/UCF_Crimes/Videos/Training_Normal_Videos_Anomaly/Normal_Videos308_x264.mp4'\n",
    "    video = cv2.VideoCapture(file_name)\n",
    "    total_frame = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    #mtcnn_detector = mtcnn.mtcnn.MTCNN()\n",
    "    #print(file_name + '  ' + str(total_frame))\n",
    "    divid_no = 1\n",
    "    \n",
    "    if total_frame > frame_max:\n",
    "        total_frame_int = int(total_frame)\n",
    "        if total_frame_int % frame_max == 0:\n",
    "            divid_no = int(total_frame / frame_max)\n",
    "        else:\n",
    "            divid_no = int(total_frame / frame_max) + 1\n",
    "        \n",
    "    batch_no = 0\n",
    "    batch_frames = []\n",
    "    batch_frames_flip = []\n",
    "    counter = 0\n",
    "    if 'Normal' in file_name:\n",
    "        print(\"\\n\\nNORMAL\\n\\n\")\n",
    "        if divid_no != 1:\n",
    "            slice_no = int(random.random()*divid_no)\n",
    "            passby = 0\n",
    "            if slice_no != divid_no - 1:\n",
    "                while video.isOpened and passby < frame_max * slice_no:\n",
    "                    passby += 1\n",
    "                    success, image = video.read()\n",
    "                    if success == False:\n",
    "                        break\n",
    "            else:\n",
    "                while video.isOpened and passby < total_frame - frame_max:\n",
    "                    passby += 1\n",
    "                    success, image = video.read()\n",
    "                    if success == False:\n",
    "                        break\n",
    "\n",
    "    while video.isOpened:               \n",
    "        success, image = video.read()\n",
    "        if success == False:\n",
    "            break\n",
    "            \n",
    "        #ratio = image.shape[0] / image.shape[1]\n",
    "        #print(str(image.shape[0])+ ' ' + str(image.shape[1]))\n",
    "        #image = cv2.resize(image, (800, int(800*ratio)))\n",
    "        #print(image.shape)\n",
    "        #faces = face_detector.detectMultiScale(image,1.1,8)\n",
    "        '''\n",
    "        faces = mtcnn_detector.detect_faces(image)\n",
    "        \n",
    "        for face in faces:\n",
    "            (x,y,w,h) = face['box']\n",
    "            #print(face)\n",
    "            cv2.rectangle(image,(x,y), (x+w,y+h), (255,255,0), 2)\n",
    "            cv2.putText(image, str(face['confidence'])[:4], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (36,255,12), 1)\n",
    "        '''\n",
    "        image = cv2.resize(image, (target_width, target_height))\n",
    "        image_flip = cv2.flip(image, 1)\n",
    "        \n",
    "        image_array = np.array(image)/255.0\n",
    "        image_array_flip = np.array(image_flip)/255.0\n",
    "        \n",
    "        batch_frames.append(image_array)\n",
    "        batch_frames_flip.append(image_array_flip)\n",
    "        \n",
    "        counter += 1\n",
    "        if counter > frame_max:\n",
    "            break\n",
    "            \n",
    "    video.release()\n",
    "    batch_frames = np.array(batch_frames)\n",
    "    #print(batch_frames.shape)\n",
    "        \n",
    "    return np.expand_dims(batch_frames,0), np.expand_dims(batch_frames_flip, 0), total_frame\n",
    "    \n",
    "    '''\n",
    "    cv2.imshow('show', image)\n",
    "    keyInput = cv2.waitKey(1)\n",
    "    if keyInput == 27:\n",
    "        break\n",
    "    '''\n",
    "\n",
    "#cv2.destroyWindow('show')\n",
    "#from keras.utils import to_categorical\n",
    "def generate_input():\n",
    "    #has_visited = [0 for i in range(len(train_fn))]\n",
    "    \n",
    "    print(\"\\n\\nGENERATE_INPUT\\n\")\n",
    "    loop_no = 0\n",
    "    while 1:\n",
    "        index = update_index[loop_no]\n",
    "        loop_no += 1\n",
    "        if loop_no == len(train_fn):\n",
    "            loop_no = 0\n",
    "            \n",
    "        #index = 0\n",
    "        batch_frames, batch_frames_flip, total_frames = input_video_data(train_fn[index])\n",
    "        print(\"\\ntrain_fn[\",index,\"]=\",train_fn[index],\"\\ntotal_frames=\",total_frames,\"\\nbatch_frames.shape=\",batch_frames.shape)\n",
    "        #if batch_frames.ndim != 5:\n",
    "        #   break\n",
    "        \n",
    "        # GENERATORS    \n",
    "        #       a kind of iterators that can only iterate over once\n",
    "        #       NO store of values in memory\n",
    "        # YIELD \n",
    "        #       like a return, except the function will return a generator\n",
    "        \n",
    "        '''\n",
    "        if 'Abuse' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([1,0,0,0,0,0,0,0,0,0,0,0,0,0])])\n",
    "        elif 'Arrest' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,1,0,0,0,0,0,0,0,0,0,0,0,0])])\n",
    "        elif 'Arson' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,1,0,0,0,0,0,0,0,0,0,0,0])])\n",
    "        elif 'Assault' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,1,0,0,0,0,0,0,0,0,0,0])]) \n",
    "        elif 'Burglary' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,1,0,0,0,0,0,0,0,0,0])]) \n",
    "        elif 'Explosion' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,1,0,0,0,0,0,0,0,0])])        \n",
    "        elif 'Fighting' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,1,0,0,0,0,0,0,0])]) \n",
    "        elif 'RoadAccidents' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,0,1,0,0,0,0,0,0])]) \n",
    "        elif 'Robbery' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,0,0,1,0,0,0,0,0])]) \n",
    "        elif 'Shooting' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,0,0,0,1,0,0,0,0])]) \n",
    "        elif 'Shoplifting' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,0,0,0,0,1,0,0,0])]) \n",
    "        elif 'Stealing' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,0,0,0,0,0,1,0,0])])\n",
    "        elif 'Normal' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,0,0,0,0,0,0,1,0])]) \n",
    "        elif 'Vandalism' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,1])]) \n",
    "        '''\n",
    "        \n",
    "        #batch_frames\n",
    "        if 'label_A' in train_fn[index]:\n",
    "            yield batch_frames, np.array([0])   #normal\n",
    "        else:\n",
    "            yield batch_frames, np.array([1])   #abnormal\n",
    "\n",
    "        #batch_frames_flip\n",
    "        if 'label_A' in train_fn[index]:\n",
    "            yield batch_frames_flip, np.array([0])  #normal\n",
    "        else:\n",
    "            yield batch_frames_flip, np.array([1])  #abnormal\n",
    "    \n",
    "    print(\"loop_no=\",loop_no)\n",
    "\n",
    "def input_test_video_data(file_name, batch_no=0):\n",
    "    #file_name = 'C:\\\\Bosch\\\\Anomaly\\\\training\\\\videos\\\\13_007.avi'\n",
    "    #file_name = '/raid/DATASETS/anomaly/UCF_Crimes/Videos/Training_Normal_Videos_Anomaly/Normal_Videos308_x264.mp4'\n",
    "    video = cv2.VideoCapture(file_name)\n",
    "    total_frame = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    #mtcnn_detector = mtcnn.mtcnn.MTCNN()\n",
    "    divid_no = 1\n",
    "\n",
    "    if total_frame > frame_max:\n",
    "        total_frame_int = int(total_frame)\n",
    "        if total_frame_int % frame_max == 0:\n",
    "            divid_no = int(total_frame / frame_max)\n",
    "        else:\n",
    "            divid_no = int(total_frame / frame_max) + 1\n",
    "\n",
    "    passby = 0\n",
    "    #updates the start frame to 0,4000,8000... excluding the last batch\n",
    "    if batch_no != divid_no - 1:\n",
    "        while video.isOpened and passby < frame_max * batch_no:\n",
    "            passby += 1\n",
    "            success, image = video.read()\n",
    "            if success == False:\n",
    "                break\n",
    "    #updates the last batch starting frame \n",
    "    else:\n",
    "        if batch_type==2:\n",
    "            #print(\"2\")\n",
    "            while video.isOpened and passby < frame_max * batch_no:\n",
    "                passby += 1\n",
    "                success, image = video.read()\n",
    "                if success == False:\n",
    "                    break\n",
    "        if batch_type==1:\n",
    "            #print(\"1\")\n",
    "            while video.isOpened and passby < total_frame - frame_max:\n",
    "                passby += 1\n",
    "                success, image = video.read()\n",
    "                if success == False:\n",
    "                    break\n",
    "            \n",
    "    batch_frames = []\n",
    "    counter = 0\n",
    "    \n",
    "    while video.isOpened:               \n",
    "        success, image = video.read()\n",
    "        if success == False:\n",
    "            break\n",
    "        \n",
    "        image = cv2.resize(image, (target_width, target_height))\n",
    "        image_array = np.array(image)/255.0 #normalize\n",
    "        batch_frames.append(image_array)\n",
    "        cv2.imshow('frame', image)\n",
    "        \n",
    "        counter += 1\n",
    "        if counter > frame_max:\n",
    "            break\n",
    "            \n",
    "    video.release()\n",
    "    batch_frames = np.array(batch_frames)\n",
    "    \n",
    "    print(\"\\t-batch\",batch_no,\"[\",passby,\", ... ] \",batch_frames.shape)    \n",
    "    \n",
    "    return np.expand_dims(batch_frames,0), divid_no, total_frame, fps\n",
    "\n",
    "\n",
    "def test_files():\n",
    "    \"\"\"\n",
    "    GENERATE LIST of TEST FILES\n",
    "    \"\"\"\n",
    "    test_fn, test_normal_fn, test_abnormal_fn = [],[],[]\n",
    "    y_test_labels, y_test_norm, y_test_abnor = [],[],[]\n",
    "    #server_testname_folder = '/raid/DATASETS/anomaly/XD_Violence/testing'\n",
    "    server_testname_folder = '/media/jtstudents/HDD/.zuble/xdviol/test'\n",
    "    for root, dirs, files in os.walk(server_testname_folder):\n",
    "        for file in files:\n",
    "            if file.find('.mp4') != -1:\n",
    "                if 'label_A' in file:\n",
    "                    test_normal_fn.append(os.path.join(root, file))\n",
    "                    y_test_norm.append(0)\n",
    "                else:\n",
    "                    test_abnormal_fn.append(os.path.join(root, file))\n",
    "                    y_test_abnor.append(1)\n",
    "                    \n",
    "    test_fn = test_normal_fn + test_abnormal_fn\n",
    "    y_test_labels = y_test_norm + y_test_abnor\n",
    "    \n",
    "    print(\"\\ntest_fn\",np.shape(test_fn),\"\\ntest_normal_fn\",np.shape(test_normal_fn),\"\\ntest_abnormal_fn\",np.shape(test_abnormal_fn))\n",
    "    print(\"\\ny_test_labels\",np.shape(y_test_labels),\"\\ny_test_norm\",np.shape(y_test_norm),\"\\ny_test_abnor\",np.shape(y_test_abnor))\n",
    "    \n",
    "    return test_fn, y_test_labels\n",
    "\n",
    "def train_files():\n",
    "    \"\"\"\n",
    "    GENERATING LIST of TRAIN FILES\n",
    "    \"\"\"\n",
    "    train_fn = []\n",
    "    #server_video_loc = '/home/zhen/Documents/Remote/raid/DATASETS/anomaly/UCF_Crimes/Videos'\n",
    "    #server_video_loc = '/raid/DATASETS/anomaly/XD_Violence/training/'\n",
    "    server_video_loc = '/media/jtstudents/HDD/.zuble/xdviol/train'\n",
    "    for root, dirs, files in os.walk(server_video_loc):\n",
    "        for file in files:\n",
    "            if file.find('.mp4') != -1:\n",
    "                train_fn.append(os.path.join(root, file))\n",
    "                \n",
    "    print(\"\\ntrain_fn=\",np.shape(train_fn))\n",
    "    \n",
    "    return train_fn\n",
    "\n",
    "\n",
    "def all_operations(args):\n",
    "    x = args[0]\n",
    "    #tf.print(x.shape)\n",
    "    x = tf.reshape(x, [1, -1,x.shape[1]*x.shape[2]*x.shape[3]])\n",
    "    return x\n",
    "@tf.function\n",
    "def loss_category(y_true, y_pred):    \n",
    "    #tf.print(y_pred, y_true, 'Prediction')\n",
    "    cce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    return cce\n",
    "\n",
    "\n",
    "def find_weights(): \n",
    "    weights_fn = []\n",
    "    weights_path = []\n",
    "    weights_base_path = base_vigia_dir+\"/zhen++/parameters_saved\"\n",
    "\n",
    "    for file in os.listdir(weights_base_path):\n",
    "        fname, fext = os.path.splitext(file)\n",
    "        if fext == \".h5\" and file.find('_2_4_8_xdviolence_model_weights') != -1 :\n",
    "            print(file)\n",
    "            weights_path.append(os.path.join(weights_base_path, file))\n",
    "            weights_fn.append(file)\n",
    "\n",
    "    return weights_fn, weights_path\n",
    "\n",
    "def form_model():\n",
    "    print(\"\\nFORM_MODEL\\n\")\n",
    "    image_input = keras.Input(shape=(None, target_height, target_width, 3))\n",
    "    #Freeze the batch normalization\n",
    "    \n",
    "    c3d_layer1 = keras.layers.Conv3D(4,(2,3,3), activation='relu')(image_input)\n",
    "    c3d_pooling1 = keras.layers.MaxPooling3D((1,2,2))(c3d_layer1)\n",
    "    c3d_layer2 = keras.layers.Conv3D(8,(4,3,3), activation='relu')(c3d_pooling1)\n",
    "    c3d_pooling2 = keras.layers.MaxPooling3D((2,2,2))(c3d_layer2)\n",
    "    c3d_layer3 = keras.layers.Conv3D(16,(8,3,3), activation='relu')(c3d_pooling2)\n",
    "    c3d_pooling3 = keras.layers.MaxPooling3D((4,2,2))(c3d_layer3)\n",
    "    #c3d_layer4 = keras.layers.Conv3D(32,(2,3,3), activation='relu')(c3d_pooling3)\n",
    "    #c3d_pooling4 = keras.layers.MaxPooling3D((2,2,2))(c3d_layer4)\n",
    "    \n",
    "    feature_conv_4 = keras.layers.Lambda(all_operations)(c3d_pooling3)\n",
    "    \n",
    "    lstm1 = keras.layers.LSTM(1024,input_shape=(1200,feature_conv_4.shape[2]), return_sequences=True)(feature_conv_4)\n",
    "    lstm2 = keras.layers.LSTM(512, return_sequences=True)(lstm1)\n",
    "    global_feature = keras.layers.GlobalMaxPooling1D()(lstm1)\n",
    "    \n",
    "    #ADD THE AUDIO FEATURE HERE \n",
    "    \n",
    "    dense_1 = keras.layers.Dense(128, activation='relu')(global_feature)\n",
    "    #dense_2 = keras.layers.Dense(13, activation='sigmoid')(dense_1)\n",
    "    \n",
    "    soft_max = keras.layers.Dense(1, activation='sigmoid')(dense_1)\n",
    "    \n",
    "    \n",
    "    model = models.Model(inputs=[image_input], outputs=[soft_max])\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    #class_weights = [10,10,10,10,10,10,10,10,10,10,10,10,0.1,10]\n",
    "    optimizer_adam = keras.optimizers.SGD(learning_rate = 0.0002)\n",
    "    METRICS = [\n",
    "        keras.metrics.TruePositives(name='tp'),\n",
    "        keras.metrics.FalsePositives(name='fp'),\n",
    "        keras.metrics.TrueNegatives(name='tn'),\n",
    "        keras.metrics.FalseNegatives(name='fn'), \n",
    "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "    ]\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=optimizer_adam, \n",
    "                    loss= 'binary_crossentropy', \n",
    "                    #loss_weights = class_weights,\n",
    "                    #metrics=['accuracy']\n",
    "                    metrics=METRICS)\n",
    "    return model\n",
    "\n",
    "def train_model():\n",
    "    '''\n",
    "    MODEL TRAIN/VALIDATION \n",
    "    (silent mode - verbose = 0)\n",
    "    '''\n",
    "\n",
    "    #https://keras.io/api/callbacks/model_checkpoint/\n",
    "    ckpt_path = base_vigia_dir+'/zhen_++/'+time_str+'_2_4_8_xdviolence_anomaly_{epoch:08d}.h5'\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(ckpt_path, save_freq='epoch')\n",
    "\n",
    "    #para_file_name = '.262731_2_4_8_xdviolence_anomaly_00000010.h5'\n",
    "    #model.load_weights(para_file_name)\n",
    "\n",
    "    print(\"\\n\\nMODEL.FIT\")\n",
    "    history = model.fit(generate_input(), \n",
    "                        steps_per_epoch=len(train_fn)*2, \n",
    "                        epochs=30, \n",
    "                        verbose=1, \n",
    "                        callbacks=[checkpoint, TqdmCallback(verbose=2)])\n",
    "\n",
    "    model.save(time_str + '_2_4_8_xdviolence')\n",
    "    model.save_weights(time_str + '_2_4_8_xdviolence_model_weights.h5')  \n",
    "\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_csv_file = time_str + '_xdviolence_history.csv'\n",
    "    with open(hist_csv_file, mode = 'w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "        \n",
    "    return model\n",
    "\n",
    "def test_model(model):\n",
    "    print(\"\\nTEST MODEL\\n\")\n",
    "    f = open(base_vigia_dir+'/zhen++/parameters_results/'+model_weight_fn+'_'+str(batch_type)+'.txt', 'w')\n",
    "    content_str = ''\n",
    "    total_frames_test = 0\n",
    "    predict_total= [] \n",
    "    \n",
    "    start_test = time.time()\n",
    "    for i in range(len(test_fn)):\n",
    "        if test_fn[i] != '':\n",
    "            file_path = test_fn[i]\n",
    "            \n",
    "            #the frist 4000 frames from actual test video                \n",
    "            frame1, divid_no, total_frames, fps = input_test_video_data(file_path)\n",
    "            video_time = total_frames/fps\n",
    "            total_frames_test += total_frames\n",
    "            \n",
    "            start_predict1 = time.time()\n",
    "            predict_result = model.predict(frame1)[0][0]\n",
    "            end_predict1 = time.time()\n",
    "            time_predict = end_predict1-start_predict1\n",
    "            \n",
    "            high_score_patch = 0\n",
    "            print(\"\\t \",predict_result,\"%\") \n",
    "            \n",
    "            \n",
    "            #when frame1 (input video) has > 4000 frames\n",
    "            patch_num = 1\n",
    "            while patch_num < divid_no:\n",
    "                frame1, divid_no, total_frames, fps = input_test_video_data(file_path, patch_num)\n",
    "                \n",
    "                start_predict2 = time.time()\n",
    "                predict_new = model.predict(frame1)[0][0]\n",
    "                end_predict2 = time.time()\n",
    "                time_predict += end_predict2 - start_predict2\n",
    "                \n",
    "                if predict_new > predict_result:\n",
    "                    predict_result = predict_new\n",
    "                    high_score_patch = patch_num\n",
    "                    \n",
    "                print(\"\\t \",predict_result,\"%\")  \n",
    "                patch_num += 1\n",
    "                \n",
    "            predict_total.append(predict_result)\n",
    "            \n",
    "            if 'label_A' in test_fn[i]:\n",
    "                print('\\nNORM',str(i),':',f'{total_frames:.0f}',\"@\",f'{fps:.0f}',\"fps =\",f'{video_time:.2f}',\"sec\\n\\t\",\n",
    "                        test_fn[i][test_fn[i].rindex('/')+1:],\n",
    "                        \"\\n\\t \"+str(predict_result),\"% @batch\",high_score_patch,\"in\",str(time_predict),\"seconds\\n\",\n",
    "                        \"----------------------------------------------------\\n\")\n",
    "            else:\n",
    "                print('\\nABNORM',str(i),':',f'{total_frames:.0f}',\"@\",f'{fps:.0f}',\"fps =\",f'{video_time:.2f}',\"sec\\n\\t\",\n",
    "                        test_fn[i][test_fn[i].rindex('/')+1:],\n",
    "                        \"\\n\\t\"+str(predict_result),\"% @batch\",high_score_patch,\"in\",str(time_predict),\"seconds\\n\",\n",
    "                        \"----------------------------------------------------\\n\")\n",
    "                \n",
    "            content_str += test_fn[i][test_fn[i].rindex('/')+1:] + '\\t' + str(predict_result)  + '\\n'\n",
    "    \n",
    "    end_test = time.time()\n",
    "    time_test = end_test - start_test\n",
    "\n",
    "    f.write(content_str)\n",
    "    f.close()\n",
    "    print(\"\\nDONE\\n\\ttotal of\",str(total_frames_test),\"frames processed in\",time_test,\" seconds\",\n",
    "            \"\\n\\t\"+str(total_frames_test / time_test),\"frames per second\")                  \n",
    "\n",
    "    return predict_total\n",
    "\n",
    "\n",
    "def plot_cm(y_test_pred,p=0.5):\n",
    "    '''\n",
    "    https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#download_the_kaggle_credit_card_fraud_data_set\n",
    "    '''\n",
    "    cm = confusion_matrix(y_test_labels, y_test_pred > p)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(base_vigia_dir+\"/zhen++/parameters_results\"+model_weight_fn+'_CM'+str(batch_type)+'.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    GPU CONFIGURATION\n",
    "    https://www.tensorflow.org/guide/gpu\n",
    "'''\n",
    "set_tf_loglevel(logging.WARNING)\n",
    "\n",
    "#Enabling device placement logging causes any Tensor allocations or operations to be printed.\n",
    "tf.debugging.set_log_device_placement(False) \n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "\n",
    "#https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_memory_growth\n",
    "\n",
    "#if gpus:\n",
    "#    print(\"\\nAvaiable GPU's\",gpus)\n",
    "#    try:\n",
    "#        # Currently, memory growth needs to be the same across GPUs\n",
    "#        for gpu in gpus:\n",
    "#            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#        \n",
    "#        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "#        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#    except RuntimeError as e:\n",
    "#        # Memory growth must be set before GPUs have been initialized\n",
    "#        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_height = 120\n",
    "target_width = 160\n",
    "frame_max = 4000\n",
    "\n",
    "test_fn, y_test_labels = test_files()\n",
    "train_fn = train_files()\n",
    "\n",
    "update_index = range(0, len(train_fn))\n",
    "time_str = str(time.time())\n",
    "print(\"\\ntime_str=\",time_str,\"\\n\")        \n",
    "\n",
    "\n",
    "#model = form_model()\n",
    "#model = train_model()\n",
    "#test_model(model) \n",
    "\n",
    "model = form_model()\n",
    "weights_fn, weights_path = find_weights()\n",
    "\n",
    "\n",
    "# =1 last batch has 4000 frames // =2 last batch has no repetead frames\n",
    "batch_org = [1,2]\n",
    "for i in range(len(batch_org)):       \n",
    "    print(\"\\n\\n\\t\\tBATCH TYPE 1\")\n",
    "    batch_type = batch_org[i]\n",
    "    \n",
    "    for i in range(len(weights_fn)):\n",
    "        print(\"\\n\\nLoading weights from\",weights_fn[i],\"\\n\")\n",
    "        model.load_weights(weights_path[i])\n",
    "        model_weight_fn,model_weight_ext = os.path.splitext(str(weights_fn[i]))\n",
    "        \n",
    "        y_test_pred = test_model(model)\n",
    "        plot_cm(y_test_pred)\n",
    "\n",
    "\n",
    "'''\n",
    "for i in range(8,11):\n",
    "    if i < 10:\n",
    "        para_file_name = '1626947956.798592_2_4_8_xdviolence_anomaly_0000000' + str(i) + '.h5'\n",
    "    else:\n",
    "        para_file_name = '1626947956.798592_2_4_8_xdviolence_anomaly_000000' + str(i) + '.h5'\n",
    "        \n",
    "model.load_weights(para_file_name)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('zhen_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6eb85c0477d574fd6bdabb52dbe9212bb7f487155853edb797b76ac4297f2c9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
