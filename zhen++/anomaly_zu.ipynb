{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mtcnn\n",
    "import keras\n",
    "from keras import models, layers\n",
    "import tensorflow as tf\n",
    "import os, time, random, logging\n",
    "from tqdm.keras import TqdmCallback\n",
    "import pandas as pd\n",
    "\n",
    "from IPython import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PATH VAR \"\"\"\n",
    "base_vigia_dir = \"/media/jtstudents/HDD/.zuble/vigia\"\n",
    "weights_base_path = base_vigia_dir+\"/zhen++/parameters_saved\"\n",
    "rslt_path = base_vigia_dir+'/zhen++/parameters_results'\n",
    "\n",
    "#server_testname_folder = '/raid/DATASETS/anomaly/XD_Violence/testing'\n",
    "server_testname_folder = '/media/jtstudents/HDD/.zuble/xdviol/test'\n",
    "\n",
    "#server_video_loc = '/home/zhen/Documents/Remote/raid/DATASETS/anomaly/UCF_Crimes/Videos'\n",
    "#server_video_loc = '/raid/DATASETS/anomaly/XD_Violence/training/'\n",
    "server_video_loc = '/media/jtstudents/HDD/.zuble/xdviol/train'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TEST/TRAIN FILES \"\"\"\n",
    "def test_files(onev = 0):\n",
    "    \"\"\"\n",
    "    GENERATE LIST of TEST FILES\n",
    "    \"\"\"\n",
    "    test_fn, test_normal_fn, test_abnormal_fn = [],[],[]\n",
    "    y_test_labels, y_test_norm, y_test_abnor = [],[],[]\n",
    "    \n",
    "    #all test files\n",
    "    if onev == 0:\n",
    "        for root, dirs, files in os.walk(server_testname_folder):\n",
    "            for file in files:\n",
    "                if file.find('.mp4') != -1:\n",
    "                    if 'label_A' not in file:\n",
    "                        test_normal_fn.append(os.path.join(root, file))\n",
    "                        y_test_norm.append(0)\n",
    "                    else:\n",
    "                        test_abnormal_fn.append(os.path.join(root, file))\n",
    "                        y_test_abnor.append(1)\n",
    "                        \n",
    "        test_fn = test_normal_fn + test_abnormal_fn\n",
    "        y_test_labels = y_test_norm + y_test_abnor\n",
    "    #only onev random files\n",
    "    else :\n",
    "        test_abn_fn = [x for x in os.listdir(server_testname_folder) if 'label_A' not in x]\n",
    "        test_nor_fn = [x for x in os.listdir(server_testname_folder) if 'label_A' in x]\n",
    "        \n",
    "        onev_abnor = int(onev/2)\n",
    "        while True: \n",
    "            ap = random.choice(test_abn_fn) \n",
    "            if ap not in test_fn: \n",
    "                test_fn.append(server_testname_folder+\"/\"+ap)\n",
    "                y_test_labels.append(1)\n",
    "                if len(test_fn) == onev_abnor: \n",
    "                    break \n",
    "        while True: \n",
    "            ap = random.choice(test_nor_fn) \n",
    "            if ap not in test_fn: \n",
    "                test_fn.append(server_testname_folder+\"/\"+ap)\n",
    "                y_test_labels.append(0)\n",
    "                if len(test_fn) == onev: \n",
    "                    break    \n",
    "    \n",
    "    print(\"\\ntest_fn\",np.shape(test_fn),\"\\ntest_normal_fn\",np.shape(test_normal_fn),\"\\ntest_abnormal_fn\",np.shape(test_abnormal_fn))\n",
    "    print(\"\\ny_test_labels\",np.shape(y_test_labels),\"\\ny_test_norm\",np.shape(y_test_norm),\"\\ny_test_abnor\",np.shape(y_test_abnor))\n",
    "    \n",
    "    return test_fn, y_test_labels\n",
    "\n",
    "def train_files():\n",
    "    \"\"\"\n",
    "    GENERATING LIST of TRAIN FILES\n",
    "    \"\"\"\n",
    "    train_fn = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(server_video_loc):\n",
    "        for file in files:\n",
    "            if file.find('.mp4') != -1:\n",
    "                train_fn.append(os.path.join(root, file))\n",
    "                \n",
    "    print(\"\\ntrain_fn=\",np.shape(train_fn))\n",
    "    \n",
    "    return train_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test_fn (800,) \n",
      "test_normal_fn (500,) \n",
      "test_abnormal_fn (300,)\n",
      "\n",
      "y_test_labels (800,) \n",
      "y_test_norm (500,) \n",
      "y_test_abnor (300,)\n",
      "\n",
      "train_fn= (3954,)\n",
      "\n",
      "time_str= 1670874934.7674057 \n",
      "\n",
      "\n",
      "\n",
      "\t\tBATCH TYPE 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\" GLOBAL VAR \"\"\"\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "target_height = 120\n",
    "target_width = 160\n",
    "frame_max = 4000\n",
    "\n",
    "test_fn, y_test_labels = test_files()\n",
    "train_fn = train_files()\n",
    "\n",
    "update_index = range(0, len(train_fn))\n",
    "time_str = str(time.time())\n",
    "print(\"\\ntime_str=\",time_str,\"\\n\")\n",
    "\n",
    "# =1 last batch has 4000 frames // =2 last batch has no repetead frames\n",
    "batch_type = 1\n",
    "print(\"\\n\\n\\t\\tBATCH TYPE\",batch_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" INPUT DATA\"\"\"\n",
    "def input_video_data(file_name):\n",
    "    print(\"\\n\\nINPUT_VIDEO_DATA\\n\")\n",
    "    #file_name = 'C:\\\\Bosch\\\\Anomaly\\\\training\\\\videos\\\\13_007.avi'\n",
    "    #file_name = '/raid/DATASETS/anomaly/UCF_Crimes/Videos/Training_Normal_Videos_Anomaly/Normal_Videos308_x264.mp4'\n",
    "    video = cv2.VideoCapture(file_name)\n",
    "    total_frame = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    mtcnn_detector = mtcnn.mtcnn.MTCNN()\n",
    "    #print(file_name + '  ' + str(total_frame))\n",
    "    divid_no = 1\n",
    "    \n",
    "    if total_frame > frame_max:\n",
    "        total_frame_int = int(total_frame)\n",
    "        if total_frame_int % frame_max == 0:\n",
    "            divid_no = int(total_frame / frame_max)\n",
    "        else:\n",
    "            divid_no = int(total_frame / frame_max) + 1\n",
    "        \n",
    "    batch_no = 0\n",
    "    batch_frames = []\n",
    "    batch_frames_flip = []\n",
    "    counter = 0\n",
    "    if 'Normal' in file_name:\n",
    "        print(\"\\n\\nNORMAL\\n\\n\")\n",
    "        if divid_no != 1:\n",
    "            slice_no = int(random.random()*divid_no)\n",
    "            passby = 0\n",
    "            if slice_no != divid_no - 1:\n",
    "                while video.isOpened and passby < frame_max * slice_no:\n",
    "                    passby += 1\n",
    "                    success, image = video.read()\n",
    "                    if success == False:\n",
    "                        break\n",
    "            else:\n",
    "                while video.isOpened and passby < total_frame - frame_max:\n",
    "                    passby += 1\n",
    "                    success, image = video.read()\n",
    "                    if success == False:\n",
    "                        break\n",
    "\n",
    "    while video.isOpened:               \n",
    "        success, image = video.read()\n",
    "        if success == False:\n",
    "            break\n",
    "            \n",
    "        #ratio = image.shape[0] / image.shape[1]\n",
    "        #print(str(image.shape[0])+ ' ' + str(image.shape[1]))\n",
    "        #image = cv2.resize(image, (800, int(800*ratio)))\n",
    "        #print(image.shape)\n",
    "        #faces = face_detector.detectMultiScale(image,1.1,8)\n",
    "        '''\n",
    "        faces = mtcnn_detector.detect_faces(image)\n",
    "        \n",
    "        for face in faces:\n",
    "            (x,y,w,h) = face['box']\n",
    "            #print(face)\n",
    "            cv2.rectangle(image,(x,y), (x+w,y+h), (255,255,0), 2)\n",
    "            cv2.putText(image, str(face['confidence'])[:4], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (36,255,12), 1)\n",
    "        '''\n",
    "        image = cv2.resize(image, (target_width, target_height))\n",
    "        image_flip = cv2.flip(image, 1)\n",
    "        \n",
    "        image_array = np.array(image)/255.0\n",
    "        image_array_flip = np.array(image_flip)/255.0\n",
    "        \n",
    "        batch_frames.append(image_array)\n",
    "        batch_frames_flip.append(image_array_flip)\n",
    "        \n",
    "        counter += 1\n",
    "        if counter > frame_max:\n",
    "            break\n",
    "            \n",
    "    video.release()\n",
    "    batch_frames = np.array(batch_frames)\n",
    "    #print(batch_frames.shape)\n",
    "        \n",
    "    return np.expand_dims(batch_frames,0), np.expand_dims(batch_frames_flip, 0), total_frame\n",
    "\n",
    "def generate_input():\n",
    "    #has_visited = [0 for i in range(len(train_fn))]\n",
    "    \n",
    "    print(\"\\n\\nGENERATE_INPUT\\n\")\n",
    "    loop_no = 0\n",
    "    while 1:\n",
    "        index = update_index[loop_no]\n",
    "        loop_no += 1\n",
    "        if loop_no == len(train_fn):\n",
    "            loop_no = 0\n",
    "            \n",
    "        #index = 0\n",
    "        batch_frames, batch_frames_flip, total_frames = input_video_data(train_fn[index])\n",
    "        print(\"\\ntrain_fn[\",index,\"]=\",train_fn[index],\"\\ntotal_frames=\",total_frames,\"\\nbatch_frames.shape=\",batch_frames.shape)\n",
    "        #if batch_frames.ndim != 5:\n",
    "        #   break\n",
    "        \n",
    "        # GENERATORS    \n",
    "        #       a kind of iterators that can only iterate over once\n",
    "        #       NO store of values in memory\n",
    "        # YIELD \n",
    "        #       like a return, except the function will return a generator\n",
    "        \n",
    "        '''\n",
    "        if 'Abuse' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([1,0,0,0,0,0,0,0,0,0,0,0,0,0])])\n",
    "        elif 'Arrest' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,1,0,0,0,0,0,0,0,0,0,0,0,0])])\n",
    "        elif 'Arson' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,1,0,0,0,0,0,0,0,0,0,0,0])])\n",
    "        elif 'Assault' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,1,0,0,0,0,0,0,0,0,0,0])]) \n",
    "        elif 'Burglary' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,1,0,0,0,0,0,0,0,0,0])]) \n",
    "        elif 'Explosion' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,1,0,0,0,0,0,0,0,0])])        \n",
    "        elif 'Fighting' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,1,0,0,0,0,0,0,0])]) \n",
    "        elif 'RoadAccidents' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,0,1,0,0,0,0,0,0])]) \n",
    "        elif 'Robbery' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,0,0,1,0,0,0,0,0])]) \n",
    "        elif 'Shooting' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,0,0,0,1,0,0,0,0])]) \n",
    "        elif 'Shoplifting' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,0,0,0,0,1,0,0,0])]) \n",
    "        elif 'Stealing' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,0,0,0,0,0,1,0,0])])\n",
    "        elif 'Normal' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,0,0,0,0,0,0,1,0])]) \n",
    "        elif 'Vandalism' in train_fn[index]:\n",
    "            yield batch_frames,  np.array([np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,1])]) \n",
    "        '''\n",
    "        \n",
    "        #batch_frames\n",
    "        if 'label_A' in train_fn[index]:\n",
    "            yield batch_frames, np.array([0])   #normal\n",
    "        else:\n",
    "            yield batch_frames, np.array([1])   #abnormal\n",
    "\n",
    "        #batch_frames_flip\n",
    "        if 'label_A' in train_fn[index]:\n",
    "            yield batch_frames_flip, np.array([0])  #normal\n",
    "        else:\n",
    "            yield batch_frames_flip, np.array([1])  #abnormal\n",
    "    \n",
    "    print(\"loop_no=\",loop_no)\n",
    "\n",
    "def input_test_video_data(file_name, batch_no=0):\n",
    "    #file_name = 'C:\\\\Bosch\\\\Anomaly\\\\training\\\\videos\\\\13_007.avi'\n",
    "    #file_name = '/raid/DATASETS/anomaly/UCF_Crimes/Videos/Training_Normal_Videos_Anomaly/Normal_Videos308_x264.mp4'\n",
    "    video = cv2.VideoCapture(file_name)\n",
    "    total_frame = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    #mtcnn_detector = mtcnn.mtcnn.MTCNN()\n",
    "    divid_no = 1\n",
    "\n",
    "    if total_frame > frame_max:\n",
    "        total_frame_int = int(total_frame)\n",
    "        if total_frame_int % frame_max == 0:\n",
    "            divid_no = int(total_frame / frame_max)\n",
    "        else:\n",
    "            divid_no = int(total_frame / frame_max) + 1\n",
    "\n",
    "\n",
    "    #updates the start frame to 0,4000,8000... excluding the last batch\n",
    "    passby = 0\n",
    "    if batch_no != divid_no - 1:\n",
    "        while video.isOpened and passby < frame_max * batch_no:\n",
    "            passby += 1\n",
    "            success, image = video.read()\n",
    "            if success == False:\n",
    "                break\n",
    "            \n",
    "    #updates the last batch starting frame \n",
    "    else:\n",
    "        if batch_type==1:\n",
    "            #print(\"1\")\n",
    "            while video.isOpened and passby < total_frame - frame_max:\n",
    "                passby += 1\n",
    "                success, image = video.read()\n",
    "                if success == False:\n",
    "                    break\n",
    "        #last batch must have >= 400 otherwise it falls back to batch_type 1\n",
    "        if batch_type==2 and total_frame - (frame_max * batch_no) >= frame_max*0.1:\n",
    "            #print(\"2\")\n",
    "            while video.isOpened and passby < frame_max * batch_no:\n",
    "                passby += 1\n",
    "                success, image = video.read()\n",
    "                if success == False:\n",
    "                    break\n",
    "        else:\n",
    "            while video.isOpened and passby < total_frame - frame_max:\n",
    "                passby += 1\n",
    "                success, image = video.read()\n",
    "                if success == False:\n",
    "                    break\n",
    "\n",
    "            \n",
    "    batch_frames, batch_imgs = [], []\n",
    "    counter = 0\n",
    "    \n",
    "    while video.isOpened:               \n",
    "        success, image = video.read()\n",
    "        if success == False:\n",
    "            break\n",
    "        batch_imgs.append(image)\n",
    "        \n",
    "        image_rsz = cv2.resize(image, (target_width, target_height))\n",
    "        image_array = np.array(image_rsz)/255.0 #normalize\n",
    "        batch_frames.append(image_array)\n",
    "        \n",
    "        counter += 1\n",
    "        if counter > frame_max:\n",
    "            break\n",
    "            \n",
    "    video.release()\n",
    "    batch_frames = np.array(batch_frames)\n",
    "    \n",
    "    print(\"\\t-batch\",batch_no,\"[\",passby,\", ... ] \",batch_frames.shape)    \n",
    "    \n",
    "    return np.expand_dims(batch_frames,0), batch_imgs, divid_no, total_frame, passby, fps\n",
    "\n",
    "def watch_test(predict_total,test_files):\n",
    "    global is_quit, is_paused, frame_counter\n",
    "    for k in range(len(test_files)):\n",
    "        \n",
    "        file_path = test_files[k]\n",
    "        video = cv2.VideoCapture(str(file_path))\n",
    "        \n",
    "        window_name = \"anoml vwr\"+str(k)+\":\"+file_path.replace('/media/jtstudents/HDD/.zuble/xdviol/test','')\n",
    "        cv2.namedWindow(window_name)\n",
    "        \n",
    "        # Video information\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        width  = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        total_frame = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        \n",
    "        # We can set up keys to pause, go back and forth.\n",
    "        # **params can be used to pass parameters to key actions.\n",
    "        def quit_key_action(**params):\n",
    "            global is_quit\n",
    "            is_quit = True\n",
    "        def rewind_key_action(**params):\n",
    "            global frame_counter\n",
    "            frame_counter = max(0, int(frame_counter - (fps * 5)))\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, frame_counter)\n",
    "        def forward_key_action(**params):\n",
    "            global frame_counter\n",
    "            frame_counter = min(int(frame_counter + (fps * 5)), total_frame - 1)\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, frame_counter)\n",
    "        def pause_key_action(**params):\n",
    "            global is_paused\n",
    "            is_paused = not is_paused\n",
    "        # Map keys to buttons\n",
    "        key_action_dict = {\n",
    "            ord('q'): quit_key_action,\n",
    "            ord('a'): rewind_key_action,\n",
    "            ord('d'): forward_key_action,\n",
    "            ord('s'): pause_key_action,\n",
    "            ord(' '): pause_key_action\n",
    "        }\n",
    "        def key_action(_key):\n",
    "            if _key in key_action_dict:\n",
    "                key_action_dict[_key]()\n",
    "                \n",
    "        prev_time = time.time() # Used to track real fps\n",
    "        is_quit = False         # Used to signal that quit is called\n",
    "        is_paused = False       # Used to signal that pause is called\n",
    "        \n",
    "        frame_counter = 0       # Used to track which frame are we.\n",
    "        batch_in_video = predict_total[k][0]\n",
    "        predict_atual = ()\n",
    "        try:\n",
    "            while video.isOpened():\n",
    "                # If the video is paused, we don't continue reading frames.\n",
    "                if is_quit:\n",
    "                    # Do something when quiting\n",
    "                    break\n",
    "                elif is_paused:\n",
    "                    # Do something when paused\n",
    "                    pass\n",
    "                else:\n",
    "                    sucess, frame = video.read() # Read the frames\n",
    "                    if not sucess:break\n",
    "\n",
    "                    frame_counter = int(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "                                        \n",
    "                    if batch_in_video == 1: predict_atual = predict_total[k][2]\n",
    "                    #(2, 4001, 0.99958295, 661, 4661, 0.98756117))\n",
    "                    if batch_in_video == 2:\n",
    "                        #<661 as=0.999\n",
    "                        if frame_counter < predict_total[k][3]: predict_atual = predict_total[k][2]\n",
    "                        # > 661 and < 4000 as: 0.999 | 0.987\n",
    "                        elif frame_counter < predict_total[k][1]: predict_atual = predict_total[k][2] , predict_total[k][5]\n",
    "                        # > 4000 as: 0.987\n",
    "                        else: predict_atual = predict_total[k][5]\n",
    "                    #(3, 4001, 0.99958295, 4001, 8000, 0.98756117,4500,8500,0.836))\n",
    "                    if batch_in_video == 3:\n",
    "                        #<4000 as=0.999\n",
    "                        if frame_counter < predict_total[k][1]: predict_atual = predict_total[k][2]\n",
    "                        #< 4500 as=0.987\n",
    "                        elif frame_counter < predict_total[k][6]: predict_atual = predict_total[k][5]\n",
    "                        #< 8000 as=0.987 | 0.836\n",
    "                        elif frame_counter < predict_total[k][4]: predict_atual = predict_total[k][5] , predict_total[k][8]\n",
    "                        # > 8000 as=0.836\n",
    "                        else:predict_atual = predict_total[k][8]\n",
    "                    #(4, 4001,0.99958295, 4001,8000,0.98756117, 8000,12000,0.836, 8500,12500,0.888))    \n",
    "                    if batch_in_video == 4:\n",
    "                        #<4000 as=0.999\n",
    "                        if frame_counter < predict_total[k][1]: predict_atual = predict_total[k][2]\n",
    "                        #<8000 as=0.987\n",
    "                        elif frame_counter < predict_total[k][4]: predict_atual = predict_total[k][5]\n",
    "                        #< 8500 as=0.836\n",
    "                        elif frame_counter < predict_total[k][9]: predict_atual = predict_total[k][8]\n",
    "                        #< 12000 as=0.836 / 0.888\n",
    "                        elif frame_counter < predict_total[k][7]: predict_atual = predict_total[k][8] , predict_total[k][11]\n",
    "                        # > 8000 as=0.836\n",
    "                        else:predict_atual = predict_total[k][11]\n",
    "                    #(5, 4001,0.99958295, 4001,8000,0.98756117, 8000,12000,0.836, 12000,16000,0.888, 12500,16500,0.777))\n",
    "                    if batch_in_video == 5:\n",
    "                        #<4000 as=0.999\n",
    "                        if frame_counter < predict_total[k][1]: predict_atual = predict_total[k][2]\n",
    "                        #<8000 as=0.987\n",
    "                        elif frame_counter < predict_total[k][4]: predict_atual = predict_total[k][5]\n",
    "                        #< 12000 as=0.836\n",
    "                        elif frame_counter < predict_total[k][7]: predict_atual = predict_total[k][8]\n",
    "                        #< 12500 as=0.888\n",
    "                        elif frame_counter < predict_total[k][12]: predict_atual = predict_total[k][11]\n",
    "                        #<16000 as:0.888 | 0.777\n",
    "                        elif frame_counter < predict_total[k][10]: predict_atual = predict_total[k][11] , predict_total[k][14]\n",
    "                        # >16000 as=0.777\n",
    "                        else:predict_atual = predict_total[k][14]\n",
    "                    #(6, 4001,0.99958295, 4001,8000,0.98756117, 8000,12000,0.836, 12000,16000,0.888, 16000,20000,0.777, 16500,20500,0.5))\n",
    "                    if batch_in_video == 6:\n",
    "                        #<4000 as=0.999\n",
    "                        if frame_counter < predict_total[k][1]: predict_atual = predict_total[k][2]\n",
    "                        #<8000 as=0.987\n",
    "                        elif frame_counter < predict_total[k][4]: predict_atual = predict_total[k][5]\n",
    "                        #< 12000 as=0.836\n",
    "                        elif frame_counter < predict_total[k][7]: predict_atual = predict_total[k][8]\n",
    "                        #<16000 as=0.888\n",
    "                        elif frame_counter < predict_total[k][10]: predict_atual = predict_total[k][11]\n",
    "                        #<16500 as:0.777\n",
    "                        elif frame_counter < predict_total[k][15]: predict_atual = predict_total[k][14]\n",
    "                        #<20000 as:0.777 | 0.5\n",
    "                        elif frame_counter < predict_total[k][13]: predict_atual = predict_total[k][14] , predict_total[k][17]\n",
    "                        #>20000 as=0.5\n",
    "                        else:predict_atual = predict_total[k][17]\n",
    "                    #(7, 4001,0.99958295, 4001,8000,0.98756117, 8000,12000,0.836, 12000,16000,0.888, 16000,20000,0.777, 20000,24000,0.5, 20500,24500,0.6))\n",
    "                    if batch_in_video == 7:\n",
    "                        #<4000 as=0.999\n",
    "                        if frame_counter < predict_total[k][1]: predict_atual = predict_total[k][2]\n",
    "                        #<8000 as=0.987\n",
    "                        elif frame_counter < predict_total[k][4]: predict_atual = predict_total[k][5]\n",
    "                        #< 12000 as=0.836\n",
    "                        elif frame_counter < predict_total[k][7]: predict_atual = predict_total[k][8]\n",
    "                        #<16000 as=0.888\n",
    "                        elif frame_counter < predict_total[k][10]: predict_atual = predict_total[k][11]\n",
    "                        #<20000 as=0.777\n",
    "                        elif frame_counter < predict_total[k][13]: predict_atual = predict_total[k][14]\n",
    "                        #<20500 as:0.5\n",
    "                        elif frame_counter < predict_total[k][18]: predict_atual = predict_total[k][17]\n",
    "                        #<24000 as:0.5 | 0.6\n",
    "                        elif frame_counter < predict_total[k][16]: predict_atual = predict_total[k][17] , predict_total[k][20]\n",
    "                        #>24000 as=0.6\n",
    "                        else:predict_atual = predict_total[k][20]\n",
    "                    #(8, 4001,0.2, 4001,8000,0.5, 8000,12000,0.8, 12000,16000,0.11, 16000,20000,0.14, 20000,24000,0.17, 24000,28000,0.20, 24500.28500,0.23))\n",
    "                    if batch_in_video == 8:\n",
    "                        #<4000 as=0.2\n",
    "                        if frame_counter < predict_total[k][1]: predict_atual = predict_total[k][2]\n",
    "                        #<8000 as=0.5\n",
    "                        elif frame_counter < predict_total[k][4]: predict_atual = predict_total[k][5]\n",
    "                        #< 12000 as=0.8\n",
    "                        elif frame_counter < predict_total[k][7]: predict_atual = predict_total[k][8]\n",
    "                        #<16000 as=0.11\n",
    "                        elif frame_counter < predict_total[k][10]: predict_atual = predict_total[k][11]\n",
    "                        #<20000 as=0.14\n",
    "                        elif frame_counter < predict_total[k][13]: predict_atual = predict_total[k][14]\n",
    "                        #<24000 as:0.17\n",
    "                        elif frame_counter < predict_total[k][16]: predict_atual = predict_total[k][17]\n",
    "                        #<24500 as:0.20\n",
    "                        elif frame_counter < predict_total[k][21]: predict_atual = predict_total[k][20]\n",
    "                        #<28000 as:0.20 | 0.23\n",
    "                        elif frame_counter < predict_total[k][19]: predict_atual = predict_total[k][20] , predict_total[k][23]\n",
    "                        #>28000 as=0.23\n",
    "                        else:predict_atual = predict_total[k][23]                    \n",
    "                    \n",
    "                    \n",
    "                    '''\n",
    "                    for current frame, check all visible items\n",
    "                    if str(frame_counter) in data_frames:\n",
    "                        for item in data_frames[str(frame_counter)]:\n",
    "                            item_id = item['visibleObjectId']\n",
    "                            color = colormap.get_color(item_id)\n",
    "                        \n",
    "                            # for visible item, get position at current frame and paint rectangle in\n",
    "                            if frame_counter in data_objects[item_id]:\n",
    "                                bbox = data_objects[item_id][frame_counter]['rectangle']\n",
    "                                x1 = bbox[0]['x']\n",
    "                                y1 = bbox[0]['y']\n",
    "                                x2 = x1 + bbox[0]['w']\n",
    "                                y2 = y1 + bbox[0]['h']\n",
    "                                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                                cv2.putText(frame, str(item_id[:3]), (x1, y1-10), font, 0.5, color, 2)\n",
    "                    '''\n",
    "                    \n",
    "                    print(predict_atual)\n",
    "                    \n",
    "                    # Display frame numba/AS/time/fps\n",
    "                    cv2.putText(frame, 'Frame: %d' % (frame_counter), (10, 10), font, 0.5, [60,250,250], 2)\n",
    "                    cv2.putText(frame, 'AS:'+str(predict_atual), (10, 30), font, 0.5, [80,100,250], 2)\n",
    "                    \n",
    "                    cv2.putText(frame, 'Time: %.4f' % (frame_counter/fps), (int(width*2/8), 10), font, 0.5, [100,250,10], 2)\n",
    "                    new_time = time.time()\n",
    "                    cv2.putText(frame, 'fps: %.2f' % (1/(new_time-prev_time)), (int(width*4/8), 10), font, 0.5, [0,50,200], 2)\n",
    "                    prev_time = new_time\n",
    "                    \n",
    "                # Display the image\n",
    "                cv2.imshow(window_name,frame)\n",
    "\n",
    "                # Wait for any key press and pass it to the key action\n",
    "                frame_time_ms = int(1000/fps)\n",
    "                key = cv2.waitKey(frame_time_ms)\n",
    "                key_action(key)\n",
    "                \n",
    "        finally:\n",
    "            video.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "    file_number =+ 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MODEL \"\"\"\n",
    "\n",
    "def all_operations(args):\n",
    "    x = args[0]\n",
    "    #tf.print(x.shape)\n",
    "    x = tf.reshape(x, [1, -1,x.shape[1]*x.shape[2]*x.shape[3]])\n",
    "    return x\n",
    "@tf.function\n",
    "def loss_category(y_true, y_pred):    \n",
    "    #tf.print(y_pred, y_true, 'Prediction')\n",
    "    cce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    return cce\n",
    "\n",
    "\n",
    "def find_weights(): \n",
    "    weights_fn = []\n",
    "    weights_path = []\n",
    "\n",
    "    for file in os.listdir(weights_base_path):\n",
    "        fname, fext = os.path.splitext(file)\n",
    "        if fext == \".h5\" and file.find('_2_4_8_xdviolence_model_weights') != -1 :\n",
    "            print(file)\n",
    "            weights_path.append(os.path.join(weights_base_path, file))\n",
    "            weights_fn.append(file)\n",
    "\n",
    "    return weights_fn, weights_path\n",
    "\n",
    "\n",
    "def form_model():\n",
    "    print(\"\\nFORM_MODEL\\n\")\n",
    "    image_input = keras.Input(shape=(None, target_height, target_width, 3))\n",
    "    #Freeze the batch normalization\n",
    "    \n",
    "    c3d_layer1 = keras.layers.Conv3D(4,(2,3,3), activation='relu')(image_input)\n",
    "    c3d_pooling1 = keras.layers.MaxPooling3D((1,2,2))(c3d_layer1)\n",
    "    c3d_layer2 = keras.layers.Conv3D(8,(4,3,3), activation='relu')(c3d_pooling1)\n",
    "    c3d_pooling2 = keras.layers.MaxPooling3D((2,2,2))(c3d_layer2)\n",
    "    c3d_layer3 = keras.layers.Conv3D(16,(8,3,3), activation='relu')(c3d_pooling2)\n",
    "    c3d_pooling3 = keras.layers.MaxPooling3D((4,2,2))(c3d_layer3)\n",
    "    #c3d_layer4 = keras.layers.Conv3D(32,(2,3,3), activation='relu')(c3d_pooling3)\n",
    "    #c3d_pooling4 = keras.layers.MaxPooling3D((2,2,2))(c3d_layer4)\n",
    "    \n",
    "    feature_conv_4 = keras.layers.Lambda(all_operations)(c3d_pooling3)\n",
    "    \n",
    "    lstm1 = keras.layers.LSTM(1024,input_shape=(1200,feature_conv_4.shape[2]), return_sequences=True)(feature_conv_4)\n",
    "    lstm2 = keras.layers.LSTM(512, return_sequences=True)(lstm1)\n",
    "    global_feature = keras.layers.GlobalMaxPooling1D()(lstm1)\n",
    "    \n",
    "    #ADD THE AUDIO FEATURE HERE \n",
    "    \n",
    "    dense_1 = keras.layers.Dense(128, activation='relu')(global_feature)\n",
    "    #dense_2 = keras.layers.Dense(13, activation='sigmoid')(dense_1)\n",
    "    \n",
    "    \n",
    "    soft_max = keras.layers.Dense(1, activation='sigmoid')(dense_1)\n",
    "    \n",
    "    \n",
    "    model = models.Model(inputs=[image_input], outputs=[soft_max])\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    #class_weights = [10,10,10,10,10,10,10,10,10,10,10,10,0.1,10]\n",
    "    optimizer_adam = keras.optimizers.SGD(learning_rate = 0.0002)\n",
    "    METRICS = [\n",
    "        keras.metrics.TruePositives(name='tp'),\n",
    "        keras.metrics.FalsePositives(name='fp'),\n",
    "        keras.metrics.TrueNegatives(name='tn'),\n",
    "        keras.metrics.FalseNegatives(name='fn'), \n",
    "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "    ]\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=optimizer_adam, \n",
    "                    loss= 'binary_crossentropy', \n",
    "                    #loss_weights = class_weights,\n",
    "                    #metrics=['accuracy']\n",
    "                    metrics=METRICS)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    '''\n",
    "    MODEL TRAIN/VALIDATION \n",
    "    (silent mode - verbose = 0)\n",
    "    '''\n",
    "\n",
    "    #https://keras.io/api/callbacks/model_checkpoint/\n",
    "    ckpt_path = base_vigia_dir+'/zhen_++/'+time_str+'_2_4_8_xdviolence_anomaly_{epoch:08d}.h5'\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(ckpt_path, save_freq='epoch')\n",
    "\n",
    "    #para_file_name = '.262731_2_4_8_xdviolence_anomaly_00000010.h5'\n",
    "    #model.load_weights(para_file_name)\n",
    "\n",
    "    print(\"\\n\\nMODEL.FIT\")\n",
    "    history = model.fit(generate_input(), \n",
    "                        steps_per_epoch=len(train_fn)*2, \n",
    "                        epochs=30, \n",
    "                        verbose=1, \n",
    "                        callbacks=[checkpoint, TqdmCallback(verbose=2)])\n",
    "\n",
    "    model.save(time_str + '_2_4_8_xdviolence')\n",
    "    model.save_weights(time_str + '_2_4_8_xdviolence_model_weights.h5')  \n",
    "\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_csv_file = time_str + '_xdviolence_history.csv'\n",
    "    with open(hist_csv_file, mode = 'w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(model):\n",
    "    print(\"\\nTEST MODEL\\n\")\n",
    "    f = open(base_vigia_dir+'/zhen++/parameters_results/'+model_weight_fn+'_'+str(batch_type)+'.txt', 'w')\n",
    "    content_str = ''\n",
    "    total_frames_test = 0\n",
    "    predict_total= [] \n",
    "    \n",
    "    start_test = time.time()\n",
    "    for i in range(len(test_fn)):\n",
    "        if test_fn[i] != '':\n",
    "            file_path = test_fn[i]\n",
    "            \n",
    "            #the frist 4000 frames from actual test video                \n",
    "            batch_frames, batch_imgs, divid_no, total_frames,start_frame, fps = input_test_video_data(file_path)\n",
    "            video_time = total_frames/fps\n",
    "            total_frames_test += total_frames\n",
    "            \n",
    "            start_predict1 = time.time()\n",
    "            predict_result = model.predict(batch_frames)[0][0]\n",
    "            end_predict1 = time.time()\n",
    "            time_predict = end_predict1-start_predict1\n",
    "            \n",
    "            high_score_patch = 0\n",
    "            print(\"\\t \",predict_result,\"%\") \n",
    "            \n",
    "            \n",
    "            #when batch_frames (input video) has > 4000 frames\n",
    "            patch_num = 1\n",
    "            while patch_num < divid_no:\n",
    "                batch_frames, batch_imgs, divid_no, total_frames,start_frame, fps = input_test_video_data(file_path, patch_num)\n",
    "                \n",
    "                start_predict2 = time.time()\n",
    "                predict_new = model.predict(batch_frames)[0][0]\n",
    "                end_predict2 = time.time()\n",
    "                time_predict += end_predict2 - start_predict2\n",
    "                \n",
    "                if predict_new > predict_result:\n",
    "                    predict_result = predict_new\n",
    "                    high_score_patch = patch_num\n",
    "                    \n",
    "                print(\"\\t \",predict_result,\"%\")  \n",
    "                patch_num += 1\n",
    "                \n",
    "            predict_total.append(predict_result)\n",
    "            \n",
    "            if 'label_A' in test_fn[i]:\n",
    "                print('\\nNORM',str(i),':',f'{total_frames:.0f}',\"@\",f'{fps:.0f}',\"fps =\",f'{video_time:.2f}',\"sec\\n\\t\",\n",
    "                        test_fn[i][test_fn[i].rindex('/')+1:],\n",
    "                        \"\\n\\t \"+str(predict_result),\"% @batch\",high_score_patch,\"in\",str(time_predict),\"seconds\\n\",\n",
    "                        \"----------------------------------------------------\\n\")\n",
    "            else:\n",
    "                print('\\nABNORM',str(i),':',f'{total_frames:.0f}',\"@\",f'{fps:.0f}',\"fps =\",f'{video_time:.2f}',\"sec\\n\\t\",\n",
    "                        test_fn[i][test_fn[i].rindex('/')+1:],\n",
    "                        \"\\n\\t\"+str(predict_result),\"% @batch\",high_score_patch,\"in\",str(time_predict),\"seconds\\n\",\n",
    "                        \"----------------------------------------------------\\n\")\n",
    "                \n",
    "            content_str += test_fn[i][test_fn[i].rindex('/')+1:] +'|'+ str(predict_result)  + '\\n'\n",
    "    \n",
    "    end_test = time.time()\n",
    "    time_test = end_test - start_test\n",
    "\n",
    "    f.write(content_str)\n",
    "    f.close()\n",
    "    print(\"\\nDONE\\n\\ttotal of\",str(total_frames_test),\"frames processed in\",time_test,\" seconds\",\n",
    "            \"\\n\\t\"+str(total_frames_test / time_test),\"frames per second\",\n",
    "            \"\\n\\n********************************************************\",\n",
    "            \"\\n\\n********************************************************\")                  \n",
    "\n",
    "    return predict_total\n",
    "\n",
    "def test_model_1V(model):\n",
    "    print(\"\\nTEST MODEL MINI\\n\")\n",
    "    f = open(rslt_path+'/1V/'+model_weight_fn+'_'+str(batch_type)+'.txt', 'w')\n",
    "    content_str = ''\n",
    "    total_frames_test = 0\n",
    "    \n",
    "    predict_total = [] #to output predict in vizualizer accordingly to the each batch prediction\n",
    "    predict_max = 0 #to print the max predict related to the file in test\n",
    "    predict_total_max = [] #to perform the metrics\n",
    "    \n",
    "    start_test = time.time()\n",
    "    for i in range(len(onev_fn)):\n",
    "        if onev_fn[i] != '':\n",
    "            file_path = onev_fn[i]\n",
    "            predict_result = () #to save predictions per file\n",
    "            \n",
    "            #the frist 4000 frames from actual test video                \n",
    "            batch_frames, batch_imgs, divid_no, total_frames,start_frame, fps = input_test_video_data(file_path)\n",
    "            video_time = total_frames/fps\n",
    "            total_frames_test += total_frames\n",
    "            \n",
    "            #prediction on frist batch\n",
    "            start_predict1 = time.time()\n",
    "            predict_aux = model.predict(batch_frames)[0][0]\n",
    "            end_predict1 = time.time()\n",
    "            time_predict = end_predict1-start_predict1\n",
    "            \n",
    "            predict_max = predict_aux\n",
    "            predict_result = (divid_no,start_frame+batch_frames.shape[1],predict_max)\n",
    "            #print(predict_result,batch_frames.shape)\n",
    "            \n",
    "            high_score_patch = 0\n",
    "            print(\"\\t \",predict_max,\"%\") \n",
    "            \n",
    "            #when batch_frames (input video) has > 4000 frames\n",
    "            patch_num = 1\n",
    "            while patch_num < divid_no:\n",
    "                batch_frames, batch_imgs, divid_no, total_frames,start_frame, fps = input_test_video_data(file_path, patch_num)\n",
    "                \n",
    "                #nÃ©simo batch prediction\n",
    "                start_predict2 = time.time()\n",
    "                predict_aux = model.predict(batch_frames)[0][0]\n",
    "                end_predict2 = time.time()\n",
    "                time_predict += end_predict2 - start_predict2\n",
    "\n",
    "                if predict_aux > predict_max:\n",
    "                    predict_max = predict_aux\n",
    "                    high_score_patch = patch_num\n",
    "                \n",
    "                predict_result += (start_frame,start_frame+batch_frames.shape[1], predict_aux)\n",
    "                #print(predict_result,batch_frames.shape)\n",
    "                \n",
    "                print(\"\\t \",predict_aux,\"%\")  \n",
    "                patch_num += 1\n",
    "            \n",
    "            predict_total.append(predict_result)\n",
    "            predict_total_max.append(predict_max)\n",
    "            print(predict_total[i])\n",
    "            \n",
    "            if 'label_A' in onev_fn[i]:\n",
    "                print('\\nNORM',str(i),':',f'{total_frames:.0f}',\"@\",f'{fps:.0f}',\"fps =\",f'{video_time:.2f}',\"sec\\n\\t\",\n",
    "                        onev_fn[i][onev_fn[i].rindex('/')+1:],\n",
    "                        \"\\n\\t \"+str(predict_max),\"% @batch\",high_score_patch,\"in\",str(time_predict),\"seconds\\n\",\n",
    "                        \"----------------------------------------------------\\n\")\n",
    "            else:\n",
    "                print('\\nABNORM',str(i),':',f'{total_frames:.0f}',\"@\",f'{fps:.0f}',\"fps =\",f'{video_time:.2f}',\"sec\\n\\t\",\n",
    "                        onev_fn[i][onev_fn[i].rindex('/')+1:],\n",
    "                        \"\\n\\t\"+str(predict_max),\"% @batch\",high_score_patch,\"in\",str(time_predict),\"seconds\\n\",\n",
    "                        \"----------------------------------------------------\\n\")\n",
    "                \n",
    "            content_str += onev_fn[i][onev_fn[i].rindex('/')+1:] + '|' + str(predict_total_max[i]) + '|' + str(predict_total[i])  + '\\n'\n",
    "            \n",
    "    end_test = time.time()\n",
    "    time_test = end_test - start_test\n",
    "\n",
    "    f.write(content_str)\n",
    "    f.close()\n",
    "    print(\"\\nDONE\\n\\ttotal of\",str(total_frames_test),\"frames processed in\",time_test,\" seconds\",\n",
    "            \"\\n\\t\"+str(total_frames_test / time_test),\"frames per second\",\n",
    "            \"\\n\\n********************************************************\",\n",
    "            \"\\n\\n********************************************************\")                  \n",
    "\n",
    "    return predict_total_max, predict_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" METRICS\n",
    "    https://www.tensorflow.org/tutorials/structured_data/imbalanced_data \"\"\"\n",
    "\n",
    "def plot_cm(name,labels,predictions,p=0.5):\n",
    "    '''\n",
    "    https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#download_the_kaggle_credit_card_fraud_data_set\n",
    "    '''\n",
    "    predictions = np.array(predictions)\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    #plt.clf()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(name+'.png',facecolor='white', transparent=False)\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
    "    \n",
    "    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "    plt.xlim([-0.5,80])\n",
    "    plt.ylim([20,100.5])\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    plt.savefig(name+'.png',facecolor='white', transparent=False)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_prc(name, labels, predictions, **kwargs):\n",
    "    precision, recall, _ = sklearn.metrics.precision_recall_curve(labels, predictions)\n",
    "    #plt.clf()\n",
    "    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('Precision')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlim([-0.5,100.5])\n",
    "    plt.ylim([-0.5,100.5])\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    plt.savefig(name+'.png',facecolor='white', transparent=False)\n",
    "    plt.show()\n",
    "\n",
    "def get_precision_recall_f1(labels, predictions):\n",
    "    p = tf.keras.metrics.Precision(thresholds = 0.5)\n",
    "    p.update_state(labels, predictions)\n",
    "    p_res = p.result().numpy()\n",
    "    print(\"\\tPRECISION (%% of True Positive out of all Positive predicted) \",p_res)\n",
    "    \n",
    "    r = tf.keras.metrics.Recall(thresholds=0.5)\n",
    "    r.update_state(labels, predictions)\n",
    "    r_res = r.result().numpy()\n",
    "    print(\"\\tRECALL (%% of True Positive out of all existing anomalie) \",r_res)\n",
    "    \n",
    "    #https://www.tensorflow.org/addons/api_docs/python/tfa/metrics/F1Score\n",
    "    #f1 = tfa.metrics.F1Score(num_classes=2, threshold=0.5)\n",
    "    #f1.update_state(labels, predictions)\n",
    "    #f1_res = f1.result().numpy()\n",
    "    #print(\"\\tF1_SCORE (harmonic mean of precision and recall) \",f1_res)\n",
    "    \n",
    "    return p_res,r_res#,f1_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' GPU CONFIGURATION\n",
    "    https://www.tensorflow.org/guide/gpu '''\n",
    "\n",
    "def set_tf_loglevel(level):\n",
    "    if level >= logging.FATAL:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "    if level >= logging.ERROR:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    if level >= logging.WARNING:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "    else:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "    logging.getLogger('tensorflow').setLevel(level)\n",
    "\n",
    "set_tf_loglevel(logging.WARNING)\n",
    "\n",
    "#Enabling device placement logging causes any Tensor allocations or operations to be printed.\n",
    "tf.debugging.set_log_device_placement(False) \n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "\n",
    "#https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_memory_growth\n",
    "\n",
    "#if gpus:\n",
    "#    print(\"\\nAvaiable GPU's\",gpus)\n",
    "#    try:\n",
    "#        # Currently, memory growth needs to be the same across GPUs\n",
    "#        for gpu in gpus:\n",
    "#            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#        \n",
    "#        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "#        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#    except RuntimeError as e:\n",
    "#        # Memory growth must be set before GPUs have been initialized\n",
    "#        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TEST ZHEN .h5 WEIGHTS FILES \"\"\"\n",
    "\n",
    "def test_zhen_wghts():\n",
    "    \n",
    "    print(\"\\n\\n\\t\\tBATCH TYPE\",batch_type)\n",
    "        \n",
    "    for i in range(len(weights_fn)):\n",
    "        print(\"\\n\\nLoading weights from\",weights_fn[i],\"\\n\")\n",
    "        model.load_weights(weights_path[i])\n",
    "        model_weight_fn,model_weight_ext = os.path.splitext(str(weights_fn[i]))\n",
    "        \n",
    "        y_test_pred = test_model(model)\n",
    "        \n",
    "        plot_cm(rslt_path+'/orignal_bt/'+model_weight_fn+'_CM'+str(batch_type),y_test_pred)\n",
    "        plot_roc(rslt_path+'/orignal_bt/'+model_weight_fn+'_ROC'+str(batch_type), y_test_labels , y_test_pred, color=colors[0], linestyle='--')\n",
    "        plot_prc(rslt_path+'/orignal_bt/'+model_weight_fn+'_PRC'+str(batch_type), y_test_labels, y_test_pred, color=colors[0])\n",
    "        \n",
    "def get_results_from_txt():\n",
    "    path = rslt_path + '/1V/'\n",
    "    res_txt_fn = []\n",
    "    res_model_fn = []\n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "        fname, fext = os.path.splitext(file)\n",
    "        if fext == \".txt\" and file.find('xdviolence') != -1:\n",
    "            res_txt_fn.append(os.path.join(path, file))\n",
    "            res_model_fn.append(fname)\n",
    "    \n",
    "    res_txt_fn = sorted(res_txt_fn)\n",
    "    res_model_fn = sorted(res_model_fn)\n",
    "    \n",
    "    res_list = [[0 for i in range(len(res_txt_fn))] for j in range(800)]\n",
    "    \n",
    "    for i in range(len(res_txt_fn)):\n",
    "        print('OPENING',res_txt_fn[i])\n",
    "        txt = open(res_txt_fn[i],'r')\n",
    "        txt_data = txt.read()\n",
    "        txt.close()\n",
    "        \n",
    "        txt_list = [line.split() for line in txt_data.split(\"\\n\") if line]\n",
    "        \n",
    "        for j in range(len(txt_list)):\n",
    "            #print(txt_list[j][1],\" \")\n",
    "            res_list[j][i] = float(txt_list[j][1])\n",
    "            \n",
    "    for i in range(len(res_txt_fn)):\n",
    "        print(\"\\nresults for\",res_model_fn[i])\n",
    "            \n",
    "        res_col = [col[i] for col in res_list]\n",
    "        get_recall(res_col)\n",
    "        get_precision(res_col)\n",
    "        \n",
    "    return res_list\n",
    "\n",
    "#model = form_model()\n",
    "#weights_fn, weights_path = find_weights()\n",
    "#test_zhen_wghts()\n",
    "\n",
    "#res_list = get_results_from_txt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FORM_MODEL\n",
      "\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, 120, 160, 3) 0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, None, 118, 158, 4) 220       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, None, 59, 79, 4)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, None, 57, 77, 8)   1160      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, None, 28, 38, 8)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, None, 26, 36, 16)  9232      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, None, 13, 18, 16)  0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (1, None, 3744)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (1, None, 1024)           19533824  \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (1, 1024)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, 128)                  131200    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (1, 1)                    129       \n",
      "=================================================================\n",
      "Total params: 19,675,765\n",
      "Trainable params: 19,675,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1626306295.6228774_2_4_8_xdviolence_model_weights.h5\n",
      "1627900597.7432737_2_4_8_xdviolence_model_weights.h5\n",
      "1626691755.4069657_2_4_8_xdviolence_model_weights.h5\n",
      "1626947956.798592_2_4_8_xdviolence_model_weights.h5\n",
      "1625759299.9331803_2_4_8_xdviolence_model_weights.h5\n",
      "1627553113.262731_2_4_8_xdviolence_model_weights.h5\n",
      "1627169149.3222094_2_4_8_xdviolence_model_weights.h5\n",
      "\n",
      "test_fn (10,) \n",
      "test_normal_fn (0,) \n",
      "test_abnormal_fn (0,)\n",
      "\n",
      "y_test_labels (10,) \n",
      "y_test_norm (0,) \n",
      "y_test_abnor (0,)\n",
      "\n",
      "\n",
      "Loading weights from 1626306295.6228774_2_4_8_xdviolence_model_weights.h5 \n",
      "\n",
      "\n",
      "TEST MODEL MINI\n",
      "\n",
      "\t-batch 0 [ 0 , ... ]  (217, 120, 160, 3)\n",
      "\t  0.963296 %\n",
      "(1, 217, 0.963296)\n",
      "\n",
      "ABNORM 0 : 217 @ 24 fps = 9.04 sec\n",
      "\t The.Bourne.Ultimatum.2007__#01-44-02_01-44-11_label_B2-0-0.mp4 \n",
      "\t0.963296 % @batch 0 in 0.1235196590423584 seconds\n",
      " ----------------------------------------------------\n",
      "\n",
      "\t-batch 0 [ 0 , ... ]  (2186, 120, 160, 3)\n",
      "\t  0.963305 %\n",
      "(1, 2186, 0.963305)\n",
      "\n",
      "ABNORM 1 : 2186 @ 24 fps = 91.08 sec\n",
      "\t v=jYENhkzdpO8__#00-00-00_00-01-31_label_B6-0-0.mp4 \n",
      "\t0.963305 % @batch 0 in 1.6960909366607666 seconds\n",
      " ----------------------------------------------------\n",
      "\n",
      "\t-batch 0 [ 0 , ... ]  (1723, 120, 160, 3)\n",
      "\t  0.9999962 %\n",
      "(1, 1723, 0.9999962)\n",
      "\n",
      "ABNORM 2 : 1723 @ 24 fps = 71.79 sec\n",
      "\t v=YdrISbwy_zI__#1_label_G-0-0.mp4 \n",
      "\t0.9999962 % @batch 0 in 1.016556978225708 seconds\n",
      " ----------------------------------------------------\n",
      "\n",
      "\t-batch 0 [ 0 , ... ]  (1275, 120, 160, 3)\n",
      "\t  0.98813176 %\n",
      "(1, 1275, 0.98813176)\n",
      "\n",
      "ABNORM 3 : 1275 @ 24 fps = 53.12 sec\n",
      "\t v=gENp4SyNxkI__#1_label_B1-0-0.mp4 \n",
      "\t0.98813176 % @batch 0 in 0.7229690551757812 seconds\n",
      " ----------------------------------------------------\n",
      "\n",
      "\t-batch 0 [ 0 , ... ]  (1537, 120, 160, 3)\n",
      "\t  0.05600385 %\n",
      "(1, 1537, 0.05600385)\n",
      "\n",
      "ABNORM 4 : 1537 @ 24 fps = 64.04 sec\n",
      "\t Bullet.in.the.Head.1990__#01-26-30_01-27-34_label_B2-0-0.mp4 \n",
      "\t0.05600385 % @batch 0 in 0.9035205841064453 seconds\n",
      " ----------------------------------------------------\n",
      "\n",
      "\t-batch 0 [ 0 , ... ]  (3577, 120, 160, 3)\n",
      "\t  0.0007910682 %\n",
      "(1, 3577, 0.0007910682)\n",
      "\n",
      "NORM 5 : 3577 @ 24 fps = 149.04 sec\n",
      "\t Be.with.You.2018__#01-14-30_01-16-59_label_A.mp4 \n",
      "\t 0.0007910682 % @batch 0 in 2.5773067474365234 seconds\n",
      " ----------------------------------------------------\n",
      "\n",
      "\t-batch 0 [ 0 , ... ]  (4001, 120, 160, 3)\n",
      "\t  7.071543e-05 %\n",
      "\t-batch 1 [ 1064 , ... ]  (4000, 120, 160, 3)\n",
      "\t  3.4855093e-05 %\n",
      "(2, 4001, 7.071543e-05, 1064, 5064, 3.4855093e-05)\n",
      "\n",
      "NORM 6 : 5064 @ 24 fps = 211.00 sec\n",
      "\t Mission.Impossible.Ghost.Protocol.2011__#01-24-59_01-28-30_label_A.mp4 \n",
      "\t 7.071543e-05 % @batch 0 in 4.024158000946045 seconds\n",
      " ----------------------------------------------------\n",
      "\n",
      "\t-batch 0 [ 0 , ... ]  (3566, 120, 160, 3)\n",
      "\t  0.008191582 %\n",
      "(1, 3566, 0.008191582)\n",
      "\n",
      "NORM 7 : 3566 @ 24 fps = 148.58 sec\n",
      "\t v=3lSHv_DUbJs__#1_label_A.mp4 \n",
      "\t 0.008191582 % @batch 0 in 2.4060397148132324 seconds\n",
      " ----------------------------------------------------\n",
      "\n",
      "\t-batch 0 [ 0 , ... ]  (2807, 120, 160, 3)\n",
      "\t  0.7908965 %\n",
      "(1, 2807, 0.7908965)\n",
      "\n",
      "NORM 8 : 2807 @ 24 fps = 116.96 sec\n",
      "\t v=5NZxPmTpV6Y__#1_label_A.mp4 \n",
      "\t 0.7908965 % @batch 0 in 1.706897258758545 seconds\n",
      " ----------------------------------------------------\n",
      "\n",
      "\t-batch 0 [ 0 , ... ]  (4001, 120, 160, 3)\n",
      "\t  0.0008566211 %\n",
      "\t-batch 1 [ 4000 , ... ]  (4001, 120, 160, 3)\n",
      "\t  0.00017043408 %\n",
      "\t-batch 2 [ 4642 , ... ]  (4000, 120, 160, 3)\n",
      "\t  3.8727376e-05 %\n",
      "(3, 4001, 0.0008566211, 4000, 8001, 0.00017043408, 4642, 8642, 3.8727376e-05)\n",
      "\n",
      "NORM 9 : 8642 @ 24 fps = 360.08 sec\n",
      "\t v=eAgqJnO3kr8__#00-42-00_00-48-00_label_A.mp4 \n",
      "\t 0.0008566211 % @batch 0 in 3.993722915649414 seconds\n",
      " ----------------------------------------------------\n",
      "\n",
      "\n",
      "DONE\n",
      "\ttotal of 30594.0 frames processed in 51.343616247177124  seconds \n",
      "\t595.8676508626729 frames per second \n",
      "\n",
      "******************************************************** \n",
      "\n",
      "********************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPRECISION (%% of True Positive out of all Positive predicted)  0.8\n",
      "\tRECALL (%% of True Positive out of all existing anomalie)  0.8\n"
     ]
    }
   ],
   "source": [
    "\"\"\" test onev \"\"\"\n",
    "model = form_model()\n",
    "weights_fn, weights_path = find_weights()\n",
    "\n",
    "onev_fn, y_onev_labels = test_files(10)\n",
    "\n",
    "# =1 last batch has 4000 frames // =2 last batch has no repetead frames\n",
    "#batch_type = 2\n",
    "\n",
    "'''for i in range(len(weights_fn)):'''\n",
    "for i in range(1):\n",
    "    print(\"\\n\\nLoading weights from\",weights_fn[i],\"\\n\")\n",
    "    model.load_weights(weights_path[i])\n",
    "    model_weight_fn,model_weight_ext = os.path.splitext(str(weights_fn[i]))\n",
    "    \n",
    "    y_test_pred, predict_total = test_model_1V(model)\n",
    "    plot_cm(rslt_path+'/1V/'+model_weight_fn+'_CM'+str(batch_type),y_onev_labels, y_test_pred)\n",
    "    plot_roc(rslt_path+'/1V/'+model_weight_fn+'_ROC'+str(batch_type), y_onev_labels , y_test_pred, color=colors[0], linestyle='--')\n",
    "    plot_prc(rslt_path+'/1V/'+model_weight_fn+'_PRC'+str(batch_type), y_onev_labels, y_test_pred, color=colors[0])\n",
    "    get_precision_recall_f1(y_onev_labels, y_test_pred)\n",
    "    #watch_test(predict_total,onev_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#watch_test(predict_total,onev_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('zhen_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6eb85c0477d574fd6bdabb52dbe9212bb7f487155853edb797b76ac4297f2c9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
