{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf 2.2.0\n",
      "cudatoolkit               10.1.243            h8cb64d8_11    conda-forge\n",
      "cudnn                     7.6.5.32             hc0a50b0_1    conda-forge\n",
      "neptune-tensorflow-keras  2.1.0              pyhd8ed1ab_0    conda-forge\n",
      "numpy                     1.19.5           py38hc896f84_4  \n",
      "numpy-base                1.19.5           py38h21a3de8_4  \n",
      "tensorflow                2.2.0           gpu_py38hb782248_0    anaconda\n",
      "tensorflow-base           2.2.0           gpu_py38h83e3d50_0    anaconda\n",
      "tensorflow-estimator      2.6.0            py38h709712a_0    conda-forge\n",
      "tensorflow-gpu            2.2.0                h0d30ee6_0    anaconda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtstudents/anaconda3/envs/zugpu/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jtstudents/anaconda3/envs/zugpu/lib/python3.8/site-packages/neptune/internal/backends/hosted_client.py:48: NeptuneDeprecationWarning: The 'neptune-client' package has been deprecated and will be removed in the future. Install the 'neptune' package instead. For more, see https://docs.neptune.ai/setup/upgrading/\n",
      "  from neptune.version import version as neptune_client_version\n"
     ]
    }
   ],
   "source": [
    "import os, time, random, logging\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PySimpleGUI as sg\n",
    "from pathlib import Path\n",
    "import csv\n",
    "#import mtcnn\n",
    "\n",
    "#import pandas as pd\n",
    "import tensorflow as tf\n",
    "print(\"tf\",tf.version.VERSION)\n",
    "#os.system(\"cat /usr/local/cuda/version.txt\")\n",
    "#os.system(\"nvcc --version\\n\")\n",
    "os.system(\"conda list | grep -E 'tensorflow|cudnn|cudatoolkit|numpy'\")\n",
    "\n",
    "#from tensorflow import keras\n",
    "#from keras import backend as K\n",
    "\n",
    "#from keras import models, layers, backend as K\n",
    "#from keras.layers import Activation\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#from tensorflow.keras.utils import get_custom_objects\n",
    "#from keras.utils.generic_utils import get_custom_objects\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import neptune\n",
    "from neptune.integrations.tensorflow_keras import NeptuneCallback\n",
    "\n",
    "import utils.auxua as aux\n",
    "import utils.tf_formh5 as tf_formh5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "''' GPU CONFIGURATION '''\n",
    "\n",
    "tf_formh5.set_tf_loglevel(logging.ERROR)\n",
    "tf_formh5.tf.debugging.set_log_device_placement(False) #Enabling device placement logging causes any Tensor allocations or operations to be printed.\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9996/2165384268.py:5: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
      "  run = neptune.init_run( api_token=nept, project=\"vigia/base\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/vigia/base/e/BASE-113\n",
      "https://app.neptune.ai/vigia/base/\n"
     ]
    }
   ],
   "source": [
    "''' NEPTUNE '''\n",
    "#https://docs.neptune.ai/integrations/keras/\n",
    "\n",
    "with open('/raid/DATASETS/.zuble/.nept', 'r') as file:nept = file.read()\n",
    "run = neptune.init_run( api_token=nept, project=\"vigia/base\")\n",
    "project = neptune.init_project(project=\"vigia/base\", api_token=nept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test_fn (800,) \n",
      "test_normal_fn (300,) \n",
      "test_abnormal_fn (500,)\n",
      "\n",
      "test_labels (800,) \n",
      "test_normal_labels (300,) \n",
      "test_abnormal_labels (500,)\n",
      "\n",
      "-------------------\n",
      "\n",
      "full_train_fn (3953,) \n",
      "full_train_normal_fn (2048,) \n",
      "full_train_abnormal (1905,)\n",
      "\n",
      "train_fn (3162,) \n",
      "train_normal_fn (1613,) \n",
      "train_abnormal_fn (1549,)\n",
      "\n",
      "valdt_fn (791,) \n",
      "valdt_normal_fn (435,) \n",
      "valdt_abnormal_fn (356,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\" TEST & TRAIN FILES \"\"\"\n",
    "\n",
    "def test_files(onev = 0):\n",
    "    \"\"\"\n",
    "    GENERATE LIST of train FILES\n",
    "    \"\"\"\n",
    "    test_fn, test_normal_fn, test_abnormal_fn = [],[],[]\n",
    "    test_labels, test_normal_labels, test_abnormal_labels = [],[],[]\n",
    "    \n",
    "    \n",
    "    #makes sure that nept log are clear\n",
    "    try:del run[\"test/data_info\"]\n",
    "    except:run[\"test/data_info\"]\n",
    "\n",
    "    #all test files\n",
    "    if onev == 0:\n",
    "        for root, dirs, files in os.walk(aux.SERVER_TEST_PATH):\n",
    "            for file in files:\n",
    "                if file.find('.mp4') != -1:\n",
    "                    if 'label_A' in file:\n",
    "                        test_normal_fn.append(os.path.join(root, file))\n",
    "                        test_normal_labels.append(0)\n",
    "                        run[\"test/data_info/test_normal\"].append(str((file,0)))\n",
    "                    else:\n",
    "                        test_abnormal_fn.append(os.path.join(root, file))\n",
    "                        test_abnormal_labels.append(1)    \n",
    "                        run[\"test/data_info/test_abnormal\"].append(str((file,1)))          \n",
    "\n",
    "        test_labels = test_normal_labels + test_abnormal_labels                \n",
    "        test_fn = test_normal_fn + test_abnormal_fn\n",
    "        for i in range(len(test_fn)): run[\"test/data_info/test\"].append(test_fn[i])\n",
    "        \n",
    "    #only onev random files\n",
    "    else :\n",
    "        test_abn_fn = [x for x in os.listdir(aux.SERVER_TEST_PATH) if 'label_A' not in x]\n",
    "        test_nor_fn = [x for x in os.listdir(aux.SERVER_TEST_PATH) if 'label_A' in x]\n",
    "        \n",
    "        onev_abnor = int(onev/2)\n",
    "        while True: \n",
    "            ap = random.choice(test_abn_fn) \n",
    "            if ap not in test_fn: \n",
    "                test_fn.append(aux.SERVER_TEST_PATH+\"/\"+ap)\n",
    "                test_labels.append(1)\n",
    "                if len(test_fn) == onev_abnor: \n",
    "                    break \n",
    "        while True: \n",
    "            ap = random.choice(test_nor_fn) \n",
    "            if ap not in test_fn: \n",
    "                test_fn.append(aux.SERVER_TEST_PATH+\"/\"+ap)\n",
    "                test_labels.append(0)\n",
    "                if len(test_fn) == onev: \n",
    "                    break    \n",
    "    \n",
    "    \n",
    "    run[\"test/data_info/test_shape\"] = \"total_fn \"+str(np.shape(test_fn)[0])+\"\\ntotal_labels \"+str(np.shape(test_labels)[0])+\\\n",
    "                                        \"\\nnormal_fn \"+str(np.shape(test_normal_fn)[0])+\"\\nnormal_labels \"+str(np.shape(test_normal_labels)[0])+\\\n",
    "                                        \"\\nabnormal_fn \"+str(np.shape(test_abnormal_fn)[0])+\"\\nabnormal_labels \"+str(np.shape(test_abnormal_labels)[0])\n",
    "    \n",
    "    print(\"\\ntest_fn\",np.shape(test_fn),\"\\ntest_normal_fn\",np.shape(test_normal_fn),\"\\ntest_abnormal_fn\",np.shape(test_abnormal_fn))\n",
    "    print(\"\\ntest_labels\",np.shape(test_labels),\"\\ntest_normal_labels\",np.shape(test_normal_labels),\"\\ntest_abnormal_labels\",np.shape(test_abnormal_labels))\n",
    "    print('\\n-------------------')\n",
    "    return test_fn , test_normal_fn , test_abnormal_fn , test_labels \n",
    "\n",
    "def train_valdt_files():\n",
    "    \"\"\"\n",
    "    GENERATING LIST of TRAIN FILES\n",
    "    \"\"\"\n",
    "    full_train_fn, full_train_normal_fn, full_train_abnormal_fn = [],[],[]\n",
    "    full_train_labels, full_train_normal_labels, full_train_abnormal_labels = [],[],[]\n",
    "\n",
    "    #makes sure that neptlog are clear\n",
    "    try:del run[\"train/data_info\"]\n",
    "    except:run[\"train/data_info\"]\n",
    "\n",
    "    for root, dirs, files in os.walk(aux.SERVER_TRAIN_PATH):\n",
    "        for file in files:\n",
    "            if file.find('.mp4') != -1:\n",
    "                full_train_fn.append(os.path.join(root, file))\n",
    "                run[\"train/data_info/full_train\"].append(file)\n",
    "\n",
    "                if 'label_A' in file:\n",
    "                    full_train_normal_fn.append(os.path.join(root, file))\n",
    "                    full_train_normal_labels.append(0)\n",
    "                    run[\"train/data_info/full_train_normal\"].append(str((file,0)))\n",
    "\n",
    "                else:\n",
    "                    full_train_abnormal_fn.append(os.path.join(root, file))\n",
    "                    full_train_abnormal_labels.append(1)\n",
    "                    run[\"train/data_info/full_train_abnormal\"].append(str((file,1)))\n",
    "    #BEFORE SPLIT INTO TRAIN+VALD\n",
    "    run[\"train/data_info/full_train_shape\"] = str(\"total \"+str(np.shape(full_train_fn)[0])+\"\\nabnormal \"+str(np.shape(full_train_abnormal_fn)[0])+\"\\nnormal \"+str(np.shape(full_train_normal_fn)[0]))\n",
    "    print(\"\\nfull_train_fn\",np.shape(full_train_fn),\"\\nfull_train_normal_fn\",np.shape(full_train_normal_fn),\"\\nfull_train_abnormal\",np.shape(full_train_abnormal_fn))\n",
    "    \n",
    "\n",
    "    #AFTER SPLIT\n",
    "    valdt_fn, valdt_normal_fn, valdt_abnormal_fn = [],[],[]\n",
    "    valdt_labels, valdt_normal_labels, valdt_abnormal_labels = [],[],[]\n",
    "\n",
    "    train_fn, train_normal_fn, train_abnormal_fn = [],[],[]\n",
    "    train_labels, train_normal_labels, train_abnormal_labels = [],[],[]\n",
    "\n",
    "    train_fn, valdt_fn = train_test_split(full_train_fn, test_size=0.2,shuffle=False)\n",
    "    for i in range(len(train_fn)):\n",
    "        if 'label_A' in train_fn[i]:train_normal_fn.append(train_fn[i]);train_normal_labels.append(0);train_labels.append(0)\n",
    "        else: train_abnormal_fn.append(train_fn[i]);train_abnormal_labels.append(1);train_labels.append(1)\n",
    "    \n",
    "    run[\"train/data_info/train_shape\"] = str(\"total \"+str(np.shape(train_fn)[0])+\"\\nabnormal \"+str(np.shape(train_abnormal_fn)[0])+\"\\nnormal \"+str(np.shape(train_normal_fn)[0]))\n",
    "    print(\"\\ntrain_fn\",np.shape(train_fn),\"\\ntrain_normal_fn\",np.shape(train_normal_fn),\"\\ntrain_abnormal_fn\",np.shape(train_abnormal_fn))\n",
    "    \n",
    "    \n",
    "    for i in range(len(valdt_fn)):\n",
    "        if 'label_A' in valdt_fn[i]:valdt_normal_fn.append(valdt_fn[i]);valdt_normal_labels.append(0);valdt_labels.append(0)\n",
    "        else: valdt_abnormal_fn.append(valdt_fn[i]);valdt_abnormal_labels.append(1);valdt_labels.append(1)   \n",
    "    \n",
    "    run[\"train/data_info/valdt_shape\"] = str(\"total \"+str(np.shape(valdt_fn)[0])+\"\\nabnormal \"+str(np.shape(valdt_abnormal_fn)[0])+\"\\nnormal \"+str(np.shape(valdt_normal_fn)[0]))\n",
    "    print(\"\\nvaldt_fn\",np.shape(valdt_fn),\"\\nvaldt_normal_fn\",np.shape(valdt_normal_fn),\"\\nvaldt_abnormal_fn\",np.shape(valdt_abnormal_fn))\n",
    "\n",
    "    return train_fn, train_labels, valdt_fn, valdt_labels\n",
    "\n",
    "def nept_load_dataset():\n",
    "    \n",
    "    #run[\"dataset/train\"].track_files(aux.SERVER_TRAIN_PATH,wait=True)\n",
    "    \n",
    "    \n",
    "    del project[\"dataset\"]\n",
    "    \n",
    "    for i in range(len(train_normal_fn)): project[\"dataset/train_normal/\"+os.path.basename(train_normal_fn[i])].upload(train_normal_fn[i])\n",
    "    for i in range(len(train_abnormal_fn)): project[\"dataset/train_abnormal/\"+os.path.basename(train_normal_fn[i])].upload(train_abnormal_fn[i])\n",
    "    \n",
    "    for i in range(len(test_normal_fn)): project[\"dataset/test_normal/\"+os.path.basename(train_normal_fn[i])].upload(test_normal_fn[i])\n",
    "    for i in range(len(test_abnormal_fn)): project[\"dataset/test_abnormal/\"+os.path.basename(train_normal_fn[i])].upload(test_abnormal_fn[i])\n",
    "    \n",
    "\n",
    "test_fn , test_abnormal_fn , test_normal_fn , test_labels = test_files()\n",
    "train_fn, train_labels, valdt_fn, valdt_labels = train_valdt_files()\n",
    "\n",
    "update_index_train = range(0, len(train_fn))\n",
    "update_index_valdt = range(0, len(valdt_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" INPUT DATA\"\"\"\n",
    "\n",
    "in_height = 120; in_width = 160\n",
    "\n",
    "def input_train_video_data(file_name):\n",
    "    print(\"\\n\\ninput_train_video_data\\n\")\n",
    "    #file_name = 'C:\\\\Bosch\\\\Anomaly\\\\training\\\\videos\\\\13_007.avi'\n",
    "    #file_name = '/raid/DATASETS/anomaly/UCF_Crimes/Videos/Training_Normal_Videos_Anomaly/Normal_Videos308_x264.mp4'\n",
    "    video = cv2.VideoCapture(file_name)\n",
    "    total_frame = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    #mtcnn_detector = mtcnn.mtcnn.MTCNN()\n",
    "    #print(file_name + '  ' + str(total_frame))\n",
    "    divid_no = 1\n",
    "    \n",
    "    frame_max = train_config[\"frame_max\"]\n",
    "    \n",
    "    # define the nmbers of batchs to divid atual video (divid_no)\n",
    "    if total_frame > int(frame_max):\n",
    "        total_frame_int = int(total_frame)\n",
    "        if total_frame_int % int(frame_max) == 0:\n",
    "            divid_no = int(total_frame / int(frame_max))\n",
    "        else:\n",
    "            divid_no = int(total_frame / int(frame_max)) + 1\n",
    "        \n",
    "    batch_no = 0\n",
    "    batch_frames = []\n",
    "    batch_frames_flip = []\n",
    "    counter = 0\n",
    "    \n",
    "    # gets random batch w\\ frame max lenght \n",
    "    if 'Normal' in file_name:\n",
    "        print(\"\\n\\nNORMAL\\n\\n\")\n",
    "        if divid_no != 1:\n",
    "            slice_no = int(random.random()*divid_no)\n",
    "            passby = 0\n",
    "            if slice_no != divid_no - 1:\n",
    "                while video.isOpened and passby < int(frame_max) * slice_no:\n",
    "                    passby += 1\n",
    "                    success, image = video.read()\n",
    "                    if success == False:\n",
    "                        break\n",
    "            else:\n",
    "                while video.isOpened and passby < total_frame - int(frame_max):\n",
    "                    passby += 1\n",
    "                    success, image = video.read()\n",
    "                    if success == False:\n",
    "                        break\n",
    "\n",
    "    while video.isOpened:               \n",
    "        success, image = video.read()\n",
    "        if success == False:\n",
    "            break\n",
    "            \n",
    "        #ratio = image.shape[0] / image.shape[1]\n",
    "        #print(str(image.shape[0])+ ' ' + str(image.shape[1]))\n",
    "        #image = cv2.resize(image, (800, int(800*ratio)))\n",
    "        #print(image.shape)\n",
    "        #faces = face_detector.detectMultiScale(image,1.1,8)\n",
    "        '''\n",
    "        faces = mtcnn_detector.detect_faces(image)\n",
    "        \n",
    "        for face in faces:\n",
    "            (x,y,w,h) = face['box']\n",
    "            #print(face)\n",
    "            cv2.rectangle(image,(x,y), (x+w,y+h), (255,255,0), 2)\n",
    "            cv2.putText(image, str(face['confidence'])[:4], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (36,255,12), 1)\n",
    "        '''\n",
    "        image = cv2.resize(image, (in_width, in_height))\n",
    "        image_flip = cv2.flip(image, 1)\n",
    "        \n",
    "        image_array = np.array(image)/255.0\n",
    "        image_array_flip = np.array(image_flip)/255.0\n",
    "        \n",
    "        batch_frames.append(image_array)\n",
    "        batch_frames_flip.append(image_array_flip)\n",
    "        \n",
    "        counter += 1\n",
    "        if counter > int(frame_max):\n",
    "            break\n",
    "            \n",
    "    video.release()\n",
    "    batch_frames = np.array(batch_frames)\n",
    "    #print(batch_frames.shape)\n",
    "        \n",
    "    return np.expand_dims(batch_frames,0), np.expand_dims(batch_frames_flip, 0), total_frame\n",
    "\n",
    "def generate_input(data,update_index,validation):\n",
    "    #has_visited = [0 for i in range(len(train_fn))]\n",
    "    data_var_name = [k for k, v in globals().items() if v is data][0]\n",
    "    print(\"\\n\\nGENERATE_INPUT FOR\",data_var_name,\\\n",
    "        '\\n\\tupdate_index len = ',len(update_index),\\\n",
    "        '\\n\\tdata len = ',len(data))\n",
    "    \n",
    "    loop_no = 0\n",
    "    while 1:\n",
    "        index = update_index[loop_no]\n",
    "        loop_no += 1\n",
    "        print(\"\\n\",data_var_name,\" index\",index,\" loop_no\",loop_no)\n",
    "        if loop_no == len(data):loop_no= 0\n",
    "        \n",
    "        #index = 0\n",
    "        batch_frames, batch_frames_flip, total_frames = input_train_video_data(data[index])\n",
    "        print(\"\\n\\t\",data_var_name,\"data[\",index,\"]=\",data[index],\"\\n\\ttotal_frames=\",total_frames,\"\\n\\tbatch_frames.shape=\",batch_frames.shape,\"\\n\")\n",
    "        #if batch_frames.ndim != 5:\n",
    "        #   break\n",
    "        \n",
    "        # GENERATORS    \n",
    "        #       a kind of iterators that can only iterate over once\n",
    "        #       NO store of values in memory\n",
    "        # YIELD \n",
    "        #       like a return, except the function will return a generator\n",
    "        \n",
    "        if not validation:\n",
    "            #batch_frames\n",
    "            if 'label_A' in data[index]: yield batch_frames, np.array([0])   #normal\n",
    "            else: yield batch_frames, np.array([1])   #abnormal\n",
    "            \n",
    "            #batch_frames_flip\n",
    "            if 'label_A' in data[index]: yield batch_frames_flip, np.array([0])  #normal\n",
    "            else: yield batch_frames_flip, np.array([1])  #abnormal\n",
    "        else:\n",
    "            #batch_frames\n",
    "            if 'label_A' in data[index]: yield batch_frames, np.array([0])   #normal\n",
    "            else: yield batch_frames, np.array([1])   #abnormal\n",
    "                \n",
    "    print(\"\\nloop_no=\",loop_no)\n",
    "\n",
    "\n",
    "def input_test_video_data(file_name,config,batch_no=0):\n",
    "    #file_name = 'C:\\\\Bosch\\\\Anomaly\\\\training\\\\videos\\\\13_007.avi'\n",
    "    #file_name = '/raid/DATASETS/anomaly/UCF_Crimes/Videos/Training_Normal_Videos_Anomaly/Normal_Videos308_x264.mp4'\n",
    "    video = cv2.VideoCapture(file_name)\n",
    "    total_frame = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    #mtcnn_detector = mtcnn.mtcnn.MTCNN()\n",
    "    divid_no = 1\n",
    "    frame_max = config[\"frame_max\"]\n",
    "    batch_type = config[\"batch_type\"]\n",
    "    \n",
    "    # define the nmbers of batchs to divid atual video (divid_no)\n",
    "    if total_frame > int(frame_max):\n",
    "        total_frame_int = int(total_frame)\n",
    "        if total_frame_int % int(frame_max) == 0:\n",
    "            divid_no = int(total_frame / int(frame_max))\n",
    "        else:\n",
    "            divid_no = int(total_frame / int(frame_max)) + 1\n",
    "\n",
    "\n",
    "    #updates the start frame to 0,frame_max*1,frame_max*2... excluding the last batch\n",
    "    passby = 0\n",
    "    if batch_no != divid_no - 1:\n",
    "        while video.isOpened and passby < int(frame_max) * batch_no:\n",
    "            passby += 1\n",
    "            success, image = video.read()\n",
    "            if success == False:\n",
    "                break\n",
    "            \n",
    "    #updates the last batch starting frame \n",
    "    else:\n",
    "        if batch_type==1:\n",
    "            #print(\"1\")\n",
    "            while video.isOpened and passby < total_frame - int(frame_max):\n",
    "                passby += 1\n",
    "                success, image = video.read()\n",
    "                if success == False:\n",
    "                    break\n",
    "        #last batch must have >= frame_max/10 otherwise it falls back to batch_type 1\n",
    "        if batch_type==2 and total_frame - (int(frame_max) * batch_no) >= int(frame_max)*0.1:\n",
    "            #print(\"2\")\n",
    "            while video.isOpened and passby < int(frame_max) * batch_no:\n",
    "                passby += 1\n",
    "                success, image = video.read()\n",
    "                if success == False:\n",
    "                    break\n",
    "        else:\n",
    "            while video.isOpened and passby < total_frame - int(frame_max):\n",
    "                passby += 1\n",
    "                success, image = video.read()\n",
    "                if success == False:\n",
    "                    break\n",
    "\n",
    "            \n",
    "    batch_frames, batch_imgs = [], []\n",
    "    counter = 0\n",
    "    \n",
    "    while video.isOpened:               \n",
    "        success, image = video.read()\n",
    "        if success == False:\n",
    "            break\n",
    "        batch_imgs.append(image)\n",
    "        \n",
    "        image_rsz = cv2.resize(image, (in_width, in_height))\n",
    "        image_array = np.array(image_rsz)/255.0 #normalize\n",
    "        batch_frames.append(image_array)\n",
    "        \n",
    "        counter += 1\n",
    "        if counter > int(frame_max):\n",
    "            break\n",
    "            \n",
    "    video.release()\n",
    "    \n",
    "    #batch_frames_tensor = tf.convert_to_tensor(batch_frames)\n",
    "    ##print(\"\\tshap tensor\",tf.shape( tf.expand_dims(batch_frames_tensor,0) ) )\n",
    "    #print(\"\\t-batch\",batch_no,\"[\",passby,\", ... ] \", batch_frames_tensor.get_shape().as_list() )    \n",
    "\n",
    "    batch_frames = np.array(batch_frames)\n",
    "    #print(\"\\tshap NP ARRAY\",np.shape( np.expand_dims(batch_frames,0) ))\n",
    "    print(\"\\t-batch\",batch_no,\"[\",passby,\", ... ] \",batch_frames.shape)    \n",
    "\n",
    "    #return tf.expand_dims(batch_frames_tensor,0), batch_imgs, divid_no, total_frame, passby, fps\n",
    "    return np.expand_dims(batch_frames,0), batch_imgs, divid_no, total_frame, passby, fps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TRAIN FX '''\n",
    "\n",
    "def train_model(model,config,ckptgui=False):\n",
    "    '''\n",
    "    MODEL TRAIN/VALIDATION \n",
    "    (silent mode - verbose = 0)\n",
    "    '''\n",
    "    print(\"\\nTRAIN MODEL\")\n",
    "    \n",
    "    #start from ckpt .h5\n",
    "    if int(config[\"ckpt_start\"]):  #aux = f\"{34:0>8}\"; if int(aux): print(type(aux), aux)\n",
    "        if ckptgui:\n",
    "            model_h5ckpt, model_h5ckpt_path = tf_formh5.find_h5(aux.CKPT_PATH,find_string=(),ruii=True)\n",
    "            model_h5ckpt = os.path.splitext(model_h5ckpt)[0]\n",
    "            model.load_weights(model_h5ckpt_path)\n",
    "        else:\n",
    "            find_string=[config[\"ativa\"]+'_'+config[\"optima\"]+'_'+str(config[\"batch_type\"])+'_'+config[\"frame_max\"],config[\"ckpt_start\"]]\n",
    "            model_h5ckpt, model_h5ckpt_path = tf_formh5.find_h5(aux.CKPT_PATH,find_string,ruii=False)\n",
    "\n",
    "            model.load_weights(model_h5ckpt_path[0])\n",
    "            print(\"\\n\\tWEIGHTS from ckpt\", '/'+os.path.split(os.path.split(model_h5ckpt_path[0])[0])[1]+'/'+os.path.split(model_h5ckpt_path[0])[1])\n",
    "            \n",
    "        model_name = model_h5ckpt[0]\n",
    "        run[\"train/model_name\"] = model_name\n",
    "        \n",
    "        # ckeck if its necessary to create a ckpt folder , else check is empty\n",
    "        ckpt_path_nw = aux.CKPT_PATH+model_name\n",
    "        if os.path.exists(ckpt_path_nw):\n",
    "            if len(os.listdir(ckpt_path_nw)) == 0:print(\"\\n\\tCKPTs at \",ckpt_path_nw)\n",
    "            else: raise Exception(f\"{ckpt_path_nw} is not empty\")\n",
    "        else:os.makedirs(ckpt_path_nw);print(\"\\n\\tCKPTs created at \",ckpt_path_nw)\n",
    "        \n",
    "        run[\"train/path_ckpt\"] = ckpt_path_nw\n",
    "        checkpoint_callback = ModelCheckpoint(filepath=ckpt_path_nw+'/'+model_name+'-{epoch:08d}.h5') #https://keras.io/api/callbacks/model_checkpoint/\n",
    "\n",
    "    #start from zero\n",
    "    else:\n",
    "        time_str = str(time.time()); \n",
    "        model_name = time_str + '_'+config[\"ativa\"]+'_'+config[\"optima\"]+'_'+str(config[\"batch_type\"])+'_'+config[\"frame_max\"]\n",
    "        run[\"train/model_name\"] = model_name\n",
    "\n",
    "        ckpt_path_nw = aux.CKPT_PATH+model_name\n",
    "        if not os.path.exists(ckpt_path_nw):\n",
    "            os.makedirs(ckpt_path_nw)\n",
    "        else:raise Exception(f\"{ckpt_path_nw} eristes\")\n",
    "        \n",
    "        checkpoint_callback = ModelCheckpoint(filepath=ckpt_path_nw+'/'+model_name+'_ckpt-{epoch:08d}.h5') #https://keras.io/api/callbacks/model_checkpoint/\n",
    "        \n",
    "        print(\"\\n\\tCKPTs at \",ckpt_path_nw)\n",
    "        run[\"train/path_ckpt\"] = ckpt_path_nw\n",
    "        \n",
    " \n",
    "    print(\"\\n\\tMODEL.FIT w/ name \",model_name)\n",
    "    #early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n",
    "    neptune_callback = NeptuneCallback(run=run,log_on_batch=True,log_model_diagram=True) \n",
    "    history = model.fit(generate_input(data = train_fn,update_index=update_index_train,validation=False), \n",
    "                        steps_per_epoch=len(train_fn)*2,\n",
    "                        epochs=config[\"epochs\"], \n",
    "                        verbose=2,\n",
    "                        validation_data=generate_input(data=valdt_fn,update_index=update_index_valdt,validation=True),\n",
    "                        validation_steps=len(valdt_fn),\n",
    "                        callbacks=[checkpoint_callback,  \\\n",
    "                                   #early_stop_callback, \\\n",
    "                                   TqdmCallback(verbose=0), \\\n",
    "                                   neptune_callback])\n",
    "    \n",
    "    model.save(aux.MODEL_PATH + model_name + '.h5')\n",
    "    model.save(aux.MODEL_PATH + model_name )\n",
    "    run[\"train/path_model\"]=aux.MODEL_PATH+model_name\n",
    "\n",
    "    model.save_weights(aux.WEIGHTS_PATH + model_name + '_weights.h5')\n",
    "    run[\"train/path_weights\"]=aux.WEIGHTS_PATH+model_name+'_weights.h5' \n",
    "    \n",
    "    # Save the history to a CSV file\n",
    "    hist_csv_file = aux.HIST_PATH + model_name + '_history.csv'\n",
    "    with open(hist_csv_file, 'w', newline='') as file:writer = csv.writer(file);writer.writerow(history.history.keys());writer.writerows(zip(*history.history.values()))\n",
    "    # OR\n",
    "    #hist_df = pd.DataFrame(history.history)\n",
    "    #with open(hist_csv_file, mode = 'w') as f:hist_df.to_csv(f)\n",
    "    \n",
    "    run[\"train/model_hist_csv_file\"].upload(hist_csv_file)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TEST FX '''\n",
    "#@tf.function\n",
    "#def predict(model,input):\n",
    "#    return model.predict(input)#.eval()[0][0]\n",
    "\n",
    "def test_model(model,model_name,config,files=test_fn):\n",
    "    print(\"\\n\\nTEST MODEL\\n\")\n",
    "\n",
    "    # rslt txt file creation\n",
    "    txt_path = aux.RSLT_PATH+model_name+'-'+str(config[\"batch_type\"])+'_'+str(config[\"frame_max\"])+'.txt'\n",
    "    if os.path.isfile(txt_path):raise Exception(txt_path,\"eriste\")\n",
    "    else: print(\"\\tSaving @\",txt_path,\"\\n\");run[\"test/path_rslt\"] = txt_path\n",
    "    \n",
    "    f = open(txt_path, 'w')\n",
    "    \n",
    "    content_str = ''\n",
    "    total_frames_test = 0\n",
    "    \n",
    "    predict_total = [] #to output predict in vizualizer accordingly to the each batch prediction\n",
    "    predict_max = 0     #to print the max predict related to the file in test\n",
    "    predict_total_max = [] #to perform the metrics\n",
    "    \n",
    "    start_test = time.time()\n",
    "    for i in range(len(files)):\n",
    "        if files[i] != '':\n",
    "            file_path = files[i]\n",
    "            predict_result = () #to save predictions per file\n",
    "            time_batch_predict = time_video_predict = 0.0\n",
    "\n",
    "            #the frist 4000 frames from actual test video                \n",
    "            batch_frames, batch_imgs, divid_no, total_frames,start_frame, fps = input_test_video_data(file_path,config)\n",
    "            video_time = total_frames/fps\n",
    "            total_frames_test += total_frames\n",
    "            \n",
    "            #prediction on frist batch\n",
    "            start_predict1 = time.time()\n",
    "            predict_aux = model.predict(batch_frames)[0][0]\n",
    "            #predict_aux = predict(model,batch_frames) #using tf.function\n",
    "            #predict_aux = model(batch_frames,training=False)[0][0]\n",
    "            end_predict1 = time.time()\n",
    "            time_video_predict = time_batch_predict = end_predict1-start_predict1\n",
    "            \n",
    "            predict_max = predict_aux\n",
    "            predict_result = (divid_no,start_frame+batch_frames.shape[1],predict_max)\n",
    "            #print(predict_result,batch_frames.shape)\n",
    "            \n",
    "            high_score_patch = 0\n",
    "            print(\"\\t \",predict_max,\"%\",\" in \",\"{:.4f}\".format(time_batch_predict),\" secs\")\n",
    "            \n",
    "            #when batch_frames (input video) has > frame_max frames\n",
    "            patch_num = 1\n",
    "            while patch_num < divid_no:\n",
    "                batch_frames, batch_imgs, divid_no, total_frames,start_frame, fps = input_test_video_data(file_path,config,patch_num)\n",
    "                \n",
    "                #nésimo batch prediction\n",
    "                start_predict2 = time.time()\n",
    "                predict_aux = model.predict(batch_frames)[0][0]\n",
    "                #predict_aux = predict(model,batch_frames) #using tf.function\n",
    "                end_predict2 = time.time()\n",
    "                time_batch_predict = end_predict2 - start_predict2\n",
    "                time_video_predict += time_batch_predict\n",
    "\n",
    "                if predict_aux > predict_max:\n",
    "                    predict_max = predict_aux\n",
    "                    high_score_patch = patch_num\n",
    "                \n",
    "                predict_result += (start_frame,start_frame+batch_frames.shape[1], predict_aux)\n",
    "                #print(predict_result)\n",
    "                \n",
    "                print(\"\\t \",predict_aux,\"%\",\" in \",\"{:.4f}\".format(time_batch_predict),\" secs\")  \n",
    "                patch_num += 1\n",
    "            \n",
    "            predict_total.append(predict_result)\n",
    "            predict_total_max.append(predict_max)\n",
    "            print(\"\\n\\t\",predict_total[i])\n",
    "            \n",
    "            if 'label_A' in files[i]:\n",
    "                print('\\nNORM',str(i),':',f'{total_frames:.0f}',\"@\",f'{fps:.0f}',\"fps =\",f'{video_time:.2f}',\"sec\\n\\t\",\n",
    "                        files[i][files[i].rindex('/')+1:],\n",
    "                        \"\\n\\t \"+str(predict_max),\"% @batch\",high_score_patch,\"in\",str(time_video_predict),\"seconds\\n\",\n",
    "                        \"----------------------------------------------------\\n\")\n",
    "            else:\n",
    "                print('\\nABNORM',str(i),':',f'{total_frames:.0f}',\"@\",f'{fps:.0f}',\"fps =\",f'{video_time:.2f}',\"sec\\n\\t\",\n",
    "                        files[i][files[i].rindex('/')+1:],\n",
    "                        \"\\n\\t\"+str(predict_max),\"% @batch\",high_score_patch,\"in\",str(time_video_predict),\"seconds\\n\",\n",
    "                        \"----------------------------------------------------\\n\")\n",
    "                \n",
    "            content_str += files[i][files[i].rindex('/')+1:] + '|' + str(predict_total_max[i]) + '|' + str(predict_total[i])  + '\\n'\n",
    "            \n",
    "    end_test = time.time()\n",
    "    time_test = end_test - start_test\n",
    "\n",
    "    f.write(content_str)\n",
    "    f.close()\n",
    "    print(\"\\nDONE\\n\\ttotal of\",str(total_frames_test),\"frames processed in\",time_test,\" seconds\",\n",
    "            \"\\n\\t\"+str(total_frames_test / time_test),\"frames per second\",\n",
    "            \"\\n\\n********************************************************\",\n",
    "            \"\\n\\n********************************************************\")                  \n",
    "\n",
    "    #remove white spaces in file , for further easier reading\n",
    "    with open(txt_path, 'r+') as f:txt=f.read().replace(' ', '');f.seek(0);f.write(txt);f.truncate()\n",
    "    aux.sort_files(txt_path) #sort alphabetcly\n",
    "    run[\"test/model/rslt\"].upload(txt_path)\n",
    "    \n",
    "    return predict_total_max, predict_total\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''INIT TRAIN MODEL'''\n",
    "\n",
    "train_config = {\n",
    "    \"ativa\" : 'leakyrelu',\n",
    "    \"optima\" : 'adamamsgrad',\n",
    "    \"batch_type\" : 0,   # =0 all batch have frame_max or video length // =1 last batch has frame_max frames // =2 last batch has no repetead frames\n",
    "    \"frame_max\" : '4000',\n",
    "    \"ckpt_start\" : f\"{9:0>8}\",  #used in train_model: if 00000000 start from scratch, else start from ckpt with config stated\n",
    "    \"epochs\" : 21\n",
    "}\n",
    "#run[\"train/config_train\"].append(train_config)\n",
    "\n",
    "#model = tf_formh5.form_model(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' TRAIN '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" TRAIN \"\"\"\n",
    "\n",
    "#model = train_model(model,train_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FORM_MODEL\n",
      "\n",
      "\n",
      "\t {'ativa': 'leakyrelu', 'optima': 'adamamsgrad', 'batch_type': 0, 'frame_max': '4000'} \n",
      "\n",
      "\tOPTIMA <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fc1125294c0> \n",
      "\tATIVA <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7fc1124c0a90>\n",
      "\n",
      "\tWEIGHTS from  /weights/1679349568.3157873_leakyrelu_adamamsgrad_0_4000_weights.h5\n"
     ]
    }
   ],
   "source": [
    "''' INIT TEST MODEL '''\n",
    "\n",
    "wght4test_config = {\n",
    "    \"ativa\" : 'leakyrelu',\n",
    "    \"optima\" : 'adamamsgrad',\n",
    "    \"batch_type\" : 0, # =0 all batch have frame_max or video length // =1 last batch has frame_max frames // =2 last batch has no repetead frames\n",
    "    \"frame_max\" : '4000'\n",
    "}\n",
    "\n",
    "#run[\"test/config_wght4test\"].append(wght4test_config)\n",
    "\n",
    "model, model_name = tf_formh5.init_test_model(wght4test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TEST MODEL\n",
      "\n",
      "\tSaving @ /raid/DATASETS/.zuble/vigia/zu++/model/rslt/1679349568.3157873_leakyrelu_adamamsgrad_0_4000_weights-2_240.txt \n",
      "\n",
      "\t-batch 0 [ 0 , ... ]  (241, 120, 160, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 17:14:10.380209: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-03-27 17:14:10.388834: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv3d/Conv3D (defined at tmp/ipykernel_9996/1024949257.py:37) ]] [Op:__inference_predict_function_1349]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m test_config \u001b[39m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbatch_type\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39m2\u001b[39m, \u001b[39m# =0 all batch have frame_max or video length // =1 last batch has frame_max frames // =2 last batch has no repetead frames\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mframe_max\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39m'\u001b[39m\u001b[39m240\u001b[39m\u001b[39m'\u001b[39m \n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      7\u001b[0m \u001b[39m#run[\"test/config_test\"].append(test_config)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m predict_total_max, predict_total \u001b[39m=\u001b[39m test_model(model,model_name,test_config)\n",
      "Cell \u001b[0;32mIn[7], line 37\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model, model_name, config, files)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m#prediction on frist batch\u001b[39;00m\n\u001b[1;32m     36\u001b[0m start_predict1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 37\u001b[0m predict_aux \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(batch_frames)[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m     38\u001b[0m \u001b[39m#predict_aux = predict(model,batch_frames) #using tf.function\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m#predict_aux = model(batch_frames,training=False)[0][0]\u001b[39;00m\n\u001b[1;32m     40\u001b[0m end_predict1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:88\u001b[0m, in \u001b[0;36mdisable_multi_worker.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_multi_worker_mode():  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     86\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m is not supported in multi-worker mode.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     87\u001b[0m       method\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n\u001b[0;32m---> 88\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1268\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   1267\u001b[0m   callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 1268\u001b[0m   tmp_batch_outputs \u001b[39m=\u001b[39m predict_function(iterator)\n\u001b[1;32m   1269\u001b[0m   \u001b[39m# Catch OutOfRangeError for Datasets of unknown size.\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m   \u001b[39m# This blocks until the batch has finished executing.\u001b[39;00m\n\u001b[1;32m   1271\u001b[0m   \u001b[39m# TODO(b/150292341): Allow multiple async steps here.\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data_handler\u001b[39m.\u001b[39minferred_steps:\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:580\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     xla_context\u001b[39m.\u001b[39mExit()\n\u001b[1;32m    579\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 580\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    582\u001b[0m \u001b[39mif\u001b[39;00m tracing_count \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tracing_count():\n\u001b[1;32m    583\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_counter\u001b[39m.\u001b[39mcalled_without_tracing()\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:618\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    616\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    619\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    620\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    621\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2420\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2419\u001b[0m   graph_function, args, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2420\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_filtered_call(args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1661\u001b[0m, in \u001b[0;36mConcreteFunction._filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_filtered_call\u001b[39m(\u001b[39mself\u001b[39m, args, kwargs):\n\u001b[1;32m   1648\u001b[0m   \u001b[39m\"\"\"Executes the function, filtering arguments from the Python function.\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m \n\u001b[1;32m   1650\u001b[0m \u001b[39m  Objects aside from Tensors, CompositeTensors, and Variables are ignored.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[39m    `args` and `kwargs`.\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1661\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   1662\u001b[0m       (t \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m nest\u001b[39m.\u001b[39;49mflatten((args, kwargs), expand_composites\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1663\u001b[0m        \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(t, (ops\u001b[39m.\u001b[39;49mTensor,\n\u001b[1;32m   1664\u001b[0m                          resource_variable_ops\u001b[39m.\u001b[39;49mBaseResourceVariable))),\n\u001b[1;32m   1665\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1740\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m (\n\u001b[1;32m   1741\u001b[0m     pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_TapeSetPossibleGradientTypes(args))\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m _POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py:593\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    592\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 593\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    594\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    595\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    596\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    597\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    598\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    599\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    600\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    601\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    602\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    605\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    606\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/zugpu/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv3d/Conv3D (defined at tmp/ipykernel_9996/1024949257.py:37) ]] [Op:__inference_predict_function_1349]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "''' TEST '''\n",
    "\n",
    "test_config = {\n",
    "    \"batch_type\" : 2, # =0 all batch have frame_max or video length // =1 last batch has frame_max frames // =2 last batch has no repetead frames\n",
    "    \"frame_max\" : '240' \n",
    "}\n",
    "#run[\"test/config_test\"].append(test_config)\n",
    "\n",
    "predict_total_max, predict_total = test_model(model,model_name,test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ALL WEIGHTS\n",
    "#weights_names , weights_paths = h5_util.find_h5(aux.WEIGHTS_PATH,find_string=(''),ruii=False)\n",
    "#for j in range(len(weights_names)):print(weights_names[j])\n",
    "#for i in range(len(weights_paths)):\n",
    "#    #print(para_file_path[i])\n",
    "#    aux_load = weights_names[i].split(\"_\")\n",
    "#    if '3' in aux_load[1]:aux_load[1] = aux_load[1].strip('3') #for 3gelu\n",
    "#    if aux_load[4] == 'weights': aux_load[4] = '4000'\n",
    "#    #print(aux_load)\n",
    "#\n",
    "#    time_str = aux_load[0]\n",
    "#    ativa = aux_load[1]\n",
    "#    optima = aux_load[2]\n",
    "#    batch_type = aux_load[3]\n",
    "#    frame_max = aux_load[4]\n",
    "#\n",
    "#    load_info = (ativa,optima,'_'+str(batch_type)+'_',frame_max)\n",
    "#    print('\\n',load_info)\n",
    "#    \n",
    "#    model = form_model(load_info[0],load_info[1])\n",
    "#    predict_total_max, predict_total = test_model(model,load_info=load_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zugpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
