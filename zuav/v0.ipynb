{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf 2.2.0\n",
      "cudatoolkit               10.1.243            h8cb64d8_11    conda-forge\n",
      "cudnn                     7.6.5.32             hc0a50b0_1    conda-forge\n",
      "neptune-tensorflow-keras  2.1.0              pyhd8ed1ab_0    conda-forge\n",
      "numpy                     1.19.5           py38hc896f84_4  \n",
      "numpy-base                1.19.5           py38h21a3de8_4  \n",
      "tensorflow                2.2.0           gpu_py38hb782248_0    anaconda\n",
      "tensorflow-base           2.2.0           gpu_py38h83e3d50_0    anaconda\n",
      "tensorflow-estimator      2.6.0            py38h709712a_0    conda-forge\n",
      "tensorflow-gpu            2.2.0                h0d30ee6_0    anaconda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtstudents/anaconda3/envs/zugpu/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudatoolkit               10.1.243            h8cb64d8_11    conda-forge\n",
      "cudnn                     7.6.5.32             hc0a50b0_1    conda-forge\n",
      "neptune-tensorflow-keras  2.1.0              pyhd8ed1ab_0    conda-forge\n",
      "numpy                     1.19.5           py38hc896f84_4  \n",
      "numpy-base                1.19.5           py38h21a3de8_4  \n",
      "tensorflow                2.2.0           gpu_py38hb782248_0    anaconda\n",
      "tensorflow-base           2.2.0           gpu_py38h83e3d50_0    anaconda\n",
      "tensorflow-estimator      2.6.0            py38h709712a_0    conda-forge\n",
      "tensorflow-gpu            2.2.0                h0d30ee6_0    anaconda\n",
      "\n",
      "Num GPUs Available:  4\n",
      "4 Physical GPUs, 4 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os, time, random, logging , cv2 , csv\n",
    "import numpy as np\n",
    "#import mtcnn\n",
    "\n",
    "#import pandas as pd\n",
    "import tensorflow as tf\n",
    "print(\"tf\",tf.version.VERSION)\n",
    "#os.system(\"cat /usr/local/cuda/version.txt\")\n",
    "#os.system(\"nvcc --version\\n\")\n",
    "os.system(\"conda list | grep -E 'tensorflow|cudnn|cudatoolkit|numpy'\")\n",
    "\n",
    "from tensorflow import keras\n",
    "#from keras import backend as K\n",
    "\n",
    "#from keras import models, layers, backend as K\n",
    "#from keras.layers import Activation\n",
    "\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#from tensorflow.keras.utils import get_custom_objects\n",
    "#from keras.utils.generic_utils import get_custom_objects\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "\n",
    "from utils import tf_formh5 , xdv , globo , auxua as aux\n",
    "\n",
    "\n",
    "\n",
    "''' GPU CONFIGURATION '''\n",
    "\n",
    "tf_formh5.set_tf_loglevel(logging.ERROR)\n",
    "tf_formh5.tf.debugging.set_log_device_placement(False) #Enabling device placement logging causes any Tensor allocations or operations to be printed.\n",
    "tf_formh5.set_memory_growth()\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TRAIN CONFIG '''\n",
    "\n",
    "in_height = 120; in_width = 160\n",
    "train_rgb_config = {\n",
    "    \"ativa\" : 'relu',\n",
    "    \"optima\" : 'sgd',\n",
    "    \"batch_type\" : 0,   # =0 all batch have frame_max or video length // =1 last batch has frame_max frames // =2 last batch has no repetead frames\n",
    "    \"frame_max\" : '1000',\n",
    "    \"ckpt_start\" : f\"{0:0>8}\",  #used in train_model: if 00000000 start from scratch, else start from ckpt with config stated\n",
    "    \"epochs\" : 30\n",
    "}\n",
    "\n",
    "train_wav_config = {\n",
    "    \"nada\" : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "full_train_fn (3953,) \n",
      "full_train_normal_fn (2048,) \n",
      "full_train_abnormal (1905,)\n",
      "\n",
      "train_fn (3162,) \n",
      "train_normal_fn (1613,) \n",
      "train_abnormal_fn (1549,)\n",
      "\n",
      "valdt_fn (791,) \n",
      "valdt_normal_fn (435,) \n",
      "valdt_abnormal_fn (356,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\" TRAIN FILES \"\"\"\n",
    "\n",
    "train_fn, train_labels, valdt_fn, valdt_labels = xdv.train_valdt_files()\n",
    "\n",
    "update_index_train = range(0, len(train_fn))\n",
    "update_index_valdt = range(0, len(valdt_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" INPUT DATA\"\"\"\n",
    "\n",
    "def input_train_video_data(file_name):\n",
    "    print(\"\\n\\ninput_train_video_data\\n\")\n",
    "    \n",
    "    video = cv2.VideoCapture(file_name)\n",
    "    total_frame = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    \n",
    "    divid_no = 1\n",
    "    \n",
    "    frame_max = train_rgb_config[\"frame_max\"]\n",
    "    \n",
    "    # define the nmbers of batchs to divid atual video (divid_no)\n",
    "    if total_frame > int(frame_max):\n",
    "        total_frame_int = int(total_frame)\n",
    "        if total_frame_int % int(frame_max) == 0:\n",
    "            divid_no = int(total_frame / int(frame_max))\n",
    "        else:\n",
    "            divid_no = int(total_frame / int(frame_max)) + 1\n",
    "     \n",
    "        \n",
    "    # if normal puts the video at the random start frame\n",
    "    if 'Normal' in file_name:\n",
    "        print(\"\\n\\nNORMAL\\n\\n\")\n",
    "        if divid_no != 1:\n",
    "            slice_no = int(random.random()*divid_no)\n",
    "            passby = 0\n",
    "            if slice_no != divid_no - 1:\n",
    "                while video.isOpened and passby < int(frame_max) * slice_no:\n",
    "                    passby += 1\n",
    "                    success, image = video.read()\n",
    "                    if success == False:\n",
    "                        break\n",
    "            else:\n",
    "                while video.isOpened and passby < total_frame - int(frame_max):\n",
    "                    passby += 1\n",
    "                    success, image = video.read()\n",
    "                    if success == False:\n",
    "                        break\n",
    "     \n",
    "                    \n",
    "    batch_no = 0\n",
    "    batch_frames = []\n",
    "    batch_frames_flip = []\n",
    "    counter = 0\n",
    "    while video.isOpened:               \n",
    "        success, image = video.read() #pixels in image are uint8 [0,255]\n",
    "        if success == False:\n",
    "            break\n",
    "        \n",
    "        image = cv2.resize(image, (in_width, in_height))\n",
    "        image_flip = cv2.flip(image, 1)\n",
    "        \n",
    "        image_array = np.array(image)/255.0\n",
    "        image_array_flip = np.array(image_flip)/255.0\n",
    "        \n",
    "        batch_frames.append(image_array)\n",
    "        batch_frames_flip.append(image_array_flip)\n",
    "        \n",
    "        counter += 1\n",
    "        if counter == int(frame_max):\n",
    "            break\n",
    "            \n",
    "    video.release()\n",
    "    batch_frames = np.array(batch_frames)\n",
    "\n",
    "    print(\"\\n\\tdata\",file_name,\"\\n\\ttotal_frames=\",total_frame,\"\\n\\tbatch_frames.shape=\",np.shape(np.expand_dims(batch_frames,0)),\"\\n\")    \n",
    "    return np.expand_dims(batch_frames,0), np.expand_dims(batch_frames_flip, 0), total_frame\n",
    "\n",
    "def generate_input(data,update_index,validation):\n",
    "    #has_visited = [0 for i in range(len(train_fn))]\n",
    "    data_var_name = [k for k, v in globals().items() if v is data][0]\n",
    "    print(\"\\n\\nGENERATE_INPUT FOR\",data_var_name,\\\n",
    "        '\\n\\tupdate_index len = ',len(update_index),\\\n",
    "        '\\n\\tdata len = ',len(data))\n",
    "    \n",
    "    loop_no = 0\n",
    "    while 1:\n",
    "        index = update_index[loop_no]\n",
    "        loop_no += 1\n",
    "        print(\"\\n\",data_var_name,\" index\",index,\" loop_no\",loop_no)\n",
    "        if loop_no == len(data):loop_no= 0\n",
    "        \n",
    "        \n",
    "        batch_frames, batch_frames_flip, total_frames = input_train_video_data(data[index])\n",
    "        print(\"\\n\\t\",data_var_name,\"data[\",index,\"]=\",data[index],\"\\n\\ttotal_frames=\",total_frames,\"\\n\\tbatch_frames.shape=\",batch_frames.shape,\"\\n\")\n",
    "        \n",
    "        \n",
    "        if not validation:\n",
    "            #batch_frames\n",
    "            if 'label_A' in data[index]: yield batch_frames, np.array([0])   #normal\n",
    "            else: yield batch_frames, np.array([1])   #abnormal\n",
    "            \n",
    "            #batch_frames_flip\n",
    "            if 'label_A' in data[index]: yield batch_frames_flip, np.array([0])  #normal\n",
    "            else: yield batch_frames_flip, np.array([1])  #abnormal\n",
    "        else:\n",
    "            #batch_frames\n",
    "            if 'label_A' in data[index]: yield batch_frames, np.array([0])   #normal\n",
    "            else: yield batch_frames, np.array([1])   #abnormal\n",
    "                \n",
    "    print(\"\\nloop_no=\",loop_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_frames, batch_frames_flip, total_frames = input_train_video_data(train_fn[333])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FORM_MODEL\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 120, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, None, 13, 18, 10612       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (1, None, 3744)      0           sequential[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (1, None, 1024)      19533824    lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 10)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (1, 1024)            0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 10)           0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (1, 1034)            0           global_max_pooling1d[0][0]       \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (1, 128)             132480      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (1, 1)               129         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 19,677,045\n",
      "Trainable params: 19,677,045\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\t {'ativa': 'relu', 'optima': 'sgd', 'batch_type': 0, 'frame_max': '1000', 'ckpt_start': '00000000', 'epochs': 30} \n",
      "\n",
      "\tOPTIMA <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f19dc157dc0> \n",
      "\tATIVA relu\n"
     ]
    }
   ],
   "source": [
    "'''' MODEL '''\n",
    "\n",
    "def all_operations(args):\n",
    "    x = args[0]#;tf.print(x.shape)\n",
    "    x = tf.reshape(x, [1, -1,x.shape[1]*x.shape[2]*x.shape[3]])\n",
    "    return x\n",
    "@tf.function\n",
    "def loss_category(y_true, y_pred):    \n",
    "    #tf.print(y_pred, y_true, 'Prediction')\n",
    "    cce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    return cce\n",
    "\n",
    "def gelu(x): return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
    "#get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "\n",
    "def form_model(params):\n",
    "    print(\"\\nFORM_MODEL\\n\")\n",
    "    \n",
    "    if params[\"ativa\"]=='leakyrelu': ativa = keras.layers.LeakyReLU()\n",
    "    elif params[\"ativa\"]=='gelu': ativa = gelu\n",
    "    elif params[\"ativa\"]=='relu': ativa = 'relu'\n",
    "    else: raise Exception(\"no ativa named assim\")\n",
    "    \n",
    "    \n",
    "    image_input = keras.Input(shape=(None, in_height, in_width, 3))\n",
    "    # ( 1 , frame_max , h , w , ch)    \n",
    "    # ( 1 , 1000 , 120 , 160 , 3)\n",
    "    c3d_mp = keras.Sequential([\n",
    "        keras.layers.Conv3D(4,(2,3,3), activation=ativa),   #c3d_layer1\n",
    "        keras.layers.MaxPooling3D((1,2,2)),                 #c3d_pooling1\n",
    "\n",
    "        keras.layers.Conv3D(8,(4,3,3), activation=ativa),   #c3d_layer2\n",
    "        keras.layers.MaxPooling3D((2,2,2)),                 #c3d_pooling2\n",
    "\n",
    "        keras.layers.Conv3D(16,(8,3,3), activation=ativa),  #c3d_layer3\n",
    "        keras.layers.MaxPooling3D((4,2,2))                  #c3d_pooling3\n",
    "    ])\n",
    "    c3d_mp_out = c3d_mp(image_input)\n",
    "    # ( 1 , time_steps , spatl_featr1 , spatl_featr2 , spatl_featr3 ) \n",
    "    # ( 1 , 122 , 13 , 18 , 16 )  \n",
    "    \n",
    "    c3d_mp_flatten = keras.layers.Lambda(all_operations)(c3d_mp_out)  # flatten spatial features to time series\n",
    "    # ( 1 , time_steps , spatl_featr_flattned ) \n",
    "    # ( 1 , 122        , 3744 )\n",
    "    \n",
    "    lstm1 = keras.layers.LSTM(1024, return_sequences=True)(c3d_mp_flatten) #input_shape=(120,c3d_mp_flatten.shape[2]),\n",
    "    # ( 1 , time_steps , units) \n",
    "    # ( 1 , 122        , 1024 ) \n",
    "    \n",
    "    global_rgb_feature = keras.layers.GlobalMaxPooling1D()(lstm1)\n",
    "    # ( 1 , 1024 ) \n",
    "\n",
    "\n",
    "    ''' waves coming '''\n",
    "    sinet_aas_len = 8\n",
    "    aas_input = tf.keras.layers.Input(shape=(None, sinet_aas_len)) #(TIMESTEPS,AAS)\n",
    "    gloabl_aas = keras.layers.GlobalMaxPooling1D()(aas_input) \n",
    "    \n",
    "    \n",
    "    av_fusion = keras.layers.concatenate([global_rgb_feature, gloabl_aas], axis=1)\n",
    "\n",
    "\n",
    "    dense_1 = keras.layers.Dense(128, activation=ativa)(av_fusion)\n",
    "    soft_max = keras.layers.Dense(1, activation='sigmoid')(dense_1)    \n",
    "    \n",
    "    model = keras.Model(inputs=[image_input , aas_input], \n",
    "                        outputs=[soft_max])\n",
    "    model.summary()\n",
    "   \n",
    "   \n",
    "    if params[\"optima\"]=='sgd':optima = keras.optimizers.SGD(learning_rate = 0.0002)\n",
    "    elif params[\"optima\"]=='adam':optima = keras.optimizers.Adam(learning_rate = 0.0002)\n",
    "    elif params[\"optima\"]=='adamamsgrad':optima = keras.optimizers.Adam(learning_rate = 0.0002,amsgrad=True)\n",
    "    else: raise Exception(\"no optima named assim\")\n",
    "\n",
    "    METRICS = [\n",
    "        keras.metrics.TruePositives(name='tp'),\n",
    "        keras.metrics.FalsePositives(name='fp'),\n",
    "        keras.metrics.TrueNegatives(name='tn'),\n",
    "        keras.metrics.FalseNegatives(name='fn'), \n",
    "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "    ]\n",
    "\n",
    "    model.compile(optimizer=optima, \n",
    "                    loss= 'binary_crossentropy', \n",
    "                    #loss_weights = class_weights,\n",
    "                    #metrics=['accuracy']\n",
    "                    metrics=METRICS)\n",
    "    \n",
    "    print(\"\\n\\t\",params,\"\\n\\n\\tOPTIMA\",optima,\"\\n\\tATIVA\",ativa)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = form_model(train_rgb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(batch_frames)\n",
    "print(np.shape(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.perplexity.ai/search/035a3df9-b2c0-45bc-908f-aaebd9773117?s=c\n",
    "# writes only the frist conv3d layer ritgh to video\n",
    "'''\n",
    "LAYER = 1\n",
    "LAYER_NAME = 'c3d_pooling1'\n",
    "\n",
    "frames = np.concatenate(output, axis=0)\n",
    "\n",
    "# create video writer object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # specify codec\n",
    "fps = 30  # specify frame rate\n",
    "video_writer = cv2.VideoWriter(str(LAYER)+'_'+str(LAYER_NAME)+'_output.mp4', fourcc, fps, (158, 118))\n",
    "\n",
    "# write frames to video file\n",
    "for frame in frames:\n",
    "    frame = np.uint8(frame * 255)  # convert to 8-bit unsigned integer\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # convert from RGB to BGR\n",
    "    video_writer.write(frame)\n",
    "\n",
    "# release video writer object\n",
    "video_writer.release()'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zugpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f7bf267530dde59ab6764f0eb5f1b22dea8a9c4ca62db1182ae079b8b4c02bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
