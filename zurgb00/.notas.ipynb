{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.predict()** : generates output predictions based on the input you pass it (for example, the predicted characters in the MNIST example)\n",
    "\n",
    "**.evaluate()** : computes the loss based on the input you pass it, along with any other metrics that you requested in the metrics param when you compiled your model (such as accuracy in the MNIST example)\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', \n",
    "        optimizer=RMSprop(), \n",
    "        metrics=['accuracy']) \n",
    "        history = model.fit(x_train, y_train, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs, \n",
    "        verbose=1, \n",
    "        validation_data=(x_test, y_test)) \n",
    "        \n",
    "        predictions = model.predict(x_test) \n",
    "        print('First prediction:', predictions[0]) \n",
    "        \n",
    "        score = model.evaluate(x_test, y_test, verbose=0) \n",
    "        print('Test loss:', score[0]) \n",
    "        print('Test accuracy:', score[1]) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARAÇAO ENTRE OS WEIGHTS CRIADOS POR ZHEN ENTRE BATCH_TYPE = { 1 , 2 }\n",
    "\n",
    "E com tal mudança no agrupando dos frames em relacao ao ultima batch (bt=1 vs 2), observa-se:\n",
    "        \n",
    "- maior dificuldade em distinguir corretamente videos normais [ < TN (pred=0/true=0) ]\n",
    "- aumento das predicoes de anomalia quando o video é normal [ > FP (pred=1/true=0) ]\n",
    "\n",
    "Uma transicao de True Negativo para Falso Positivo. \n",
    "\n",
    "Os casos de Positivo mantiveram-se constantes entre os dois casos.\n",
    "\n",
    "\n",
    "\n",
    "![Alt text](../zhen++/parameters_results/original_bt/1625759299.9331803_2_4_8_xdviolence_model_weights_CM1.png)\n",
    "![Alt text](../zhen++/parameters_results/original_bt/1625759299.9331803_2_4_8_xdviolence_model_weights_CM2.png)\n",
    "\n",
    "***\n",
    "\n",
    "![Alt text](../zhen++/parameters_results/original_bt/1626306295.6228774_2_4_8_xdviolence_model_weights_CM1.png)![Alt text](../zhen++/parameters_results/original_bt/1626306295.6228774_2_4_8_xdviolence_model_weights_CM2.png)\n",
    "\n",
    "***\n",
    "\n",
    "![Alt text](../zhen++/parameters_results/original_bt/1626691755.4069657_2_4_8_xdviolence_model_weights_CM1.png)![Alt text](../zhen++/parameters_results/original_bt/1626691755.4069657_2_4_8_xdviolence_model_weights_CM2.png)\n",
    "\n",
    "***\n",
    "\n",
    "![Alt text](../zhen++/parameters_results/original_bt/1626947956.798592_2_4_8_xdviolence_model_weights_CM1.png)![Alt text](../zhen++/parameters_results/original_bt/1626947956.798592_2_4_8_xdviolence_model_weights_CM2.png)\n",
    "\n",
    "***\n",
    "\n",
    "![Alt text](../zhen++/parameters_results/original_bt/1627169149.3222094_2_4_8_xdviolence_model_weights_CM1.png)![Alt text](../zhen++/parameters_results/original_bt/1627169149.3222094_2_4_8_xdviolence_model_weights_CM2.png)\n",
    "\n",
    "***\n",
    "\n",
    "![Alt text](../zhen++/parameters_results/original_bt/1627553113.262731_2_4_8_xdviolence_model_weights_CM1.png)![Alt text](../zhen++/parameters_results/original_bt/1627553113.262731_2_4_8_xdviolence_model_weights_CM2.png)\n",
    "\n",
    "***\n",
    "\n",
    "![Alt text](../zhen++/parameters_results/original_bt/1627900597.7432737_2_4_8_xdviolence_model_weights_CM1.png)![Alt text](../zhen++/parameters_results/original_bt/1627900597.7432737_2_4_8_xdviolence_model_weights_CM2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE MODEL FORMATS W/ CUSTOM ACTIVATIONS FX EXPERIMENTS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/keras/save_and_serialize\n",
    "\n",
    "https://www.tensorflow.org/guide/saved_model\n",
    "\n",
    "https://colab.research.google.com/drive/1gfvcXwBDel8USWuMeb-hrSKihXGy_bSl?usp=sharing#scrollTo=PBIrwGo9IXvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "Epoch 1/3\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1759\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1647\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1568\n",
      "WARNING:tensorflow:From /home/jtstudents/anaconda3/envs/zhen_gpu/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /media/jtstudents/HDD/.zuble/vigia/zu++/modeltf/assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
    "\n",
    "def get_model():\n",
    "    # Create a simple model.\n",
    "    inputs = keras.Input(shape=(32,))\n",
    "    outputs = keras.layers.Dense(1, activation=gelu)(inputs)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "# Train the model.\n",
    "test_input = np.random.random((128, 32))\n",
    "test_target = np.random.random((128, 1))\n",
    "model.fit(test_input, test_target,epochs=3)\n",
    "\n",
    "# Calling `save('my_model')` creates a SavedModel folder `my_model`.\n",
    "model.save(\"/media/jtstudents/HDD/.zuble/vigia/zu++/modeltf\")\n",
    "model.save(\"modelh5.h5\")\n",
    "\n",
    "\n",
    "#json_config = model.to_json()\n",
    "#new_model = keras.models.model_from_json(json_config,custom_objects={\"gelu\":gelu})\n",
    "#new_model.predict(test_input)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#SavedModel format\n",
    "modeltf = tf.saved_model.load('/media/jtstudents/HDD/.zuble/vigia/zu++/modeltf')\n",
    "modeltf = tf.keras.models.load_model('/media/jtstudents/HDD/.zuble/vigia/zu++/modeltf')\n",
    "\n",
    "modeltf.summary()\n",
    "\n",
    "for l in modeltf.layers:\n",
    "    try:\n",
    "        print(l.activation)\n",
    "    except: # some layers don't have any activation\n",
    "        pass\n",
    "\n",
    "#tf.keras.utils.plot_model(modeltf,show_shapes=True)\n",
    "\n",
    "\n",
    "#Raises an AssertionError if two objects are not equal up to desired tolerance.\n",
    "np.testing.assert_allclose(\n",
    "    model.predict(test_input), modeltf.predict(test_input)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "<function gelu at 0x7f39eb1f0158>\n"
     ]
    }
   ],
   "source": [
    "#h5 format\n",
    "modelh5 = tf.keras.models.load_model('/media/jtstudents/HDD/.zuble/vigia/zu++/modelh5.h5',custom_objects={\"gelu\":gelu})\n",
    "modelh5.summary()\n",
    "\n",
    "for l in modelh5.layers:\n",
    "    try:\n",
    "        print(l.activation)\n",
    "    except: # some layers don't have any activation\n",
    "        pass\n",
    "\n",
    "tf.keras.utils.plot_model(modelh5,show_shapes=True)\n",
    "\n",
    "#Raises an AssertionError if two objects are not equal up to desired tolerance.\n",
    "np.testing.assert_allclose(\n",
    "    modeltf.predict(test_input), modelh5.predict(test_input)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "\n",
    "#model_info = h5py.File('/media/jtstudents/HDD/.zuble/vigia/zu++/model/model/1670428387.3704295_3gelu_xdviolence_model.h5', 'r')\n",
    "model_info = h5py.File('/media/jtstudents/HDD/.zuble/vigia/zu++/modelh5.h5', 'r')\n",
    "\n",
    "model_config = json.loads(model_info.attrs.get('model_config').decode('utf-8'))\n",
    "\n",
    "for k in model_config['config']['layers']:\n",
    "    if 'activation' in k['config']:\n",
    "        print(f\"{k['class_name']}: {k['config']['activation']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zhen_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6eb85c0477d574fd6bdabb52dbe9212bb7f487155853edb797b76ac4297f2c9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
