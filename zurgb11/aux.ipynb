{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raid/DATASETS/.zuble/vigia /raid/DATASETS/anomaly\n"
     ]
    }
   ],
   "source": [
    "from utils import globo , xdv \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import time , os , cv2\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VSWIN TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(\"/raid/DATASETS/.zuble/vigia/zurgb11/.pretrained/swin_tiny_patch244_window877_kinetics400_1k_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 768, 16, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "shape_of_input = [1,3,32,224,224]   # [batch_size, channels, frames, height, width]\n",
    "dummy_video = tf.random.normal(shape_of_input)\n",
    "\n",
    "output = model(dummy_video)\n",
    "\n",
    "print(output.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XDV INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import xdv , yammet , globo\n",
    "import numpy as np , os\n",
    "\n",
    "yammet = yammet.Yammet(globo.CFG_YAMMET)\n",
    "\n",
    "\n",
    "fn, labels, tot_frames = xdv.load_train_valdt_npy('train',4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for f in fn:\n",
    "    \n",
    "    l = f.split(\"label_\")[1].replace(\".mp4\",\"\")\n",
    "    \n",
    "    if l != 'A':\n",
    "        print(\"\\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\\n\\n\\t\\t\",\\\n",
    "        os.path.basename(f))\n",
    "        p_yam_arr_max = yammet.get_sigmoid(f,ef=4000,debug=True)\n",
    "        for kkk,anom_yam_k in enumerate(globo.CFG_YAMMET[\"anom_labels_i\"]):\n",
    "            if p_yam_arr_max[anom_yam_k] >= 0.4:\n",
    "                print('\\t\\t-TP- {}: {:.4f}'.format(np.array(globo.CFG_YAMMET['labels'])[anom_yam_k], p_yam_arr_max[anom_yam_k]))\n",
    "                print(\"\\t\\tCHECK\")\n",
    "                break\n",
    "    '''else:\n",
    "        fp_flag = False\n",
    "        p_yam_arr_max = yammet.get_sigmoid(f,debug=True)\n",
    "        for kkk,anom_yam_k in enumerate(globo.CFG_YAMMET[\"anom_labels_i\"]):\n",
    "            if p_yam_arr_max[anom_yam_k] >= 0.4:\n",
    "                print('\\n\\t\\t-FP- {}: {:.4f}'.format(np.array(globo.CFG_YAMMET['labels'])[anom_yam_k], p_yam_arr_max[anom_yam_k]))\n",
    "                fp_flag = True\n",
    "                break          \n",
    "        if not fp_flag: print(\"\\n\\t\\tCHECK\") '''       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdv.get_info_from_infotxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "frame = []\n",
    "for i in range(10):\n",
    "    frame.append(np.ones((155,155,3),np.float32))\n",
    "t1 = np.stack(frame)\n",
    "t2 = np.stack(frame,axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mobile net inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(\"/raid/DATASETS/.zuble/vigia/zurgb11/model/model/1683929580.7657886_mobilenetv2_fp16_relu_0.0002_sgd_0_4_4000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def vas_predict(model,x):\n",
    "    return model(x, training=False)    \n",
    "\n",
    "def get_n_frames(video_path, n):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_indices = [i * total_frames // n for i in range(n)]\n",
    "\n",
    "    for i in range(total_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if i in frame_indices:\n",
    "            frame = cv2.resize(frame, (224, 224) )\n",
    "            frame = np.array(frame)/255.0\n",
    "            frames.append(frame)\n",
    "    cap.release()\n",
    "    \n",
    "    return np.expand_dims(np.array(frames).astype(np.float32), 0)\n",
    "\n",
    "def test_model():\n",
    "    test_fn, *_ = xdv.test_files()\n",
    "    filtered_test_fn = [fn for fn in test_fn if 'label_A' not in fn]\n",
    "    for i,fn in enumerate(test_fn):\n",
    "            print(fn)\n",
    "            if i == 5:break\n",
    "            inp = get_n_frames(fn, 500)\n",
    "            t = time.time()\n",
    "            output = vas_predict(model,inp)[0][0].numpy()\n",
    "            print(f\"Output shape: {output.shape}\")\n",
    "            tt = time.time()\n",
    "            print(output,str(tt-t))\n",
    "\n",
    "test_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zugpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
