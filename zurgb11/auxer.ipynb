{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random, logging , datetime , cv2 , csv , subprocess\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"tf\",tf.version.VERSION)\n",
    "from tensorflow import keras\n",
    "\n",
    "from utils import globo ,  xdv , tfh5\n",
    "\n",
    "\n",
    "''' GPU CONFIGURATION '''\n",
    "\n",
    "tfh5.set_tf_loglevel(logging.ERROR)\n",
    "tfh5.tf.debugging.set_log_device_placement(False) #Enabling device placement logging causes any Tensor allocations or operations to be printed.\n",
    "tfh5.set_memory_growth()\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TRAIN & VALDT '''\n",
    "#train_fn, train_labels, train_tot_frames, valdt_fn, valdt_labels , valdt_tot_frames = xdv.train_valdt_files(tframes=True)\n",
    "train_fn, train_labels, valdt_fn, valdt_labels = xdv.train_valdt_files()\n",
    "\n",
    "update_index_train = range(0, len(train_fn))\n",
    "update_index_valdt = range(0, len(valdt_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CONFIGS '''\n",
    "\n",
    "train_config = {\n",
    "    \"frame_step\":2, #24 fps -> 12\n",
    "    \n",
    "    \"in_height\":120,\n",
    "    \"in_width\":160,\n",
    "    \n",
    "    \"batch_size\":1,\n",
    "    \"augment\":True,\n",
    "    \"shuffle\":False,\n",
    "    \n",
    "    \"ativa\" : 'leakyrelu',\n",
    "    \"optima\" : 'sgd',\n",
    "    \"batch_type\" : 0,   # =0 all batch have frame_max or video length // =1 last batch has frame_max frames // =2 last batch has no repetead frames\n",
    "    \"frame_max\" : 8000,\n",
    "    \"ckpt_start\" : f\"{0:0>8}\",  #used in train_model: if 00000000 start from scratch, else start from ckpt with config stated\n",
    "    \n",
    "    \"epochs\" : 1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintDataCallback(tf.keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        # Access the input data shape of the current batch\n",
    "        input_batch_shape = self.model.get_layer('print_input_shape').output\n",
    "\n",
    "        # Run the model on a dummy input to get the actual input shape\n",
    "        input_shape = self.model.predict(np.zeros((1, *input_batch_shape.shape)))\n",
    "\n",
    "        # Print the input shape\n",
    "        print(\"Input shape:\\n\", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen(keras.utils.Sequence):\n",
    "    def __init__(self, vpath_list, label_list, config , valdt=False):\n",
    "        \n",
    "        self.valdt = valdt\n",
    "        self.vpath_list = vpath_list\n",
    "        self.label_list = label_list\n",
    "        \n",
    "        print(len(vpath_list),(len(label_list)))\n",
    "        \n",
    "        self.batch_size = config[\"batch_size\"]\n",
    "        self.frame_max = config[\"frame_max\"]\n",
    "        \n",
    "        self.in_height = config[\"in_height\"]\n",
    "        self.in_width = config[\"in_width\"]\n",
    "        \n",
    "        self.augment = config[\"augment\"]\n",
    "        self.shuffle = config[\"shuffle\"]\n",
    "        \n",
    "        self.len_vpath_list = len(self.vpath_list)\n",
    "        #self.indices = np.arange(self.len_vpath_list)\n",
    "\n",
    "        self.frame_step = config[\"frame_step\"]\n",
    "    \n",
    "    \n",
    "    def skip_ms(self,cap):\n",
    "        start_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        #print(\"skip_start\",start_frame)\n",
    "        while True:\n",
    "            success = cap.grab()\n",
    "            curr_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "            if not success or curr_frame - start_frame >= self.frame_step:break\n",
    "        \n",
    "        if not success:return success, None, start_frame + self.frame_step\n",
    "\n",
    "        success, image = cap.retrieve()\n",
    "        return success, image, curr_frame        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        #if self.augment:\n",
    "        #    print(\"\\n\\n__len__ = n batchs = \",int(np.ceil(self.len_vpath_list * 2 / float(self.batch_size ))) ,\" w/ '2' vid each\")\n",
    "        #    return int(np.ceil(self.len_vpath_list * 2 / float(self.batch_size )))\n",
    "        #else:\n",
    "        #    print(\"\\n\\n__len__ = n batchs = \",int(np.ceil(self.len_vpath_list / float(self.batch_size))),\" w/ 1 vid each\")\n",
    "        #    return int(np.ceil(self.len_vpath_list / float(self.batch_size)))\n",
    "        return self.len_vpath_list\n",
    "           \n",
    "    def __getitem__(self, idx):\n",
    "        #batch_indices = self.indices[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        print(\"\\n\\nbatch_indx\",idx)\n",
    "        \n",
    "        batch_frames , batch_frames_flip , batch_labels = [] , [] , []\n",
    "        \n",
    "        #for i, index in enumerate(batch_indices):\n",
    "        #vpath = self.vpath_list[index]\n",
    "        #label = self.label_list[index] \n",
    "        vpath = self.vpath_list[idx]\n",
    "        label = self.label_list[idx]\n",
    "    \n",
    "        video = cv2.VideoCapture(vpath)\n",
    "        tframes = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(\"\\n*************\",vpath , label , tframes)\n",
    "        \n",
    "        ## if normal > frame_max picks random frame_max W\n",
    "        if label == 0 and tframes > self.frame_max :\n",
    "            start_index = random.randint(0, tframes - self.frame_max)\n",
    "            end_index = start_index + self.frame_max\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, start_index)\n",
    "        ## else ingests full video\n",
    "        else: \n",
    "            start_index = 0\n",
    "            end_index = tframes\n",
    "        \n",
    "        print(\"sstart_index,end_index\",start_index , end_index)\n",
    "        \n",
    "        frames = []\n",
    "        curr_frame = 0\n",
    "        success, frame = video.read()\n",
    "        for j in range(end_index - start_index):\n",
    "            \n",
    "            if not success or curr_frame > end_index: break\n",
    "            \n",
    "            frame = cv2.resize(frame, (self.in_width, self.in_height))\n",
    "            frame_arr = np.array(frame)/255.0\n",
    "            frames.append(frame_arr)\n",
    "            \n",
    "            ## jumps the next frame wo decoding\n",
    "            success, frame, curr_frame = self.skip_ms(video)\n",
    "            #print(\"skip_end\",curr_frame)\n",
    "                \n",
    "        \n",
    "        frames_arr = np.array(frames)\n",
    "        frames_arr_flip = np.flip(frames_arr, axis=2)\n",
    "        print(\"frames\",frames_arr.shape,frames_arr_flip.shape)\n",
    "\n",
    "        batch_frames.append(frames_arr)\n",
    "        batch_frames_flip.append(frames_arr_flip)\n",
    "        batch_labels.append(label)\n",
    "        \n",
    "        XN = np.array(batch_frames).astype(np.float32)\n",
    "        XF = np.array(batch_frames_flip).astype(np.float32)\n",
    "        y = np.array(batch_labels).astype(np.float32)\n",
    "        \n",
    "\n",
    "        if self.valdt or not self.augment:\n",
    "            print(\"valdt\")\n",
    "            print(\"XN \",XN.dtype,XN.shape )\n",
    "            print(\"y\",y.shape)\n",
    "            return XN , y\n",
    "        elif self.augment:\n",
    "            print(\"augment , train\")\n",
    "            X = np.concatenate([XN, XF], axis=0)\n",
    "            Y = np.concatenate([y, y], axis=0)\n",
    "            print(\"XN \",XN.dtype,XN.shape )\n",
    "            print(\"XF \",XF.dtype,XF.shape )\n",
    "            print(\"X \",X.dtype,X.shape )\n",
    "            print(\"Y \",Y.dtype,Y.shape)\n",
    "            return X , Y\n",
    "\n",
    "    #def on_epoch_end(self):\n",
    "    #    if self.shuffle:\n",
    "    #        np.random.shuffle(self.indexes)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are only 8 videos being fed to the training phase, and batch_size is set to 1 with augment enabled, then the generator will yield 16 batches for each epoch of training, as each video will be flipped horizontally to create a second batch. This means that each video will be processed twice per epoch, once in its original orientation and once flipped horizontally.\n",
    "\n",
    "After all of the training batches have been processed, the fit method will move onto the validation data, which is processed separately using a different generator (valdt_generator).\n",
    "\n",
    "If augment is set to False, then each video will only yield one batch, regardless of the batch_size. So in this case, with a batch_size of 1, the generator would yield 8 batches for training before moving onto the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGen(train_fn[], train_labels[], train_config)\n",
    "\n",
    "valdt_generator = DataGen(valdt_fn[], valdt_labels[], train_config , True)\n",
    "\n",
    "## len(train_fn) / batch_size = number of video per batch = __len__\n",
    "## if batch_size 1 , each batch contains a video\n",
    "## if augmt =True & batch_size 1 , each batch contains \"2\" videos\n",
    "\n",
    "model,model_name = tfh5.form_model(train_config)\n",
    "\n",
    "history = model.fit(train_generator, \n",
    "                    epochs = train_config[\"epochs\"] ,\n",
    "                    steps_per_epoch = len(train_fn),\n",
    "                    \n",
    "                    verbose=2,\n",
    "                    \n",
    "                    validation_data = valdt_generator ,\n",
    "                    validation_steps = len(valdt_fn),\n",
    "                    \n",
    "                    use_multiprocessing = True , \n",
    "                    workers = 32 #,\n",
    "                    #callbacks=[print_data_callback]\n",
    "                  )\n",
    "\n",
    "# Save the history to a CSV file\n",
    "hist_csv_file = globo.HIST_PATH + model_name + '_history.csv'\n",
    "with open(hist_csv_file, 'w', newline='') as file:writer = csv.writer(file);writer.writerow(history.history.keys());writer.writerows(zip(*history.history.values()))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_generator(video_paths, labels, fps, frame_max, in_height, in_width):\n",
    "    \n",
    "    \n",
    "    def skip_ms(cap,frame_step):\n",
    "        start_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        \n",
    "        while True:\n",
    "            success = cap.grab()\n",
    "\n",
    "            curr_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "            if not success or curr_frame - start_frame >= frame_step:\n",
    "                break\n",
    "        \n",
    "        if not success:\n",
    "            return success, None, start_frame + frame_step\n",
    "\n",
    "        success, image = cap.retrieve()\n",
    "        \n",
    "        return success, image, curr_frame    \n",
    "    \n",
    "    \n",
    "    #while True:\n",
    "    # Shuffle the video paths and labels\n",
    "    zipped = list(zip(video_paths, labels))\n",
    "    random.shuffle(zipped)\n",
    "    video_paths, labels = zip(*zipped)\n",
    "    \n",
    "    # Loop over the video paths and labels\n",
    "    #for i in range(len(video_paths)):\n",
    "    video_path = video_paths[0]\n",
    "    label = labels[0]\n",
    "    \n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    tframes = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(video_path , label , tframes)\n",
    "    \n",
    "    if label == 0 and tframes > frame_max :\n",
    "        start_index = random.randint(0, tframes - frame_max)\n",
    "        end_index = start_index + frame_max\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, start_index)\n",
    "    else : \n",
    "        start_index = 0\n",
    "        end_index = tframes\n",
    "    \n",
    "    print(start_index , end_index)\n",
    "    \n",
    "    frames = []\n",
    "    curr_frame = 0\n",
    "    \n",
    "    success, frame = video.read()\n",
    "    while 1:\n",
    "        \n",
    "        if not success or curr_frame > end_index: break\n",
    "        \n",
    "        frame = cv2.resize(frame, (in_width, in_height))\n",
    "        frame = np.array(frame)/255.0\n",
    "        frames.append(frame)\n",
    "        \n",
    "        '''cv2.imshow('ff', frame)\n",
    "        key = cv2.waitKey(int(1000/12))\n",
    "        if key == ord('q'): break  # quit\n",
    "        if key == ord(' '):  # pause\n",
    "            while True:\n",
    "                key = cv2.waitKey(1)\n",
    "                if key == ord(' '):break'''\n",
    "                \n",
    "        success, frame, curr_frame = skip_ms(video,2)\n",
    "        \n",
    "    #batch_frames.append(frames)\n",
    "    #batch_labels.append(label)\n",
    "    #\n",
    "    #batch_frames = np.array(batch_frames) / 255.0\n",
    "    #batch_labels = np.array(batch_labels)\n",
    "    \n",
    "    X = np.array(frames)\n",
    "    \n",
    "        \n",
    "    return np.expand_dims(X,0) , np.array([label])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x , y = video_generator(train_fn,train_labels,12,8000,120,160)\n",
    "\n",
    "#print( np.shape(x) , np.shape(y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORIGINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" INPUT DATA\"\"\"\n",
    "\n",
    "in_height = 120; in_width = 160\n",
    "\n",
    "def input_train_video_data(file_name):\n",
    "    print(\"\\n\\ninput_train_video_data\\n\")\n",
    "    \n",
    "    #file_name = 'C:\\\\Bosch\\\\Anomaly\\\\training\\\\videos\\\\13_007.avi'\n",
    "    \n",
    "    video = cv2.VideoCapture(file_name)\n",
    "    total_frame = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    \n",
    "    divid_no = 1\n",
    "    \n",
    "    frame_max = train_config[\"frame_max\"]\n",
    "    \n",
    "    # define the nmbers of batchs to divid atual video (divid_no)\n",
    "    if total_frame > int(frame_max):\n",
    "        total_frame_int = int(total_frame)\n",
    "        if total_frame_int % int(frame_max) == 0:\n",
    "            divid_no = int(total_frame / int(frame_max))\n",
    "        else:\n",
    "            divid_no = int(total_frame / int(frame_max)) + 1\n",
    "        \n",
    "    batch_no = 0\n",
    "    batch_frames = []\n",
    "    batch_frames_flip = []\n",
    "    counter = 0\n",
    "    \n",
    "    # gets random batch w\\ frame max lenght \n",
    "    if 'Normal' in file_name:\n",
    "        print(\"\\n\\nNORMAL\\n\\n\")\n",
    "        if divid_no != 1:\n",
    "            slice_no = int(random.random()*divid_no)\n",
    "            passby = 0\n",
    "            if slice_no != divid_no - 1:\n",
    "                while video.isOpened and passby < int(frame_max) * slice_no:\n",
    "                    passby += 1\n",
    "                    success, image = video.read()\n",
    "                    if success == False:\n",
    "                        break\n",
    "            else:\n",
    "                while video.isOpened and passby < total_frame - int(frame_max):\n",
    "                    passby += 1\n",
    "                    success, image = video.read()\n",
    "                    if success == False:\n",
    "                        break\n",
    "\n",
    "    while video.isOpened:               \n",
    "        success, image = video.read()\n",
    "        if success == False:\n",
    "            break\n",
    "\n",
    "        image = cv2.resize(image, (in_width, in_height))\n",
    "        image_flip = cv2.flip(image, 1)\n",
    "        \n",
    "        image_array = np.array(image)/255.0\n",
    "        image_array_flip = np.array(image_flip)/255.0\n",
    "        \n",
    "        batch_frames.append(image_array)\n",
    "        batch_frames_flip.append(image_array_flip)\n",
    "        \n",
    "        counter += 1\n",
    "        if counter > int(frame_max):\n",
    "            break\n",
    "            \n",
    "    video.release()\n",
    "    batch_frames = np.array(batch_frames)\n",
    "    print(batch_frames.shape)\n",
    "        \n",
    "    return np.expand_dims(batch_frames,0), np.expand_dims(batch_frames_flip, 0), total_frame\n",
    "\n",
    "\n",
    "\n",
    "def generate_input(data,update_index,validation):\n",
    "    \n",
    "    #data_var_name = [k for k, v in globals().items() if v is data][0]\n",
    "    #print(\"\\n\\nGENERATE_INPUT FOR\",data_var_name,\\\n",
    "    #    '\\n\\tupdate_index len = ',len(update_index),\\\n",
    "    #    '\\n\\tdata len = ',len(data))\n",
    "    \n",
    "    loop_no = 0\n",
    "    while 1:\n",
    "        index = update_index[loop_no]\n",
    "        loop_no += 1\n",
    "        #print(\"\\n\",data_var_name,\" index\",index,\" loop_no\",loop_no)\n",
    "        if loop_no == len(data):loop_no= 0\n",
    "        \n",
    "        \n",
    "        batch_frames, batch_frames_flip, total_frames = input_train_video_data(data[index])\n",
    "        print(\"\\n\\tdata[\",index,\"]=\",data[index],\"\\n\\ttotal_frames=\",total_frames,\"\\n\\tbatch_frames.shape=\",batch_frames.shape,\"\\n\")\n",
    "        #if batch_frames.ndim != 5:\n",
    "        #   break\n",
    "\n",
    "        \n",
    "        if not validation:\n",
    "            #batch_frames\n",
    "            if 'label_A' in data[index]: return batch_frames, np.array([0])   #normal\n",
    "            else: return batch_frames, np.array([1])   #abnormal\n",
    "            \n",
    "            #batch_frames_flip\n",
    "            if 'label_A' in data[index]: return batch_frames_flip, np.array([0])  #normal\n",
    "            else: return batch_frames_flip, np.array([1])  #abnormal\n",
    "        else:\n",
    "            #batch_frames\n",
    "            if 'label_A' in data[index]: return batch_frames, np.array([0])   #normal\n",
    "            else: return batch_frames, np.array([1])   #abnormal\n",
    "                \n",
    "    print(\"\\nloop_no=\",loop_no)\n",
    "    \n",
    "    \n",
    "#generate_input(train_fn[:4] , update_index_train[:4] , False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zugpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
