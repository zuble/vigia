{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random, logging , datetime , cv2 , csv , subprocess\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"tf\",tf.version.VERSION)\n",
    "from tensorflow import keras\n",
    "\n",
    "from utils import globo ,  xdv , tfh5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' GPU CONFIGURATION '''\n",
    "\n",
    "tfh5.set_tf_loglevel(logging.ERROR)\n",
    "tfh5.tf.debugging.set_log_device_placement(False) #Enabling device placement logging causes any Tensor allocations or operations to be printed.\n",
    "tfh5.set_memory_growth()\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TRAIN & VALDT '''\n",
    "#train_fn, train_labels, train_tot_frames, valdt_fn, valdt_labels , valdt_tot_frames = xdv.train_valdt_files(tframes=True)\n",
    "train_fn, train_labels, valdt_fn, valdt_labels = xdv.train_valdt_files()\n",
    "\n",
    "update_index_train = range(0, len(train_fn))\n",
    "update_index_valdt = range(0, len(valdt_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CONFIGS '''\n",
    "\n",
    "train_config = {\n",
    "    \"target_size\":[120,160],\n",
    "    \"frame_max_A\":8000,\n",
    "    \"target_fps\":12,\n",
    "    \n",
    "    \"ativa\" : 'leakyrelu',\n",
    "    \"optima\" : 'sgd',\n",
    "    \"batch_type\" : 0,   # =0 all batch have frame_max or video length // =1 last batch has frame_max frames // =2 last batch has no repetead frames\n",
    "    \"frame_max\" : '4000',\n",
    "    \"ckpt_start\" : f\"{0:0>8}\",  #used in train_model: if 00000000 start from scratch, else start from ckpt with config stated\n",
    "    \"epochs\" : 30\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, video_paths, labels, batch_size, n_frames, target_fps, shuffle=True):\n",
    "        self.video_paths = video_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.n_frames = n_frames\n",
    "        self.target_fps = target_fps\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "        self.frame_step = 2\n",
    "    \n",
    "    def skip_ms(self,cap):\n",
    "        start_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        \n",
    "        while True:\n",
    "            success = cap.grab()\n",
    "\n",
    "            curr_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "            if not success or curr_frame - start_frame >= self.frame_step:\n",
    "                break\n",
    "        \n",
    "        if not success:\n",
    "            return success, None, start_frame + self.frame_step\n",
    "\n",
    "        success, image = cap.retrieve()\n",
    "        \n",
    "        return success, image, curr_frame  \n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.video_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start_index = index * self.batch_size\n",
    "        end_index = (index + 1) * self.batch_size\n",
    "        batch_video_paths = self.video_paths[start_index:end_index]\n",
    "        batch_labels = self.labels[start_index:end_index]\n",
    "\n",
    "        X, y = self.__data_generation(batch_video_paths, batch_labels)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            temp = list(zip(self.video_paths, self.labels))\n",
    "            np.random.shuffle(temp)\n",
    "            self.video_paths, self.labels = zip(*temp)\n",
    "\n",
    "    def __data_generation(self, batch_video_paths, batch_labels):\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for video_path, label in zip(batch_video_paths, batch_labels):\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            original_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "            frame_step = int(original_fps / self.target_fps)\n",
    "\n",
    "            if label == 0 and total_frames > self.n_frames :\n",
    "                start_index = random.randint(0, total_frames - self.n_frames)\n",
    "                end_index = start_index + self.n_frames\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, start_index)\n",
    "            else: \n",
    "                start_index = 0\n",
    "                end_index = total_frames\n",
    "\n",
    "            frames = []\n",
    "            for i in range(start_index, end_index, frame_step):\n",
    "                if len(frames) == self.n_frames:\n",
    "                    break\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "                ret, frame = cap.read()\n",
    "                if ret:\n",
    "                    frame = cv2.resize(frame, (160, 120))\n",
    "                    frames.append(frame)\n",
    "\n",
    "            cap.release()\n",
    "            X.append(frames)\n",
    "            y.append(label)\n",
    "\n",
    "        X = np.array(X, dtype=np.float32) / 255.0\n",
    "        y = np.array(y, dtype=np.float32)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "n_frames = 4000  # Number of frames to extract from each video\n",
    "target_fps = 12  # Target FPS for extracting frames\n",
    "\n",
    "model = tfh5.form_model(train_config)\n",
    "\n",
    "data_gen = VideoDataGenerator(train_fn[:4], train_labels[:4], batch_size, n_frames, target_fps)\n",
    "model.fit(data_gen, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, vpath_list, label_list, batch_size, frame_max_A , fps, in_height, in_width):\n",
    "        \n",
    "        self.vpath_list = vpath_list\n",
    "        self.label_list = label_list\n",
    "        \n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.frame_max_A = frame_max_A\n",
    "        self.fps = fps\n",
    "        self.in_height = in_height\n",
    "        self.in_width = in_width\n",
    "        \n",
    "        self.len_vpath_list = len(self.vpath_list)\n",
    "        self.indices = np.arange(self.len_vpath_list)\n",
    "\n",
    "        self.frame_step = 2 \n",
    "    \n",
    "    \n",
    "    def skip_ms(self,cap):\n",
    "        start_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        \n",
    "        while True:\n",
    "            success = cap.grab()\n",
    "\n",
    "            curr_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "            if not success or curr_frame - start_frame >= self.frame_step:\n",
    "                break\n",
    "        \n",
    "        if not success:\n",
    "            return success, None, start_frame + self.frame_step\n",
    "\n",
    "        success, image = cap.retrieve()\n",
    "        \n",
    "        return success, image, curr_frame        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        print(\"__len__\",int(np.ceil(self.len_vpath_list / float(self.batch_size))))\n",
    "        return int(np.ceil(self.len_vpath_list / float(self.batch_size)))\n",
    "\n",
    "           \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        \n",
    "        batch_frames = np.zeros((len(batch_indices),), dtype=np.object)\n",
    "        #batch_frames = np.zeros((len(batch_indices), self.frame_max_A, self.in_height, self.in_width, 3), dtype=np.float32)\n",
    "        \n",
    "        batch_labels = np.zeros((len(batch_indices),), dtype=np.int32)\n",
    "        \n",
    "        for i, index in enumerate(batch_indices):\n",
    "            vpath = self.vpath_list[index]\n",
    "            #tframes = self.tframes_list[i]\n",
    "            label = self.label_list[index]\n",
    "        \n",
    "        \n",
    "            video = cv2.VideoCapture(vpath)\n",
    "            tframes = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            print(vpath , label , tframes)\n",
    "            \n",
    "            if label == 0 and tframes > self.frame_max_A :\n",
    "                start_index = random.randint(0, tframes - self.frame_max_A)\n",
    "                end_index = start_index + self.frame_max_A\n",
    "                video.set(cv2.CAP_PROP_POS_FRAMES, start_index)\n",
    "            else: \n",
    "                start_index = 0\n",
    "                end_index = tframes\n",
    "            \n",
    "            print(\"sstart_index,end_index\",start_index , end_index)\n",
    "            \n",
    "            frames = np.zeros((end_index - start_index, self.in_height, self.in_width, 3), dtype=np.float32)\n",
    "            curr_frame = 0\n",
    "            success, frame = video.read()\n",
    "            \n",
    "            for j in range(end_index - start_index):\n",
    "                \n",
    "                if not success or curr_frame > end_index: break\n",
    "                \n",
    "                frame = cv2.resize(frame, (self.in_width, self.in_height))\n",
    "                frame = np.array(frame)/255.0\n",
    "                frames[j] = frame\n",
    "                \n",
    "                #batch_frames[idx][j] = frame\n",
    "                \n",
    "                \n",
    "                #cv2.imshow('ff', frame)\n",
    "                #key = cv2.waitKey(int(1000/12))\n",
    "                #if key == ord('q'): break  # quit\n",
    "                #if key == ord(' '):  # pause\n",
    "                #    while True:\n",
    "                #        key = cv2.waitKey(1)\n",
    "                #        if key == ord(' '):break\n",
    "                \n",
    "                \n",
    "                success, frame, curr_frame = self.skip_ms(video)\n",
    "            \n",
    "            batch_frames[i] = frames\n",
    "            batch_labels[i] = label\n",
    "\n",
    "            #batch_labels[idx] = label\n",
    "\n",
    "        print(np.shape(batch_frames),np.shape(batch_labels))\n",
    "        return batch_frames, batch_labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = FrameGenerator(train_fn[:4], train_labels[:4], 2, 8000, 12, 120, 160)\n",
    "\n",
    "#bf , bl = train_generator.getitem(0)\n",
    "model = tfh5.form_model(train_config)\n",
    "\n",
    "model.fit(train_generator, epochs=1 , use_multiprocessing = True , workers = 8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_generator(video_paths, labels, fps, window_size, in_height, in_width):\n",
    "    \n",
    "    \n",
    "    def skip_ms(cap,frame_step):\n",
    "        start_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        \n",
    "        while True:\n",
    "            success = cap.grab()\n",
    "\n",
    "            curr_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "            if not success or curr_frame - start_frame >= frame_step:\n",
    "                break\n",
    "        \n",
    "        if not success:\n",
    "            return success, None, start_frame + frame_step\n",
    "\n",
    "        success, image = cap.retrieve()\n",
    "        \n",
    "        return success, image, curr_frame    \n",
    "    \n",
    "    \n",
    "    #while True:\n",
    "    # Shuffle the video paths and labels\n",
    "    zipped = list(zip(video_paths, labels))\n",
    "    random.shuffle(zipped)\n",
    "    video_paths, labels = zip(*zipped)\n",
    "    \n",
    "    # Loop over the video paths and labels\n",
    "    #for i in range(len(video_paths)):\n",
    "    video_path = video_paths[0]\n",
    "    label = labels[0]\n",
    "    \n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    tframes = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(video_path , label , tframes)\n",
    "    \n",
    "    if label == 0 and tframes > 4000 :\n",
    "        start_index = random.randint(0, tframes - 4000)\n",
    "        end_index = start_index + 4000\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, start_index)\n",
    "    else : \n",
    "        start_index = 0\n",
    "        end_index = tframes\n",
    "    \n",
    "    print(start_index , end_index)\n",
    "    \n",
    "    frames = []\n",
    "    curr_frame = 0\n",
    "    \n",
    "    success, frame = video.read()\n",
    "    while 1:\n",
    "        \n",
    "        if not success or curr_frame > end_index: break\n",
    "        \n",
    "        frame = cv2.resize(frame, (in_width, in_height))\n",
    "        frame = np.array(frame)/255.0\n",
    "        frames.append(frame)\n",
    "        \n",
    "        cv2.imshow('ff', frame)\n",
    "        key = cv2.waitKey(int(1000/12))\n",
    "        if key == ord('q'): break  # quit\n",
    "        if key == ord(' '):  # pause\n",
    "            while True:\n",
    "                key = cv2.waitKey(1)\n",
    "                if key == ord(' '):break\n",
    "        \n",
    "         \n",
    "        success, frame, curr_frame = skip_ms(video,2)\n",
    "        \n",
    "    #batch_frames.append(frames)\n",
    "    #batch_labels.append(label)\n",
    "    #\n",
    "    #batch_frames = np.array(batch_frames) / 255.0\n",
    "    #batch_labels = np.array(batch_labels)\n",
    "    \n",
    "    X = np.array(frames)\n",
    "    \n",
    "        \n",
    "    return np.expand_dims(X,0) , np.array([label])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , y = video_generator(train_fn,train_labels,12,8000,120,160)\n",
    "\n",
    "print( np.shape(x) , np.shape(y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORIGINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" INPUT DATA\"\"\"\n",
    "\n",
    "in_height = 120; in_width = 160\n",
    "\n",
    "def input_train_video_data(file_name):\n",
    "    print(\"\\n\\ninput_train_video_data\\n\")\n",
    "    \n",
    "    #file_name = 'C:\\\\Bosch\\\\Anomaly\\\\training\\\\videos\\\\13_007.avi'\n",
    "    \n",
    "    video = cv2.VideoCapture(file_name)\n",
    "    total_frame = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    \n",
    "    divid_no = 1\n",
    "    \n",
    "    frame_max = train_config[\"frame_max\"]\n",
    "    \n",
    "    # define the nmbers of batchs to divid atual video (divid_no)\n",
    "    if total_frame > int(frame_max):\n",
    "        total_frame_int = int(total_frame)\n",
    "        if total_frame_int % int(frame_max) == 0:\n",
    "            divid_no = int(total_frame / int(frame_max))\n",
    "        else:\n",
    "            divid_no = int(total_frame / int(frame_max)) + 1\n",
    "        \n",
    "    batch_no = 0\n",
    "    batch_frames = []\n",
    "    batch_frames_flip = []\n",
    "    counter = 0\n",
    "    \n",
    "    # gets random batch w\\ frame max lenght \n",
    "    if 'Normal' in file_name:\n",
    "        print(\"\\n\\nNORMAL\\n\\n\")\n",
    "        if divid_no != 1:\n",
    "            slice_no = int(random.random()*divid_no)\n",
    "            passby = 0\n",
    "            if slice_no != divid_no - 1:\n",
    "                while video.isOpened and passby < int(frame_max) * slice_no:\n",
    "                    passby += 1\n",
    "                    success, image = video.read()\n",
    "                    if success == False:\n",
    "                        break\n",
    "            else:\n",
    "                while video.isOpened and passby < total_frame - int(frame_max):\n",
    "                    passby += 1\n",
    "                    success, image = video.read()\n",
    "                    if success == False:\n",
    "                        break\n",
    "\n",
    "    while video.isOpened:               \n",
    "        success, image = video.read()\n",
    "        if success == False:\n",
    "            break\n",
    "\n",
    "        image = cv2.resize(image, (in_width, in_height))\n",
    "        image_flip = cv2.flip(image, 1)\n",
    "        \n",
    "        image_array = np.array(image)/255.0\n",
    "        image_array_flip = np.array(image_flip)/255.0\n",
    "        \n",
    "        batch_frames.append(image_array)\n",
    "        batch_frames_flip.append(image_array_flip)\n",
    "        \n",
    "        counter += 1\n",
    "        if counter > int(frame_max):\n",
    "            break\n",
    "            \n",
    "    video.release()\n",
    "    batch_frames = np.array(batch_frames)\n",
    "    #print(batch_frames.shape)\n",
    "        \n",
    "    return np.expand_dims(batch_frames,0), np.expand_dims(batch_frames_flip, 0), total_frame\n",
    "\n",
    "\n",
    "\n",
    "def generate_input(data,update_index,validation):\n",
    "    \n",
    "    data_var_name = [k for k, v in globals().items() if v is data][0]\n",
    "    print(\"\\n\\nGENERATE_INPUT FOR\",data_var_name,\\\n",
    "        '\\n\\tupdate_index len = ',len(update_index),\\\n",
    "        '\\n\\tdata len = ',len(data))\n",
    "    \n",
    "    loop_no = 0\n",
    "    while 1:\n",
    "        index = update_index[loop_no]\n",
    "        loop_no += 1\n",
    "        print(\"\\n\",data_var_name,\" index\",index,\" loop_no\",loop_no)\n",
    "        if loop_no == len(data):loop_no= 0\n",
    "        \n",
    "        \n",
    "        batch_frames, batch_frames_flip, total_frames = input_train_video_data(data[index])\n",
    "        print(\"\\n\\t\",data_var_name,\"data[\",index,\"]=\",data[index],\"\\n\\ttotal_frames=\",total_frames,\"\\n\\tbatch_frames.shape=\",batch_frames.shape,\"\\n\")\n",
    "        #if batch_frames.ndim != 5:\n",
    "        #   break\n",
    "\n",
    "        \n",
    "        if not validation:\n",
    "            #batch_frames\n",
    "            if 'label_A' in data[index]: yield batch_frames, np.array([0])   #normal\n",
    "            else: yield batch_frames, np.array([1])   #abnormal\n",
    "            \n",
    "            #batch_frames_flip\n",
    "            if 'label_A' in data[index]: yield batch_frames_flip, np.array([0])  #normal\n",
    "            else: yield batch_frames_flip, np.array([1])  #abnormal\n",
    "        else:\n",
    "            #batch_frames\n",
    "            if 'label_A' in data[index]: yield batch_frames, np.array([0])   #normal\n",
    "            else: yield batch_frames, np.array([1])   #abnormal\n",
    "                \n",
    "    print(\"\\nloop_no=\",loop_no)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zugpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
