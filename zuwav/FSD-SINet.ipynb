{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1-beta6-dev\n",
      "/usr/local/lib/python3.8/site-packages/essentia/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import essentia\n",
    "print(essentia.__version__)\n",
    "print(essentia.__file__)\n",
    "import essentia.standard , essentia.streaming\n",
    "from essentia.standard import MonoLoader, TensorflowPredictFSDSINet\n",
    "\n",
    "# let's have a look at what is in there\n",
    "#print(dir(essentia.standard))\n",
    "\n",
    "from utils import util\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error while configuring TensorflowPredictFSDSINet: TensorflowPredict: could not open the Tensorflow graph file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m graph_filename \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfsd-sinet-vgg42-tlpf_aps-1.pb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m audio \u001b[39m=\u001b[39m MonoLoader(filename\u001b[39m=\u001b[39maac_fn[\u001b[39m1\u001b[39m], sampleRate\u001b[39m=\u001b[39m\u001b[39m22050\u001b[39m)()\n\u001b[0;32m----> 5\u001b[0m model \u001b[39m=\u001b[39m TensorflowPredictFSDSINet(graphFilename\u001b[39m=\u001b[39;49mgraph_filename)\n\u001b[1;32m      7\u001b[0m activations \u001b[39m=\u001b[39m model(audio)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/essentia/standard.py:44\u001b[0m, in \u001b[0;36m_create_essentia_class.<locals>.Algo.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m _essentia\u001b[39m.\u001b[39mAlgorithm\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name)\n\u001b[1;32m     43\u001b[0m \u001b[39m# configure the algorithm\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfigure(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/essentia/standard.py:64\u001b[0m, in \u001b[0;36m_create_essentia_class.<locals>.Algo.configure\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError cannot convert parameter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\\\n\u001b[1;32m     60\u001b[0m                         \u001b[39m%\u001b[39m(\u001b[39mstr\u001b[39m(_c\u001b[39m.\u001b[39mdetermineEdt(val)),\u001b[39mstr\u001b[39m(goalType))) \u001b[39m#\\''+name+'\\' parameter: '+str(e))\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     kwargs[name] \u001b[39m=\u001b[39m convertedVal\n\u001b[0;32m---> 64\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__configure__(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error while configuring TensorflowPredictFSDSINet: TensorflowPredict: could not open the Tensorflow graph file."
     ]
    }
   ],
   "source": [
    "mp4_fn,mp4_labels,aac_fn,aac_labels = util.load_xdv_test()\n",
    "graph_filename = \"fsd-sinet-vgg42-tlpf_aps-1.pb\"\n",
    "audio = MonoLoader(filename=aac_fn[1], sampleRate=22050)()\n",
    "model = TensorflowPredictFSDSINet(graphFilename=graph_filename)\n",
    "\n",
    "activations = model(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_from_average(data, top_n=10):\n",
    "    av = np.mean(data, axis=1)\n",
    "    sorting = np.argsort(av)[::-1]\n",
    "    return sorting[:top_n], [av[i] for i in sorting]\n",
    "\n",
    "# Read the metadata\n",
    "metadata_file = \"fsd-sinet-vgg42-tlpf_aps-1.json\"\n",
    "metadata = json.load(open(metadata_file, \"r\"))\n",
    "labels = metadata[\"classes\"]\n",
    "\n",
    "# Compute the top-n labels and predictions\n",
    "top_n, averages = top_from_average(predictions, top_n=15)\n",
    "top_labels = [labels[i] for i in top_n]\n",
    "top_labels_with_av = [\n",
    "    f\"{label} ({av:.3f})\" for label, av in zip(top_labels, averages)\n",
    "]\n",
    "\n",
    "top_predictions = np.array([predictions[i, :] for i in top_n])\n",
    "\n",
    "# Generate plots and improve formatting\n",
    "matfig = plt.figure(figsize=(8, 3))\n",
    "plt.matshow(top_predictions, fignum=matfig.number, aspect=\"auto\")\n",
    "\n",
    "plt.yticks(np.arange(len(top_labels_with_av)), top_labels_with_av)\n",
    "locs, _ = plt.xticks()\n",
    "ticks = np.array(locs // 2).astype(\"int\")\n",
    "plt.xticks(locs[1: -1], ticks[1: -1])\n",
    "plt.tick_params(\n",
    "    bottom=True, top=False, labelbottom=True, labeltop=False\n",
    ")\n",
    "plt.xlabel(\"(s)\")\n",
    "\n",
    "plt.savefig(\"activations.png\", bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zugpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
