{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model files\n",
    "\n",
    "[audio-event-recognition/fsd-sinet/](https://essentia.upf.edu/models/audio-event-recognition/fsd-sinet/)    \n",
    "\n",
    "!wget -q https://essentia.upf.edu/models/audio-event-recognition/fsd-sinet/fsd-sinet-vgg41-tlpf-1.pb\n",
    "\n",
    "!wget -q https://essentia.upf.edu/models/audio-event-recognition/fsd-sinet/fsd-sinet-vgg41-tlpf-1.json\n",
    "\n",
    "\n",
    "<https://mtg.github.io/essentia-labs/news/tensorflow/2023/02/08/fsdsinet-models/>\n",
    "    \n",
    "    tlpf : Trainable Low-Pass Filters\n",
    "    aps : Adaptive Polyphase Sampling\n",
    "\n",
    "    fsd-sinet-vgg42-tlpf_aps-1 - best\n",
    "    fsd-sinet-vgg41-tlpf-1 - lighter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import essentia\n",
    "print(essentia.__version__)\n",
    "print(essentia.__file__)\n",
    "import essentia.standard as es\n",
    "\n",
    "# let's have a look at what is in there\n",
    "#print(dir(essentia.standard))\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import utils.util as util\n",
    "import moviepy.editor as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' HELPERS '''\n",
    "#print(dir(essentia.standard))\n",
    "#print(help(es.MonoLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicition_complete(audio,nlabels2predict,printt=False,plott=False,save_plot=False):\n",
    "    \n",
    "    # Loading the model\n",
    "    graph_filename = \"/raid/DATASETS/.zuble/vigia/zuwav/fsd-sinet-essentia/models/fsd-sinet-vgg41-tlpf-1.pb\"\n",
    "    model = es.TensorflowPredictFSDSINet(graphFilename=graph_filename)\n",
    "\n",
    "    # Read the metadata\n",
    "    metadata_file = \"/raid/DATASETS/.zuble/vigia/zuwav/fsd-sinet-essentia/models/fsd-sinet-vgg41-tlpf-1.json\"\n",
    "    metadata = json.load(open(metadata_file, \"r\"))\n",
    "    labels = metadata[\"classes\"]\n",
    "    \n",
    "    \n",
    "    def top_from_average(data, top_n):\n",
    "        av = np.mean(data, axis=1)\n",
    "        sorting = np.argsort(av)[::-1]\n",
    "        return sorting[:top_n], [av[i] for i in sorting]\n",
    "\n",
    "    \n",
    "    def plot_predictions(top_preds, top_labels_w_av):\n",
    "    \n",
    "        # Generate plots and improve formatting\n",
    "        matfig = plt.figure(figsize=(8, 3))\n",
    "        plt.matshow(top_preds, fignum=matfig.number, aspect=\"auto\")\n",
    "\n",
    "        plt.yticks(np.arange(len(top_labels_w_av)), top_labels_with_av)\n",
    "        locs, _ = plt.xticks()\n",
    "        ticks = np.array(locs // 2).astype(\"int\")\n",
    "        plt.xticks(locs[1: -1], ticks[1: -1])\n",
    "        plt.tick_params(\n",
    "            bottom=True, top=False, labelbottom=True, labeltop=False\n",
    "        )\n",
    "        plt.xlabel(\"(s)\")\n",
    "\n",
    "        if save_plot : plt.savefig(\"activations.png\", bbox_inches='tight')\n",
    "    \n",
    "    \n",
    "    predictions = model(audio)\n",
    "\n",
    "    if printt:\n",
    "        for label, probability in zip(metadata['classes'], predictions.mean(axis=0)):\n",
    "            print(f'{label}: {100 * probability:.1f}%') \n",
    "\n",
    "    # Compute the top-n labels and predictions\n",
    "    top_n, averages = top_from_average(predictions,nlabels2predict)\n",
    "    \n",
    "    top_labels = [labels[i] for i in top_n]\n",
    "    if printt : print(top_labels)\n",
    "    \n",
    "    top_labels_with_av = [\n",
    "        f\"{label} ({av:.3f})\" for label, av in zip(top_labels, averages)\n",
    "    ]\n",
    "    if printt: print(top_labels_with_av)\n",
    "    \n",
    "    top_predictions = np.array([predictions[i, :] for i in top_n])\n",
    "    if plott: plot_predictions(top_predictions, top_labels_with_av)\n",
    "    \n",
    "    return top_labels_with_av\n",
    "\n",
    "\n",
    "def fdspredict_from_video(index,path):\n",
    "    \n",
    "    # cv video info\n",
    "    video = cv2.VideoCapture(path)\n",
    "    width  = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "    total_time = total_frames/fps\n",
    "    print(\"total_time\",total_time)\n",
    "    frame_time_ms = int(1000/fps)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontScale = 0.5;thickness = 1;lineType = cv2.LINE_AA\n",
    "    \n",
    "    videoo = mp.VideoFileClip(path)\n",
    "    print(videoo.duration)\n",
    "    return\n",
    "    # Extract the audio from the video\n",
    "    audio = mp.AudioFileClip(filename=path)#.fx(mp.afx.audio_normalize)\n",
    "    #audio_total_array = audio.to_soundarray()\n",
    "    #audio_total_array_mono = np.mean(audio_total_array, axis=1)\n",
    "    #audio_total_array_mono_single = audio_total_array_mono.astype(np.float32)\n",
    "   \n",
    "    \n",
    "    # predict over total array\n",
    "    #top_n1 = predicition_complete(audio_total_array_mono_single,5)\n",
    "    #print('total_array0',top_n1,'\\n\\n')\n",
    "    \n",
    "    \n",
    "    # predict over total saved wavfile\n",
    "    #fn2 = 'audio_mono_total'+str(index)+'.wav'\n",
    "    #es.MonoWriter(filename=fn2)(audio_total_array_mono_single)#sampleRate = int(22050)\n",
    "    \n",
    "    #audio_monoloader = es.MonoLoader(filename=fn2)()#, sampleRate=22050\n",
    "    #top_n2 = predicition_complete(audio_monoloader,5)\n",
    "    #print('total_wav2',top_n2,'\\n\\n')\n",
    "    \n",
    "    \n",
    "    '''#predict over framed explosion\n",
    "    #t_s=47;t_e=49 #680\n",
    "    t_s=3;t_e=4 #675\n",
    "    audio_explosion = audio.subclip(t_start=t_s,t_end=t_e)\n",
    "    audio_explosion_array = audio_explosion.to_soundarray()\n",
    "    audio_explosion_array_mono = np.mean(audio_explosion_array, axis=1)\n",
    "    audio_explosion_array_mono_single = audio_explosion_array_mono.astype(np.float32)\n",
    "    top_n3 = predicition_complete(audio_explosion_array_mono_single,5)\n",
    "    print('explosion_array000',top_n3,'\\n\\n')\n",
    "    fn3 = 'audio_mono_explosion'+str(index)+'.wav'\n",
    "    es.MonoWriter(filename=fn3)(audio_explosion_array_mono_single)'''\n",
    "    \n",
    "    \n",
    "    batch_len = 5*int(fps)\n",
    "    batch_step_len = batch_len\n",
    "    batch_steap_atual = 0\n",
    "    \n",
    "    batch_frame_step = 1\n",
    "    atual_label0 = atual_label00 = ''\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        ret, frame = video.read()\n",
    "        if not ret:break\n",
    "        video_atual_frame = int(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        \n",
    "        #video_atual_time = video.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "        #audio_frame = audio.subclip(video_atual_time , video_atual_time+(1/fps))\n",
    "        #audio_frame_array = np.array(audio_frame.to_soundarray())\n",
    "        \n",
    "        if video_atual_frame == batch_len + batch_step_len * batch_steap_atual:\n",
    "            #print(video_atual_frame)\n",
    "            \n",
    "            start = (batch_step_len * batch_steap_atual)/fps\n",
    "            end = video_atual_frame / fps\n",
    "            print(start,end)\n",
    "            \n",
    "            audio_batch = audio.subclip(t_start=start,t_end=end)\n",
    "            audio_batch_array = audio_batch.to_soundarray()\n",
    "            \n",
    "            nsamples = np.shape(audio_batch_array)[0]\n",
    "            secs = end-start\n",
    "            sample_rate = nsamples / secs\n",
    "            print(\"audio_batch_array\",audio_batch_array.dtype,np.shape(audio_batch_array), sample_rate)\n",
    "            \n",
    "            audio_batch_array_mono = np.mean(audio_batch_array, axis=1)\n",
    "            audio_batch_array_mono_single = audio_batch_array_mono.astype(np.float32)\n",
    "            print(\"mono_single\",audio_batch_array_mono_single.dtype,np.shape(audio_batch_array_mono_single))\n",
    "            top_n0 = predicition_complete(audio_batch_array_mono_single,4)\n",
    "            atual_label0 = str(top_n0[0])\n",
    "            print('batch_array',top_n0)\n",
    "            \n",
    "            \n",
    "            # 2 save as stereo\n",
    "            #es.AudioWriter(filename='audio_stereo.wav',sampleRate = int(sample_rate))(audio_batch_array)\n",
    "            \n",
    "            ## 1 transform stereo to mono\n",
    "            #fn00 = 'audio_mono_'+str(batch_steap_atual)+'.wav'\n",
    "            #es.MonoWriter(filename=fn00,sampleRate = int(sample_rate))(audio_batch_array_mono)\n",
    "            #audio_monoloader = es.MonoLoader(filename=fn00, sampleRate=22050)()\n",
    "            #top_n00 = predicition_complete(audio_monoloader,2)\n",
    "            #atual_label00 = str(top_n00[0])\n",
    "            #print('essentia',top_n00,'\\n\\n')\n",
    "            \n",
    "            \n",
    "            batch_steap_atual += 1\n",
    "            \n",
    "        cv2.putText(frame, '%d' % (video_atual_frame)+'/'+str(int(total_frames)), (5, int(height)-7),font,fontScale,[60,250,250],thickness,lineType)    \n",
    "        cv2.putText(frame,str(atual_label0)+' '+str(batch_steap_atual),(10,15),font,fontScale,[0,0,255],thickness,lineType)  \n",
    "        cv2.putText(frame,str(atual_label00)+' '+str(batch_steap_atual),(10,30),font,fontScale,[0,0,255],thickness,lineType)  \n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "        key = cv2.waitKey(frame_time_ms)  \n",
    "        if key == ord('q'): break  # quit\n",
    "        if key == ord(' '):  # pause\n",
    "            while True:\n",
    "                key = cv2.waitKey(1)\n",
    "                if key == ord(' '):break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_watch_live(watch_this):\n",
    "    print(\"\\n\\nINIT WATCH LIVE\")\n",
    "    \n",
    "    test_mp4_paths,test_mp4_labels,test_aac_paths,test_aac_labels = util.load_xdv_test(util.SERVER_TEST_AUD_ORIG_PATH)\n",
    "    print('\\n  test_mp4_paths',np.shape(test_mp4_paths))\n",
    "\n",
    "    test_labels_indexs = util.get_index_per_label_from_filelist(test_mp4_paths)\n",
    "\n",
    "    print('\\n  watching',watch_this)\n",
    "    for labels_2_watch in watch_this:\n",
    "        print('  ',labels_2_watch,' : ',test_labels_indexs[labels_2_watch])\n",
    "        \n",
    "        all_or_specific = input(\"\\n\\nall indxs : enter  |  specific indxs : ex 3,4,77,7  |  dry_run no as window : dr\\n\\n\")\n",
    "        \n",
    "        if all_or_specific == \"\": # all\n",
    "            for i in range(len(test_labels_indexs[labels_2_watch])):\n",
    "                index = test_labels_indexs[labels_2_watch][i]\n",
    "                path = test_mp4_paths[index]\n",
    "                print('\\n#-------------------#$%--------------------#\\n',labels_2_watch,index,path)\n",
    "                fdspredict_from_video(index,path)\n",
    "        elif all_or_specific == \"dr\": \n",
    "            for i in range(len(test_labels_indexs[labels_2_watch])):\n",
    "                index = test_labels_indexs[labels_2_watch][i]\n",
    "                path = test_mp4_paths[index]\n",
    "                print('\\n#-------------------#$%--------------------#\\n',labels_2_watch,index,path) \n",
    "        else: # specific\n",
    "            all_or_specific = all_or_specific.split(\",\")\n",
    "            all_or_specific = [int(num) for num in all_or_specific]\n",
    "            for index in all_or_specific:\n",
    "                path = test_mp4_paths[index]\n",
    "                print('\\n#-------------------#$%--------------------#\\n',labels_2_watch,index,path)\n",
    "                fdspredict_from_video(index,path)\n",
    "\n",
    "\n",
    "'''\n",
    "    A  NORMAL\n",
    "    B1 FIGHT\n",
    "    B2 SHOOTING\n",
    "    B4 RIOT\n",
    "    B5 ABUSE\n",
    "    B6 CAR ACCIDENT\n",
    "    G  EXPLOSION \n",
    "    BG ALL ANOMALIES\n",
    "'''\n",
    "\n",
    "init_watch_live(watch_this=['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mp4_paths,test_mp4_labels,test_aac_paths,test_aac_labels = util.load_xdv_test(util.SERVER_TEST_AUD_ORIG_PATH)\n",
    "for path in test_mp4_paths:\n",
    "    util.recreate_mp4_with_right_duration(path)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = ['/raid/DATASETS/anomaly/XD_Violence/testing_copy/A.Beautiful.Mind.2001__#00-25-20_00-29-20_label_A_1.mp4']\n",
    "util.print_acodec_from_mp4(tt,printt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''class FSDSINET():\n",
    "    def __init__(self , index):\n",
    "        # Loading the model\n",
    "        self.graph_filename = \"/raid/DATASETS/.zuble/vigia/zuwav/fsd-sinet-essentia/models/fsd-sinet-vgg41-tlpf-1.pb\"\n",
    "        self.model = TensorflowPredictFSDSINet(graphFilename=self.graph_filename)\n",
    "\n",
    "        # Read the metadata\n",
    "        self.metadata_file = \"/raid/DATASETS/.zuble/vigia/zuwav/fsd-sinet-essentia/models/fsd-sinet-vgg41-tlpf-1.json\"\n",
    "        self.metadata = json.load(open(self.metadata_file, \"r\"))\n",
    "        self.labels = self.metadata[\"classes\"]\n",
    "\n",
    "        self.mp4_fn,self.mp4_labels,self.aac_fn,self.aac_labels = util.load_xdv_test(util.SERVER_TEST_AUD_MONO_PATH)\n",
    "        self.audio = MonoLoader(filename=self.aac_fn[index], sampleRate=22050)()\n",
    "        print(self.aac_fn[index],np.shape(self.audio))\n",
    "    \n",
    "    def top_from_average(self, data , top_n=5):\n",
    "        av = np.mean(data, axis=1)\n",
    "        sorting = np.argsort(av)[::-1]\n",
    "        return sorting[:top_n], [av[i] for i in sorting]\n",
    "    \n",
    "    def plot_predictions(self, top_predictions, top_labels_with_av , save=False):\n",
    "    \n",
    "        # Generate plots and improve formatting\n",
    "        matfig = plt.figure(figsize=(8, 3))\n",
    "        plt.matshow(top_predictions, fignum=matfig.number, aspect=\"auto\")\n",
    "\n",
    "        plt.yticks(np.arange(len(top_labels_with_av)), top_labels_with_av)\n",
    "        locs, _ = plt.xticks()\n",
    "        ticks = np.array(locs // 2).astype(\"int\")\n",
    "        plt.xticks(locs[1: -1], ticks[1: -1])\n",
    "        plt.tick_params(\n",
    "            bottom=True, top=False, labelbottom=True, labeltop=False\n",
    "        )\n",
    "        plt.xlabel(\"(s)\")\n",
    "\n",
    "        if save : plt.savefig(\"activations.png\", bbox_inches='tight')\n",
    "        \n",
    "    \n",
    "    def predicition_complete(self,nlabels2predict,printt=False,plott=False):\n",
    "        print(\"predict\")\n",
    "        predictions = self.model(self.audio)\n",
    "        print(\"done\")\n",
    "        if printt:\n",
    "            for label, probability in zip(self.labels, predictions.mean(axis=0)):\n",
    "                print(f'{label}: {100 * probability:.1f}%') \n",
    "\n",
    "        # Compute the top-n labels and predictions\n",
    "        top_n, averages = self.top_from_average(predictions,top_n=nlabels2predict)\n",
    "        top_labels = [self.labels[i] for i in top_n]\n",
    "\n",
    "        top_labels_with_av = [\n",
    "            f\"{label} ({av:.3f})\" for label, av in zip(top_labels, averages)\n",
    "        ]\n",
    "\n",
    "        top_predictions = np.array([predictions[i, :] for i in top_n])\n",
    "        \n",
    "        if plott: self.plot_predictions(top_predictions, top_labels_with_av)\n",
    "        \n",
    "        return top_labels'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fsdsinet = FSDSINET(475)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fsdsinet.predicition_complete(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zugpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f7bf267530dde59ab6764f0eb5f1b22dea8a9c4ca62db1182ae079b8b4c02bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
