{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model files\n",
    "\n",
    "[audio-event-recognition/fsd-sinet/](https://essentia.upf.edu/models/audio-event-recognition/fsd-sinet/)    \n",
    "\n",
    "!wget -q https://essentia.upf.edu/models/audio-event-recognition/fsd-sinet/fsd-sinet-vgg41-tlpf-1.pb\n",
    "\n",
    "!wget -q https://essentia.upf.edu/models/audio-event-recognition/fsd-sinet/fsd-sinet-vgg41-tlpf-1.json\n",
    "\n",
    "\n",
    "<https://mtg.github.io/essentia-labs/news/tensorflow/2023/02/08/fsdsinet-models/>\n",
    "    \n",
    "    tlpf : Trainable Low-Pass Filters\n",
    "    aps : Adaptive Polyphase Sampling\n",
    "\n",
    "    fsd-sinet-vgg42-tlpf_aps-1 - best\n",
    "    fsd-sinet-vgg41-tlpf-1 - lighter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import essentia\n",
    "print(essentia.__version__)\n",
    "print(essentia.__file__)\n",
    "import essentia.standard as es\n",
    "\n",
    "# let's have a look at what is in there\n",
    "#print(dir(essentia.standard))\n",
    "\n",
    "\n",
    "import threading , cv2 , os , time , json\n",
    "import matplotlib.pyplot as plt\n",
    "from queue import Queue\n",
    "import numpy as np\n",
    "\n",
    "import utils.util as util\n",
    "import moviepy.editor as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pstats\n",
    "\n",
    "# Load the profiling data from the .prof file\n",
    "stats = pstats.Stats('profile.prof')\n",
    "\n",
    "# Sort the profiling data by cumulative time\n",
    "stats.sort_stats('cumulative')\n",
    "\n",
    "# Print the profiling data to the console\n",
    "stats.print_stats()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' HELPERS '''\n",
    "#print(dir(essentia.standard))\n",
    "#print(help(es.AudioLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://essentia.upf.edu/reference/streaming_TensorflowPredictFSDSINet.html\n",
    "\n",
    "batchSize:\n",
    "    integer ∈ [-1,inf) (default = 64)\n",
    "    the batch size for prediction. This allows parallelization when GPUs are\n",
    "    available. Set it to -1 or 0 to accumulate all the patches and run a single\n",
    "    TensorFlow session at the end of the stream\n",
    "\n",
    "graphFilename:\n",
    "    string (default = \"\")\n",
    "    the name of the file from which to load the TensorFlow graph\n",
    "\n",
    "input:\n",
    "    string (default = \"x\")\n",
    "    the name of the input node in the TensorFlow graph\n",
    "\n",
    "lastPatchMode:\n",
    "    string ∈ {discard,repeat} (default = \"discard\")\n",
    "    what to do with the last frames: `repeat` them to fill the last patch or\n",
    "    `discard` them\n",
    "\n",
    "normalize:\n",
    "    bool ∈ {false,true} (default = true)\n",
    "    whether to normalize the input audio signal. Note that this parameter is\n",
    "    only available in standard mode\n",
    "\n",
    "output:\n",
    "    string (default = \"model/predictions/Sigmoid\")\n",
    "    the name of the node from which to retrieve the output tensors\n",
    "\n",
    "patchHopSize:\n",
    "    integer ∈ [0,inf) (default = 50)\n",
    "    number of frames between the beginnings of adjacent patches. 0 to avoid\n",
    "    overlap\n",
    "\n",
    "savedModel:\n",
    "    string (default = \"\")\n",
    "    the name of the TensorFlow SavedModel. Overrides parameter `graphFilename`\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' predicts per batch array while cv displaying'''\n",
    "class FSDSINET_live():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Loading the model\n",
    "        self.graph_filename = \"/raid/DATASETS/.zuble/vigia/zuwav/fsd-sinet-essentia/models/fsd-sinet-vgg41-tlpf-1.pb\"\n",
    "        self.model = es.TensorflowPredictFSDSINet(graphFilename=self.graph_filename)\n",
    "\n",
    "        # Read the metadata\n",
    "        self.metadata_file = \"/raid/DATASETS/.zuble/vigia/zuwav/fsd-sinet-essentia/models/fsd-sinet-vgg41-tlpf-1.json\"\n",
    "        self.metadata = json.load(open(self.metadata_file, \"r\"))\n",
    "        self.labels = self.metadata[\"classes\"]\n",
    "        self.anom_labels = [\"Alarm\",\"Boom\",\"Crowd\",\"Dog\",\"Drill\",\"Explosion\",\"Fire\",\"Gunshot and gunfire\",\"Hammer\",\"Screaming\",\"Screech\",\\\n",
    "                            \"Shatter\",\"Shout\",\"Siren\",\"Slam\",\"Squeak\",\"Yell\"]\n",
    "        self.anom_labels_i = [4,18,51,59,65,72,78,92,94,145,146,147,148,152,154,161,198]\n",
    "        \n",
    "        # get file list\n",
    "        self.mp4_fn, *_ = util.load_xdv_test(util.SERVER_TEST_AUD_MONO_PATH)\n",
    "        \n",
    "        self.test_config = {\n",
    "            \"batch_len_secs\":2,\n",
    "            \"batch_step_secs\": 1,\n",
    "            \"audio_fs_input\":22050\n",
    "        }\n",
    "      \n",
    "      \n",
    "    def plot_predictions(self, top_preds, top_labels_w_av,top_labels_with_av):\n",
    "        # Generate plots and improve formatting\n",
    "        matfig = plt.figure(figsize=(8, 3))\n",
    "        plt.matshow(top_preds, fignum=matfig.number, aspect=\"auto\")\n",
    "\n",
    "        plt.yticks(np.arange(len(top_labels_w_av)), top_labels_with_av)\n",
    "        locs, _ = plt.xticks()\n",
    "        ticks = np.array(locs // 2).astype(\"int\")\n",
    "        plt.xticks(locs[1: -1], ticks[1: -1])\n",
    "        plt.tick_params(bottom=True, top=False, labelbottom=True, labeltop=False)\n",
    "        plt.xlabel(\"(s)\")\n",
    "        plt.show()\n",
    "        if self.save_plot : plt.savefig(\"activations.png\", bbox_inches='tight')\n",
    "        \n",
    "    def process_rslt_all(self,predictions):\n",
    "        \n",
    "        def top_from_average(data):\n",
    "            av = np.mean(data, axis=0)\n",
    "            sorting = np.argsort(av)[::-1]\n",
    "            return sorting[:self.nlabels2predict], [av[i] for i in sorting] ,av\n",
    "\n",
    "        top_labels_i, averages_sorted , averages = top_from_average(predictions)\n",
    "        top_labels = [self.labels[i] for i in top_labels_i]\n",
    "        top_labels_with_av = [f\"{label} ({av:.3f})\" for label, av in zip(top_labels, averages_sorted)]\n",
    "        top_predictions = np.array([predictions[:,i] for i in top_labels_i])\n",
    "        \n",
    "        return top_labels, top_labels_with_av, top_predictions\n",
    "    \n",
    "    def process_rslt_anom(self,predictions):\n",
    "        \n",
    "        def top_from_anomaly(data):\n",
    "            av = np.mean(data, axis=0)\n",
    "            sorting = np.argsort(av)[::-1]\n",
    "            sorting_anom = [x for x in sorting if x in self.anom_labels_i]\n",
    "            return sorting_anom[:self.nlabels2predict],[av[i] for i in sorting_anom]\n",
    "\n",
    "        top_labels_anom_i, averages_anom_sorted = top_from_anomaly(predictions)\n",
    "        top_labels_anom = [self.labels[i] for i in top_labels_anom_i]\n",
    "        top_labels_anom_with_av = [f\"{label} ({av:.3f})\" for label, av in zip(top_labels_anom, averages_anom_sorted)]\n",
    "        top_predictions_anom = np.array([predictions[:,i] for i in top_labels_anom_i])\n",
    "        \n",
    "        return top_labels_anom, top_labels_anom_with_av,top_predictions_anom\n",
    "\n",
    "    def predicition(self,audio2predict,printt=True,plott=False,save_plot=False):\n",
    "        \n",
    "        self.save_plot = save_plot\n",
    "    \n",
    "        predictions = self.model(audio2predict)\n",
    "        print(\"predictions_shape\",np.shape(predictions))\n",
    "\n",
    "        top_labels, top_labels_with_av ,top_predictions = self.process_rslt_all(predictions)   \n",
    "        top_labels_anom, top_labels_anom_with_av,top_predictions_anom = self.process_rslt_anom(predictions)     \n",
    "\n",
    "        if printt:\n",
    "            #print(\"\\nall\", top_labels_with_av)\n",
    "            print(\"anom\", top_labels_anom_with_av)\n",
    "            #for label, probability in zip(self.metadata['classes'], predictions.mean(axis=0)):\n",
    "            #    print(f'{label}: {100 * probability:.1f}%') \n",
    "        if plott:\n",
    "            self.plot_predictions(top_predictions_anom,top_labels_anom_with_av,top_labels_anom_with_av)\n",
    "                \n",
    "        return top_labels_with_av,top_labels_anom_with_av\n",
    "\n",
    "\n",
    "    def prediction_thread(self,batchinfo_queque , as_queque ):\n",
    "        \n",
    "        resampler = es.Resample(inputSampleRate=self.mp4_fs_aac, outputSampleRate=self.test_config[\"audio_fs_input\"])\n",
    "        \n",
    "        # get full audio from atual mp4\n",
    "        audio_mp = mp.AudioFileClip(filename=self.path,fps=self.mp4_fs_aac)#.fx(mp.afx.audio_normalize)\n",
    "        audio_es = mp.AudioFileClip(filename=self.path,fps=self.mp4_fs_aac)\n",
    "        \n",
    "        \n",
    "        while True:\n",
    "            start, end = batchinfo_queque.get()\n",
    "            \n",
    "            # checks for close signal\n",
    "            if start == -1 and end == -1:\n",
    "                audio_mp.close() ; audio_es.close()\n",
    "                break\n",
    "                \n",
    "            # MOVIEPY \n",
    "            audio_batch_mp = audio_mp.subclip(t_start=start,t_end=end)\n",
    "            audio_batch_array = audio_batch_mp.to_soundarray(fps = self.test_config[\"audio_fs_input\"])\n",
    "            audio_batch_array_mp = np.mean(audio_batch_array, axis=1).astype(np.float32)\n",
    "            \n",
    "            #print(\"mp_batch\")\n",
    "            top_mp = self.predicition(audio_batch_array_mp,printt=False)\n",
    "              \n",
    "            \n",
    "            # ESSENTIA\n",
    "            audio_batch_es = audio_es.subclip(t_start=start,t_end=end)\n",
    "            audio_batch_array2 = audio_batch_es.to_soundarray()\n",
    "            audio_batch_array_mono_single2 = np.mean(audio_batch_array2, axis=1).astype(np.float32)\n",
    "            audio_bacth_array_essentia = resampler(audio_batch_array_mono_single2) \n",
    "            \n",
    "            #print(\"essentia_batch\")\n",
    "            top_es = self.predicition(audio_bacth_array_essentia,printt=False)\n",
    "            \n",
    "            \n",
    "            print(\"mp\",np.shape(audio_batch_array_mp),\"\\nessentia\",np.shape(audio_bacth_array_essentia))\n",
    "            as_queque.put((top_mp,top_es))\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def fdspredict_from_video(self,index,path,nlabels2predict):\n",
    "        \n",
    "        self.nlabels2predict = nlabels2predict\n",
    "        \n",
    "        ''' CV video info '''\n",
    "        self.path = path; self.index = index\n",
    "        video = cv2.VideoCapture(path)\n",
    "        width  = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        self.fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "        total_time = total_frames/self.fps\n",
    "        print(\"total_time\",total_time,\"self.fps\",self.fps)\n",
    "        \n",
    "        \n",
    "        ''' CV window info '''\n",
    "        frame_time_ms = int(1000/self.fps)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX;fontScale = 0.5;thickness = 1;lineType = cv2.LINE_AA\n",
    "        strap_video_name = os.path.splitext(os.path.basename(path))[0]\n",
    "        wn='asVwR @ '+str(index)+strap_video_name\n",
    "        cv2.namedWindow(wn) \n",
    "        \n",
    "        \n",
    "        ''' FS converter '''\n",
    "        self.mp4_fs_aac = util.print_acodec_from_mp4([path],only_sr=True) # get audio stream fs from mp4 \n",
    "        print(\"mp4_fs_aac\",self.mp4_fs_aac)\n",
    "        resampler = es.Resample(inputSampleRate=self.mp4_fs_aac, outputSampleRate=self.test_config[\"audio_fs_input\"])\n",
    "        \n",
    "        \n",
    "        ''' THREAD prediction creation '''\n",
    "        ## Create the input and as queues\n",
    "        batchinfo_queque = Queue()\n",
    "        as_queque = Queue()\n",
    "        \n",
    "        # Create the prediction thread\n",
    "        prediction_thread = threading.Thread(target=self.prediction_thread, args=(batchinfo_queque , as_queque))\n",
    "        prediction_thread.start()\n",
    "        \n",
    "        \n",
    "        ''' BATCH init '''\n",
    "        batch_len = self.test_config[\"batch_len_secs\"]*int(self.fps)\n",
    "        batch_step_len = self.test_config[\"batch_step_secs\"]*int(self.fps)\n",
    "        batch_step_atual = 0 \n",
    "        \n",
    "\n",
    "        top_mp3 = top_es3 = [['','',''],['','','']]\n",
    "        while True:\n",
    "            \n",
    "            ret, frame = video.read()\n",
    "            if not ret:break\n",
    "            video_atual_frame = int(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            \n",
    "            #video_atual_time = video.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "            #audio_frame = audio.subclip(video_atual_time , video_atual_time+(1/fps))\n",
    "            #audio_frame_array = np.array(audio_frame.to_soundarray())\n",
    "            \n",
    "            if video_atual_frame == batch_len + batch_step_len * batch_step_atual:\n",
    "                #print(video_atual_frame)\n",
    "                \n",
    "                # set start and end of batch in secs to use in mp.subclip\n",
    "                start = (batch_step_len * batch_step_atual)/self.fps\n",
    "                end = video_atual_frame / self.fps\n",
    "                print('\\n******************************************',\\\n",
    "                        batch_step_atual,start,end)\n",
    "                \n",
    "                # inject start and stop secs to queque\n",
    "                try: batchinfo_queque.put_nowait((start, end))\n",
    "                except: pass\n",
    "                \n",
    "                batch_step_atual += 1\n",
    "            \n",
    "            \n",
    "            # Get aas if ready\n",
    "            try: top_mp3,top_es3 = as_queque.get_nowait() # Use this to prefer smooth display over frame/text shift\n",
    "            except: pass\n",
    "             \n",
    "            # frames / secs   \n",
    "            cv2.putText(frame, '%d' % (video_atual_frame)+'/'+str(int(total_frames)), (5, int(height)-7),font,fontScale,[60,250,250],thickness,lineType)    \n",
    "            cv2.putText(frame, '%.2f' % (video_atual_frame/self.fps)+'s',(5,int(height)-25),font,fontScale, [80,100,250],thickness,lineType)\n",
    "          \n",
    "            # aas\n",
    "            cv2.putText(frame,str(top_mp3[1][0])+'\\n'+str(top_mp3[1][1])+'\\n'+str(top_mp3[1][2])+'\\n'+str(batch_step_atual),(10,15),font,fontScale,[0,0,255],thickness,lineType)  \n",
    "            cv2.putText(frame,str(top_es3[1][0])+'\\n'+str(top_es3[1][1])+'\\n'+str(top_es3[1][2])+str(batch_step_atual),(10,30),font,fontScale,[0,0,255],thickness,lineType)  \n",
    "            \n",
    "            cv2.imshow(wn, frame)\n",
    "            \n",
    "            key = cv2.waitKey(frame_time_ms)  \n",
    "            if key == ord('q'): break  # quit\n",
    "            if key == ord(' '):  # pause\n",
    "                while True:\n",
    "                    key = cv2.waitKey(1)\n",
    "                    if key == ord(' '):break\n",
    "        \n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        print(\"signal frame queue to close\")\n",
    "        batchinfo_queque.put_nowait((-1, -1))\n",
    "        \n",
    "        print(\"closing predict thread\")\n",
    "        prediction_thread.join()\n",
    "\n",
    "def init_watch_live(watch_this):\n",
    "    print(\"\\n\\nINIT WATCH LIVE\")\n",
    "    \n",
    "    test_mp4_paths,*_ = util.load_xdv_test(util.SERVER_TEST_AUD_ORIG_PATH)\n",
    "    print('\\n  test_mp4_paths',np.shape(test_mp4_paths))\n",
    "\n",
    "    test_labels_indexs = util.get_index_per_label_from_filelist(test_mp4_paths)\n",
    "\n",
    "    fsdsinet = FSDSINET_live()\n",
    "\n",
    "    print('\\n  watching',watch_this)\n",
    "    for labels_2_watch in watch_this:\n",
    "        print('  ',labels_2_watch,' : ',test_labels_indexs[labels_2_watch])\n",
    "        \n",
    "        all_or_specific = input(\"\\n\\nall indxs : enter  |  specific indxs : ex 3,4,77,7  |  dry_run no as window : dr\\n\\n\")\n",
    "        \n",
    "        if all_or_specific == \"\": # all\n",
    "            for i in range(len(test_labels_indexs[labels_2_watch])):\n",
    "                index = test_labels_indexs[labels_2_watch][i]\n",
    "                path = test_mp4_paths[index]\n",
    "                print('\\n#-------------------#$%--------------------#\\n',labels_2_watch,index,path)\n",
    "                fsdsinet.fdspredict_from_video(index,path,10)\n",
    "        elif all_or_specific == \"dr\": \n",
    "            for i in range(len(test_labels_indexs[labels_2_watch])):\n",
    "                index = test_labels_indexs[labels_2_watch][i]\n",
    "                path = test_mp4_paths[index]\n",
    "                print('\\n#-------------------#$%--------------------#\\n',labels_2_watch,index,path) \n",
    "        \n",
    "        else: # specific\n",
    "            all_or_specific = all_or_specific.split(\",\")\n",
    "            all_or_specific = [int(num) for num in all_or_specific]\n",
    "            for index in all_or_specific:\n",
    "                path = test_mp4_paths[index]\n",
    "                print('\\n#-------------------#$%--------------------#\\n',labels_2_watch,index,path)\n",
    "                fsdsinet.fdspredict_from_video(index,path,10)\n",
    "\n",
    "'''\n",
    "    A  NORMAL  \n",
    "    B1 FIGHT | B2 SHOOTING | B4 RIOT | B5 ABUSE | B6 CAR ACCIDENT | G  EXPLOSION \n",
    "    BG ALL ANOMALIES\n",
    "'''\n",
    "init_watch_live(watch_this=['B2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' predicts per batch array while cv displaying'''\n",
    "class FSDSINET():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Loading the model\n",
    "        self.graph_filename = \"/raid/DATASETS/.zuble/vigia/zuwav/fsd-sinet-essentia/models/fsd-sinet-vgg41-tlpf-1.pb\"\n",
    "        self.model = es.TensorflowPredictFSDSINet(graphFilename=self.graph_filename)\n",
    "\n",
    "        # Read the metadata\n",
    "        self.metadata_file = \"/raid/DATASETS/.zuble/vigia/zuwav/fsd-sinet-essentia/models/fsd-sinet-vgg41-tlpf-1.json\"\n",
    "        self.metadata = json.load(open(self.metadata_file, \"r\"))\n",
    "        self.labels = self.metadata[\"classes\"]\n",
    "        self.anom_labels = [\"Alarm\",\"Boom\",\"Crowd\",\"Dog\",\"Drill\",\"Explosion\",\"Fire\",\"Gunshot and gunfire\",\"Hammer\",\"Screaming\",\"Screech\",\\\n",
    "                            \"Shatter\",\"Shout\",\"Siren\",\"Slam\",\"Squeak\",\"Yell\"]\n",
    "        self.anom_labels_i = [4,18,51,59,65,72,78,92,94,145,146,147,148,152,154,161,198]\n",
    "        \n",
    "        # get file list\n",
    "        self.mp4_fn, *_ = util.load_xdv_test(util.SERVER_TEST_AUD_MONO_PATH)\n",
    "        \n",
    "        self.test_config = {\n",
    "            \"batch_len_secs\":2,\n",
    "            \"batch_step_secs\": 1,\n",
    "            \"audio_fs_input\":22050\n",
    "        }\n",
    "        \n",
    "    def plot_predictions(self, top_preds, top_labels_w_av,top_labels_with_av):\n",
    "        # Generate plots and improve formatting\n",
    "        matfig = plt.figure(figsize=(8, 3))\n",
    "        plt.matshow(top_preds, fignum=matfig.number, aspect=\"auto\")\n",
    "\n",
    "        plt.yticks(np.arange(len(top_labels_w_av)), top_labels_with_av)\n",
    "        locs, _ = plt.xticks()\n",
    "        ticks = np.array(locs // 2).astype(\"int\")\n",
    "        plt.xticks(locs[1: -1], ticks[1: -1])\n",
    "        plt.tick_params(bottom=True, top=False, labelbottom=True, labeltop=False)\n",
    "        plt.xlabel(\"(s)\")\n",
    "        plt.show()\n",
    "        if self.save_plot : plt.savefig(\"activations.png\", bbox_inches='tight')\n",
    "        \n",
    "    def process_rslt_all(self,predictions):\n",
    "        \n",
    "        def top_from_average(data):\n",
    "            av = np.mean(data, axis=0)\n",
    "            sorting = np.argsort(av)[::-1]\n",
    "            return sorting[:self.nlabels2predict], [av[i] for i in sorting] ,av\n",
    "\n",
    "        top_labels_i, averages_sorted , averages = top_from_average(predictions)\n",
    "        top_labels = [self.labels[i] for i in top_labels_i]\n",
    "        top_labels_with_av = [f\"{label} ({av:.3f})\" for label, av in zip(top_labels, averages_sorted)]\n",
    "        top_predictions = np.array([predictions[:,i] for i in top_labels_i])\n",
    "        \n",
    "        return top_labels, top_labels_with_av, top_predictions\n",
    "    \n",
    "    def process_rslt_anom(self,predictions):\n",
    "        \n",
    "        def top_from_anomaly(data):\n",
    "            av = np.mean(data, axis=0)\n",
    "            sorting = np.argsort(av)[::-1]\n",
    "            sorting_anom = [x for x in sorting if x in self.anom_labels_i]\n",
    "            return sorting_anom[:self.nlabels2predict],[av[i] for i in sorting_anom]\n",
    "\n",
    "        top_labels_anom_i, averages_anom_sorted = top_from_anomaly(predictions)\n",
    "        top_labels_anom = [self.labels[i] for i in top_labels_anom_i]\n",
    "        top_labels_anom_with_av = [f\"{label} ({av:.3f})\" for label, av in zip(top_labels_anom, averages_anom_sorted)]\n",
    "        top_predictions_anom = np.array([predictions[:,i] for i in top_labels_anom_i])\n",
    "        \n",
    "        return top_labels_anom, top_labels_anom_with_av,top_predictions_anom\n",
    "\n",
    "    def predicition(self,audio2predict,printt=True,plott=False,save_plot=False):\n",
    "        \n",
    "        self.save_plot = save_plot\n",
    "    \n",
    "        predictions = self.model(audio2predict)\n",
    "        print(\"predictions_shape\",np.shape(predictions))\n",
    "\n",
    "        top_labels, top_labels_with_av ,top_predictions = self.process_rslt_all(predictions)   \n",
    "        top_labels_anom, top_labels_anom_with_av,top_predictions_anom = self.process_rslt_anom(predictions)     \n",
    "\n",
    "        if printt:\n",
    "            #print(\"\\nall\", top_labels_with_av)\n",
    "            print(\"anom\", top_labels_anom_with_av)\n",
    "            #for label, probability in zip(self.metadata['classes'], predictions.mean(axis=0)):\n",
    "            #    print(f'{label}: {100 * probability:.1f}%') \n",
    "        if plott:\n",
    "            self.plot_predictions(top_predictions_anom,top_labels_anom_with_av,top_labels_anom_with_av)\n",
    "                \n",
    "        return top_labels_with_av,top_labels_anom_with_av\n",
    "\n",
    "       \n",
    "    def fdspredict_from_video(self,index,path,nlabels2predict):\n",
    "        \n",
    "        self.nlabels2predict = nlabels2predict\n",
    "        \n",
    "        ''' CV video info '''\n",
    "        self.path = path; self.index = index\n",
    "        video = cv2.VideoCapture(path)\n",
    "        width  = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        self.fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "        total_time = total_frames/self.fps\n",
    "        print(\"total_time\",total_time)\n",
    "        \n",
    "        \n",
    "        ''' CV window info '''\n",
    "        frame_time_ms = int(1000/self.fps)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX;fontScale = 0.5;thickness = 1;lineType = cv2.LINE_AA\n",
    "        strap_video_name = os.path.splitext(os.path.basename(path))[0]\n",
    "        wn='asVwR @ '+str(index)+strap_video_name\n",
    "        cv2.namedWindow(wn) \n",
    "        \n",
    "        \n",
    "        ''' FS converter '''\n",
    "        self.mp4_fs_aac = util.print_acodec_from_mp4([path],only_sr=True) # get audio stream fs from mp4 \n",
    "        print(\"mp4_fs_aac\",self.mp4_fs_aac)\n",
    "        resampler = es.Resample(inputSampleRate=self.mp4_fs_aac, outputSampleRate=self.test_config[\"audio_fs_input\"])\n",
    "          \n",
    "        \n",
    "        ''' predicts over total audio array'''\n",
    "\n",
    "        # MOVIEPY\n",
    "        tti = time.time()\n",
    "        audio_mp = mp.AudioFileClip(filename=path,fps=self.mp4_fs_aac)#.fx(mp.afx.audio_normalize)\n",
    "        print(\"audio\",audio_mp,\"fps\",audio_mp.fps,\"nch\",audio_mp.nchannels)\n",
    "        audio_total_array = audio_mp.to_soundarray(fps=self.test_config[\"audio_fs_input\"])\n",
    "        audio_total_array_mono_single = np.mean(audio_total_array, axis=1).astype(np.float32)\n",
    "        \n",
    "        _ = self.predicition(audio_total_array_mono_single,printt=False,plott=True)\n",
    "        ttf = time.time()\n",
    "        print(\"total_MOVIEPY_time\",ttf-tti)\n",
    "        \n",
    "        #ESSENTIA\n",
    "        tti2 = time.time()\n",
    "        audio_es = mp.AudioFileClip(filename=path,fps=self.mp4_fs_aac)\n",
    "        audio2_array = audio_es.to_soundarray()\n",
    "        audio2_array_mono = np.mean(audio2_array, axis=1)\n",
    "        audio2_array_mono_single = audio2_array_mono.astype(np.float32)\n",
    "        audio2__array_essentia = resampler(audio2_array_mono_single) \n",
    "        \n",
    "        _ = self.predicition(audio2__array_essentia,printt=False,plott=True)\n",
    "        ttf2 = time.time()\n",
    "        print(\"total_ESSENTIA_time\",ttf2-tti2)\n",
    "        \n",
    "        \n",
    "        # predict over total saved wavfile\n",
    "        #fn2 = 'audio_mono_total'+str(index)+'.wav'\n",
    "        #es.MonoWriter(filename=fn2 , sampleRate = 22050)(audio2__array_essentia)\n",
    "        #aaa = es.MonoLoader(filename=fn2, sampleRate=22050)()\n",
    "        #top_n2,*_ = self.predicition(aaa,5)\n",
    "        \n",
    "        \n",
    "\n",
    "        batch_len = self.test_config[\"batch_len_secs\"]*int(self.fps)\n",
    "        batch_step_len = self.test_config[\"batch_step_secs\"]*int(self.fps)\n",
    "        batch_step_atual = 0 \n",
    "        \n",
    "        atual_label_mp0=atual_label_mp1=atual_label_mp2 = ''\n",
    "        atual_label_es0=atual_label_es1=atual_label_es2 = ''\n",
    "        while True:\n",
    "            \n",
    "            ret, frame = video.read()\n",
    "            if not ret:break\n",
    "            video_atual_frame = int(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            \n",
    "            #video_atual_time = video.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "            #audio_frame = audio.subclip(video_atual_time , video_atual_time+(1/fps))\n",
    "            #audio_frame_array = np.array(audio_frame.to_soundarray())\n",
    "            \n",
    "            if video_atual_frame == batch_len + batch_step_len * batch_step_atual:\n",
    "                #print(video_atual_frame)\n",
    "                \n",
    "                # set start and end of batch in secs to use in mp.subclip\n",
    "                start = (batch_step_len * batch_step_atual)/self.fps\n",
    "                end = video_atual_frame / self.fps\n",
    "                print('\\n******************************************',\\\n",
    "                    batch_step_atual,start,end)\n",
    "                \n",
    "\n",
    "                \n",
    "                ''' PREDICT batch without thread '''\n",
    "                \n",
    "                # MOVIEPY \n",
    "                audio_batch_mp = audio_mp.subclip(t_start=start,t_end=end)\n",
    "                audio_batch_array = audio_batch_mp.to_soundarray(fps = self.test_config[\"audio_fs_input\"])\n",
    "                audio_batch_array_mp = np.mean(audio_batch_array, axis=1).astype(np.float32)\n",
    "                #print(\"mono_single\",audio_batch_array_mp.dtype,np.shape(audio_batch_array_mp))\n",
    "                \n",
    "                print(\"\\nPREDICT\")\n",
    "                print(\"mp_batch\")\n",
    "                top_anom_mp = self.predicition(audio_batch_array_mp,5,printt=True)\n",
    "                atual_label_mp0 = str(top_anom_mp[1][0])\n",
    "                atual_label_mp1 = str(top_anom_mp[1][1])\n",
    "                atual_label_mp2 = str(top_anom_mp[1][2])\n",
    "                \n",
    "                \n",
    "                # ESSENTIA\n",
    "                audio_batch_es = audio_es.subclip(t_start=start,t_end=end)\n",
    "                audio_batch_array2 = audio_batch_es.to_soundarray()\n",
    "                audio_batch_array_mono_single2 = np.mean(audio_batch_array2, axis=1).astype(np.float32)\n",
    "                audio_bacth_array_essentia = self.resampler(audio_batch_array_mono_single2) \n",
    "                \n",
    "                print(\"essentia_batch\")\n",
    "                top_anom_es = self.predicition(audio_bacth_array_essentia,5,printt=True)\n",
    "                atual_label_es0 = str(top_anom_es[1][0])\n",
    "                atual_label_es1 = str(top_anom_es[1][1])\n",
    "                atual_label_es2 = str(top_anom_es[1][2])\n",
    "                \n",
    "                print(\"mp\",np.shape(audio_batch_array_mp),\"\\nessentia\",np.shape(audio_bacth_array_essentia))\n",
    "                \n",
    "                \n",
    "                #return audio_batch_array_mono_single, audio_bacth_array_essentia\n",
    "                #assert np.array_equal(audio_batch_array_mp, audio_bacth_array_essentia)\n",
    "                #nsamples = np.shape(audio_batch_array)[0] ; secs = end-start ; sample_rate = nsamples / secs\n",
    "                #print(sample_rate)\n",
    "                \n",
    "                \n",
    "                ''' save both bacthes'''\n",
    "                #print(\"\\nFROM WAVS\")\n",
    "                #fnmp = 'mp_mono_'+str(batch_step_atual)+'.wav'\n",
    "                #es.MonoWriter(filename=fnmp,sampleRate = self.test_config[\"audio_fs_input\"])(audio_batch_array_mp)\n",
    "                #fnes = 'essentia_mono_'+str(batch_step_atual)+'.wav'\n",
    "                #es.MonoWriter(filename=fnes,sampleRate = self.test_config[\"audio_fs_input\"])(audio_bacth_array_essentia)\n",
    "                \n",
    "                ''' predict on saved files '''\n",
    "                #print(\"mp_batch\")\n",
    "                #monoloader_batch_mp = es.MonoLoader(filename=fnmp, sampleRate=self.test_config[\"audio_fs_input\"])()\n",
    "                #top_anom_mp2 = self.predicition(monoloader_batch_mp,5,printt=True)\n",
    "                #print(\"essentia_batch\")\n",
    "                #monoloader_batch_es = es.MonoLoader(filename=fnes, sampleRate=self.test_config[\"audio_fs_input\"])()\n",
    "                #top_anom_es2 = self.predicition(monoloader_batch_es,5,printt=True)\n",
    "                \n",
    "                \n",
    "                batch_step_atual += 1\n",
    "            \n",
    "            # frames / secs   \n",
    "            cv2.putText(frame, '%d' % (video_atual_frame)+'/'+str(int(total_frames)), (5, int(height)-7),font,fontScale,[60,250,250],thickness,lineType)    \n",
    "            cv2.putText(frame, '%.2f' % (video_atual_frame/self.fps)+'s',(5,int(height)-25),font,fontScale, [80,100,250],thickness,lineType)\n",
    "            \n",
    "            # aas without thread\n",
    "            cv2.putText(frame,atual_label_mp0+'\\n'+atual_label_mp1+'\\n'+atual_label_mp2+'\\n'+str(batch_step_atual),(10,15),font,fontScale,[0,0,255],thickness,lineType)  \n",
    "            cv2.putText(frame,atual_label_es0+'\\n'+atual_label_es1+'\\n'+atual_label_es2+'\\n'+str(batch_step_atual),(10,30),font,fontScale,[0,0,255],thickness,lineType)  \n",
    "            \n",
    "            cv2.imshow(wn, frame)\n",
    "            \n",
    "            key = cv2.waitKey(frame_time_ms)  \n",
    "            if key == ord('q'): break  # quit\n",
    "            if key == ord(' '):  # pause\n",
    "                while True:\n",
    "                    key = cv2.waitKey(1)\n",
    "                    if key == ord(' '):break\n",
    "        \n",
    "        audio_mp.close()\n",
    "        audio_es.close()\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def init_watch_live2(watch_this):\n",
    "    print(\"\\n\\nINIT WATCH LIVE\")\n",
    "    \n",
    "    test_mp4_paths,*_ = util.load_xdv_test(util.SERVER_TEST_AUD_ORIG_PATH)\n",
    "    print('\\n  test_mp4_paths',np.shape(test_mp4_paths))\n",
    "\n",
    "    test_labels_indexs = util.get_index_per_label_from_filelist(test_mp4_paths)\n",
    "\n",
    "    fsdsinet = FSDSINET()\n",
    "\n",
    "    print('\\n  watching',watch_this)\n",
    "    for labels_2_watch in watch_this:\n",
    "        print('  ',labels_2_watch,' : ',test_labels_indexs[labels_2_watch])\n",
    "        \n",
    "        all_or_specific = input(\"\\n\\nall indxs : enter  |  specific indxs : ex 3,4,77,7  |  dry_run no as window : dr\\n\\n\")\n",
    "        \n",
    "        if all_or_specific == \"\": # all\n",
    "            for i in range(len(test_labels_indexs[labels_2_watch])):\n",
    "                index = test_labels_indexs[labels_2_watch][i]\n",
    "                path = test_mp4_paths[index]\n",
    "                print('\\n#-------------------#$%--------------------#\\n',labels_2_watch,index,path)\n",
    "                fsdsinet.fdspredict_from_video(index,path,10)\n",
    "        elif all_or_specific == \"dr\": \n",
    "            for i in range(len(test_labels_indexs[labels_2_watch])):\n",
    "                index = test_labels_indexs[labels_2_watch][i]\n",
    "                path = test_mp4_paths[index]\n",
    "                print('\\n#-------------------#$%--------------------#\\n',labels_2_watch,index,path) \n",
    "        \n",
    "        else: # specific\n",
    "            all_or_specific = all_or_specific.split(\",\")\n",
    "            all_or_specific = [int(num) for num in all_or_specific]\n",
    "            for index in all_or_specific:\n",
    "                path = test_mp4_paths[index]\n",
    "                print('\\n#-------------------#$%--------------------#\\n',labels_2_watch,index,path)\n",
    "                fsdsinet.fdspredict_from_video(index,path,10)\n",
    "\n",
    "'''\n",
    "    A  NORMAL  \n",
    "    B1 FIGHT | B2 SHOOTING | B4 RIOT | B5 ABUSE | B6 CAR ACCIDENT | G  EXPLOSION \n",
    "    BG ALL ANOMALIES\n",
    "'''\n",
    "init_watch_live2(watch_this=['B2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' predicts over entire audio array'''\n",
    "\n",
    "class FSDSINET2():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Loading the model\n",
    "        self.graph_filename = \"/raid/DATASETS/.zuble/vigia/zuwav/fsd-sinet-essentia/models/fsd-sinet-vgg41-tlpf-1.pb\"\n",
    "        self.model = es.TensorflowPredictFSDSINet(graphFilename=self.graph_filename)\n",
    "\n",
    "        # Read the metadata\n",
    "        self.metadata_file = \"/raid/DATASETS/.zuble/vigia/zuwav/fsd-sinet-essentia/models/fsd-sinet-vgg41-tlpf-1.json\"\n",
    "        self.metadata = json.load(open(self.metadata_file, \"r\"))\n",
    "        self.labels = self.metadata[\"classes\"]\n",
    "        self.anom_labels = [\"Alarm\",\"Boom\",\"Crowd\",\"Dog\",\"Drill\",\"Explosion\",\"Fire\",\"Gunshot and gunfire\",\"Hammer\",\"Screaming\",\"Screech\",\\\n",
    "                            \"Shatter\",\"Shout\",\"Siren\",\"Slam\",\"Squeak\",\"Yell\"]\n",
    "        self.anom_labels_i = [4,18,51,59,65,72,78,92,94,145,146,147,148,152,154,161,198]\n",
    "        \n",
    "        # get file list\n",
    "        self.mp4_fn, *_ = util.load_xdv_test(util.SERVER_TEST_AUD_MONO_PATH)\n",
    "\n",
    "    def plot_predictions(self, top_preds, top_labels_w_av,top_labels_with_av):\n",
    "        # Generate plots and improve formatting\n",
    "        matfig = plt.figure(figsize=(8, 3))\n",
    "        plt.matshow(top_preds, fignum=matfig.number, aspect=\"auto\")\n",
    "\n",
    "        plt.yticks(np.arange(len(top_labels_w_av)), top_labels_with_av)\n",
    "        locs, _ = plt.xticks()\n",
    "        ticks = np.array(locs // 2).astype(\"int\")\n",
    "        plt.xticks(locs[1: -1], ticks[1: -1])\n",
    "        plt.tick_params(bottom=True, top=False, labelbottom=True, labeltop=False)\n",
    "        plt.xlabel(\"(s)\")\n",
    "\n",
    "        if self.save_plot : plt.savefig(\"activations.png\", bbox_inches='tight')\n",
    "        \n",
    "    def process_rslt_all(self,predictions):\n",
    "        \n",
    "        def top_from_average(data, top_n):\n",
    "            av = np.mean(data, axis=0)\n",
    "            sorting = np.argsort(av)[::-1]\n",
    "            return sorting[:top_n], [av[i] for i in sorting] ,av\n",
    "\n",
    "        top_labels_i, averages_sorted , averages = top_from_average(predictions,self.nlabels2predict)\n",
    "        top_labels = [self.labels[i] for i in top_labels_i]\n",
    "        top_labels_with_av = [f\"{label} ({av:.3f})\" for label, av in zip(top_labels, averages_sorted)]\n",
    "        top_predictions = np.array([predictions[:,i] for i in top_labels_i])\n",
    "        if self.plott : self.plot_predictions(top_predictions, top_labels_with_av,top_labels_with_av)\n",
    "\n",
    "        return top_labels, top_labels_with_av\n",
    "    \n",
    "    def process_rslt_anom(self,predictions):\n",
    "        \n",
    "        def top_from_anomaly(data):\n",
    "            av = np.mean(data, axis=0)\n",
    "            sorting = np.argsort(av)[::-1]\n",
    "            sorting_anom = [x for x in sorting if x in self.anom_labels_i]\n",
    "            return sorting_anom,[av[i] for i in sorting_anom]\n",
    "\n",
    "        top_labels_anom_i, averages_anom_sorted = top_from_anomaly(predictions)\n",
    "        top_labels_anom = [self.labels[i] for i in top_labels_anom_i]\n",
    "        top_labels_anom_with_av = [f\"{label} ({av:.3f})\" for label, av in zip(top_labels_anom, averages_anom_sorted)]\n",
    "        top_predictions_anom = np.array([predictions[:,i] for i in top_labels_anom_i])\n",
    "        if self.plott : self.plot_predictions(top_predictions_anom, top_labels_anom_with_av,top_labels_anom_with_av)\n",
    "        \n",
    "        return top_labels_anom, top_labels_anom_with_av\n",
    "\n",
    "    def predicition_complete(self,index,nlabels2predict,printt=True,plott=False,save_plot=False):\n",
    "        \n",
    "        self.plott = plott; self.save_plot = save_plot\n",
    "        self.nlabels2predict = nlabels2predict\n",
    "        \n",
    "        path = self.mp4_fn[index]\n",
    "        print(\"PATH\",path)\n",
    "        \n",
    "        # Extract the audio from the video\n",
    "        audio = mp.AudioFileClip(filename=path)#.fx(mp.afx.audio_normalize)\n",
    "        audio_total_array = audio.to_soundarray(fps=22050)\n",
    "        audio_total_array_mono = np.mean(audio_total_array, axis=1)\n",
    "        audio_total_array_mono_single = audio_total_array_mono.astype(np.float32)\n",
    "        audio2predict = audio_total_array_mono_single\n",
    "        \n",
    "        predictions = self.model(audio2predict)\n",
    "        print(\"predictions_shape\",np.shape(predictions))\n",
    "\n",
    "        top_labels, top_labels_with_av = self.process_rslt_all(predictions)   \n",
    "        top_labels_anom, top_labels_anom_with_av = self.process_rslt_anom(predictions)     \n",
    "\n",
    "\n",
    "        if printt:\n",
    "            print(\"\\nall\", top_labels_with_av)\n",
    "            print(\"\\nanom\", top_labels_anom_with_av)\n",
    "            #for label, probability in zip(self.metadata['classes'], predictions.mean(axis=0)):\n",
    "            #    print(f'{label}: {100 * probability:.1f}%') \n",
    "\n",
    "def init_watch_live2(watch_this):\n",
    "    print(\"\\n\\nINIT WATCH LIVE\")\n",
    "    \n",
    "    test_mp4_paths,*_ = util.load_xdv_test(util.SERVER_TEST_AUD_ORIG_PATH)\n",
    "    print('\\n  test_mp4_paths',np.shape(test_mp4_paths))\n",
    "\n",
    "    test_labels_indexs = util.get_index_per_label_from_filelist(test_mp4_paths)\n",
    "\n",
    "    fsdsinet = FSDSINET2()\n",
    "    \n",
    "    print('\\n  watching',watch_this)\n",
    "    for labels_2_watch in watch_this:\n",
    "        print('  ',labels_2_watch,' : ',test_labels_indexs[labels_2_watch])\n",
    "        \n",
    "        all_or_specific = input(\"\\n\\nall indxs : enter  |  specific indxs : ex 3,4,77,7  |  dry_run no as window : dr\\n\\n\")\n",
    "        \n",
    "        if all_or_specific == \"\": # all\n",
    "            for i in range(len(test_labels_indexs[labels_2_watch])):\n",
    "                index = test_labels_indexs[labels_2_watch][i]\n",
    "                path = test_mp4_paths[index]\n",
    "                print('\\n#-------------------#$%--------------------#\\n',labels_2_watch,index,path)\n",
    "                fsdsinet.predicition_complete(index,15,plott=True)\n",
    "        elif all_or_specific == \"dr\": \n",
    "            for i in range(len(test_labels_indexs[labels_2_watch])):\n",
    "                index = test_labels_indexs[labels_2_watch][i]\n",
    "                path = test_mp4_paths[index]\n",
    "                print('\\n#-------------------#$%--------------------#\\n',labels_2_watch,index,path) \n",
    "        else: # specific\n",
    "            all_or_specific = all_or_specific.split(\",\")\n",
    "            all_or_specific = [int(num) for num in all_or_specific]\n",
    "            for index in all_or_specific:\n",
    "                path = test_mp4_paths[index]\n",
    "                print('\\n#-------------------#$%--------------------#\\n',labels_2_watch,index,path)\n",
    "                fsdsinet.predicition_complete(index,15,plott=True)\n",
    "\n",
    "\n",
    "'''\n",
    "    A  NORMAL  \n",
    "    B1 FIGHT | B2 SHOOTING | B4 RIOT | B5 ABUSE | B6 CAR ACCIDENT | G  EXPLOSION \n",
    "    BG ALL ANOMALIES\n",
    "'''\n",
    "\n",
    "init_watch_live2(watch_this=['G'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zugpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f7bf267530dde59ab6764f0eb5f1b22dea8a9c4ca62db1182ae079b8b4c02bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
