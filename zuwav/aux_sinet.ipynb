{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model files\n",
    "\n",
    "[audio-event-recognition/fsd-sinet/](https://essentia.upf.edu/models/audio-event-recognition/fsd-sinet/)    \n",
    "\n",
    "!wget -q https://essentia.upf.edu/models/audio-event-recognition/fsd-sinet/fsd-sinet-vgg41-tlpf-1.pb\n",
    "\n",
    "!wget -q https://essentia.upf.edu/models/audio-event-recognition/fsd-sinet/fsd-sinet-vgg41-tlpf-1.json\n",
    "\n",
    "<https://mtg.github.io/essentia-labs/news/tensorflow/2023/02/08/fsdsinet-models/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import essentia\n",
    "print(essentia.__version__)\n",
    "print(essentia.__file__)\n",
    "import essentia.standard as es\n",
    "\n",
    "# let's have a look at what is in there\n",
    "#print(dir(essentia.standard))\n",
    "\n",
    "\n",
    "import  cv2 , os , time , json\n",
    "import matplotlib.pyplot as plt\n",
    "#from queue import Queue\n",
    "import numpy as np\n",
    "\n",
    "import utils.util as util\n",
    "import moviepy.editor as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' HELPERS '''\n",
    "#print(dir(essentia.standard))\n",
    "#print(help(es.AudioLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' FAST PREDICT '''\n",
    "def fast_predict():\n",
    "    model_config = {\n",
    "        \n",
    "        'graph_filename' : \"/raid/DATASETS/.zuble/vigia/zuwav/fsd-sinet-essentia/models/fsd-sinet-vgg41-tlpf-1.pb\",\n",
    "        'metadata_file' : \"/raid/DATASETS/.zuble/vigia/zuwav/fsd-sinet-essentia/models/fsd-sinet-vgg41-tlpf-1.json\",\n",
    "        \n",
    "        'batchSize' : 64,\n",
    "        'lastPatchMode': 'repeat',\n",
    "        'patchHopSize' : 50\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "    ''' MODEL & METADATA '''\n",
    "    model = es.TensorflowPredictFSDSINet(\n",
    "                graphFilename = model_config['graph_filename'],\n",
    "                batchSize = model_config[\"batchSize\"],\n",
    "                lastPatchMode = model_config[\"lastPatchMode\"],\n",
    "                patchHopSize = model_config[\"patchHopSize\"]\n",
    "                                        )\n",
    "    metadata = json.load(open(model_config['metadata_file'], \"r\"))\n",
    "\n",
    "\n",
    "    mp4path = '/raid/DATASETS/anomaly/XD_Violence/testing_copy/v=SMy2_qNO2Y0__#00-01-50_00-03-13_label_G-0-0.mp4'\n",
    "    print()\n",
    "    \n",
    "    ## FS converter \n",
    "    mp4_fs_aac = util.print_acodec_from_mp4([mp4path],only_sr=True) # get audio stream fs from mp4 \n",
    "    print(\"mp4_fs_aac\",mp4_fs_aac)\n",
    "    resampler = es.Resample(inputSampleRate=mp4_fs_aac, outputSampleRate=22050)\n",
    "\n",
    "\n",
    "    audio_es = mp.AudioFileClip(filename=mp4path,fps=mp4_fs_aac)\n",
    "    aud_arr2 = audio_es.to_soundarray()\n",
    "    aud_arr_mono_single2 = np.mean(aud_arr2, axis=1).astype(np.float32)\n",
    "    aud_arr_essentia = resampler(aud_arr_mono_single2) \n",
    "\n",
    "    ## predict\n",
    "    p_es = model(aud_arr_essentia)#;print(\"predictions_shape\",np.shape(p_es))\n",
    "    print(np.shape(p_es)) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zugpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f7bf267530dde59ab6764f0eb5f1b22dea8a9c4ca62db1182ae079b8b4c02bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
