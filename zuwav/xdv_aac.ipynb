{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess , IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import essentia.standard as es\n",
    "#import essentia.streaming\n",
    "\n",
    "import pylab  #plot, show, figure, imshow\n",
    "import cv2\n",
    "import moviepy.editor as mp\n",
    "\n",
    "import utils.util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' HELPERS '''\n",
    "#print(dir(essentia.standard))\n",
    "print(help(es.AudioLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mp4_paths,mp4_labels,aac_paths,aac_labels = util.load_xdv_test(aac_path=util.SERVER_TEST_AUD_ORIG_PATH)\n",
    "#out1 = util.print_acodec_from_mp4(mp4_paths)\n",
    "#util.conv_mp4_to_aac(mp4_paths,util.SERVER_TEST_AUD_MONO_PATH,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_paths,*_ = util.load_xdv_test(aac_path=util.SERVER_TEST_AUD_MONO_PATH)\n",
    "out2 = util.print_acodec_from_mp4(mp4_paths,printt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_paths,mp4_labels,aac_paths,aac_labels = util.load_xdv_test(aac_path=util.SERVER_TEST_AUD_MONO_PATH)\n",
    "aacpath = aac_paths[44]\n",
    "mp4path = mp4_paths[44]\n",
    "\n",
    "#IPython.display.Audio(aacpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio = es.MonoLoader(filename=aacpath)()\n",
    "#from pylab import plot, show, figure, imshow\n",
    "#pylab.plot(audio[1*44100:2*44100])\n",
    "#plt.title(\"This is how the 2nd second of this audio looks like:\")\n",
    "#pylab.show()\n",
    "\n",
    "#util.plot_mfcc_melbands(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import moviepy.editor as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = util.print_acodec_from_mp4([mp4path],printt=True)\n",
    "\n",
    "video = mp.VideoFileClip(mp4path,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.audio.fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "audio = mp.AudioFileClip(mp4path,fps=48000)\n",
    "audio_array = np.array(audio.to_soundarray())\n",
    "\n",
    "audioaux = audio.subclip(0,2)\n",
    "audioaux_array = np.array(audioaux.to_soundarray())\n",
    "\n",
    "print(audio_array.shape , audioaux_array.shape)\n",
    "\n",
    "audio.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' writes 10 sec of audio from mp4 cv read synced'''\n",
    "def get_audio_from_mp4(path,start_t=0.0,end_t=10.0):\n",
    "\n",
    "    video = cv2.VideoCapture(path)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Extract the audio from the video\n",
    "    audio = mp.AudioFileClip(path)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        ret, frame = video.read()\n",
    "        if not ret:break\n",
    "        video_atual_frame = int(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        \n",
    "        start=video.get(cv2.CAP_PROP_POS_MSEC)/1000\n",
    "        end=(video.get(cv2.CAP_PROP_POS_MSEC)+1000/fps)/1000\n",
    "        print(\"1 frame sec start end\",start,end)\n",
    "        \n",
    "        if video_atual_frame == 240:\n",
    "\n",
    "            start=start_t\n",
    "            end=end_t\n",
    "            print(start,end)\n",
    "            \n",
    "            audio_frame = audio.subclip(t_start=start,t_end=end)\n",
    "            audio_array = np.array(audio_frame.to_soundarray())\n",
    "            \n",
    "            nsamples = np.shape(audio_array)[0]\n",
    "            secs = end-start\n",
    "            sample_rate = nsamples / secs\n",
    "            print(audio_array.dtype,np.shape(audio_array) , sample_rate)\n",
    "            \n",
    "            # 1 transform stereo to mono\n",
    "            audio_array_mono = np.mean(audio_array, axis=1)\n",
    "            es.MonoWriter(filename='audio_mono.wav',sampleRate = int(sample_rate))(audio_array_mono)\n",
    "            \n",
    "            # 2 save as stereo\n",
    "            es.AudioWriter(filename='audio_stereo.wav',sampleRate = int(sample_rate))(audio_array)\n",
    "            \n",
    "            break\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "#get_audio_from_mp4(mp4path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zugpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f7bf267530dde59ab6764f0eb5f1b22dea8a9c4ca62db1182ae079b8b4c02bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
