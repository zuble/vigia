{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model files\n",
    "\n",
    "[audio-event-recognition/fsd-sinet/](https://essentia.upf.edu/models/audio-event-recognition/fsd-sinet/)    \n",
    "\n",
    "!wget -q https://essentia.upf.edu/models/audio-event-recognition/fsd-sinet/fsd-sinet-vgg41-tlpf-1.pb\n",
    "\n",
    "!wget -q https://essentia.upf.edu/models/audio-event-recognition/fsd-sinet/fsd-sinet-vgg41-tlpf-1.json\n",
    "\n",
    "<https://mtg.github.io/essentia-labs/news/tensorflow/2023/02/08/fsdsinet-models/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1-beta6-dev\n",
      "/home/jtstudents/anaconda3/envs/zugpupip/lib/python3.8/site-packages/essentia/__init__.py\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m#from queue import Queue\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mutil\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmoviepy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meditor\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmp\u001b[39;00m\n",
      "File \u001b[0;32m/raid/DATASETS/.zuble/vigia/zuwav00/utils/util.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39msubprocess\u001b[39;00m \u001b[39m,\u001b[39m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39messentia\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstandard\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39m#---------------------------------------------#\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# audio\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import essentia\n",
    "print(essentia.__version__)\n",
    "print(essentia.__file__)\n",
    "import essentia.standard as es\n",
    "\n",
    "# let's have a look at what is in there\n",
    "#print(dir(essentia.standard))\n",
    "\n",
    "\n",
    "import json\n",
    "#from queue import Queue\n",
    "import numpy as np\n",
    "\n",
    "import utils.util as util\n",
    "import moviepy.editor as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' HELPERS '''\n",
    "print(dir(essentia.standard))\n",
    "#print(help(es.AudioLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' FAST PREDICT '''\n",
    "def fast_predict():\n",
    "    model_config = {\n",
    "        \n",
    "        'graph_filename' : \"/raid/DATASETS/.zuble/vigia/zuwav/fsd-sinet-essentia/models/fsd-sinet-vgg41-tlpf-1.pb\",\n",
    "        'metadata_file' : \"/raid/DATASETS/.zuble/vigia/zuwav/fsd-sinet-essentia/models/fsd-sinet-vgg41-tlpf-1.json\",\n",
    "        \n",
    "        'batchSize' : 64,\n",
    "        'lastPatchMode': 'repeat',\n",
    "        'patchHopSize' : 50\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "    ''' MODEL & METADATA '''\n",
    "    model = es.TensorflowPredictFSDSINet(\n",
    "                graphFilename = model_config['graph_filename'],\n",
    "                batchSize = model_config[\"batchSize\"],\n",
    "                lastPatchMode = model_config[\"lastPatchMode\"],\n",
    "                patchHopSize = model_config[\"patchHopSize\"]\n",
    "                                        )\n",
    "    metadata = json.load(open(model_config['metadata_file'], \"r\"))\n",
    "\n",
    "\n",
    "    mp4path = '/raid/DATASETS/anomaly/XD_Violence/testing_copy/v=SMy2_qNO2Y0__#00-01-50_00-03-13_label_G-0-0.mp4'\n",
    "    print()\n",
    "    \n",
    "    ## FS converter \n",
    "    mp4_fs_aac = util.print_acodec_from_mp4([mp4path],only_sr=True) # get audio stream fs from mp4 \n",
    "    print(\"mp4_fs_aac\",mp4_fs_aac)\n",
    "    resampler = es.Resample(inputSampleRate=mp4_fs_aac, outputSampleRate=22050)\n",
    "\n",
    "\n",
    "    audio_es = mp.AudioFileClip(filename=mp4path,fps=mp4_fs_aac)\n",
    "    aud_arr2 = audio_es.to_soundarray()\n",
    "    aud_arr_mono_single2 = np.mean(aud_arr2, axis=1).astype(np.float32)\n",
    "    aud_arr_essentia = resampler(aud_arr_mono_single2) \n",
    "\n",
    "    ## predict\n",
    "    p_es = model(aud_arr_essentia)#;print(\"predictions_shape\",np.shape(p_es))\n",
    "    print(np.shape(p_es)) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zugpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f7bf267530dde59ab6764f0eb5f1b22dea8a9c4ca62db1182ae079b8b4c02bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
