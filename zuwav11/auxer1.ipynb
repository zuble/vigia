{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random, logging , datetime , cv2 , csv , subprocess , json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"tf\",tf.version.VERSION)\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.cm import get_cmap\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "import plotly.subplots as sp\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from utils import globo , xdv , tfh5 , sinet\n",
    "\n",
    "\n",
    "''' GPU CONFIGURATION '''\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\"\n",
    "#tfh5.set_tf_loglevel(logging.ERROR)\n",
    "#tfh5.tf.debugging.set_log_device_placement(False) #Enabling device placement logging causes any Tensor allocations or operations to be printed.\n",
    "#tfh5.set_memory_growth()\n",
    "#os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "\n",
    "CFG_SINET = {\n",
    "    \n",
    "    'sinet_version': 'fsd-sinet-vgg42-tlpf_aps-1',\n",
    "    \n",
    "    'graph_filename' : os.path.join(globo.FSDSINET_PATH,\"fsd-sinet-vgg42-tlpf_aps-1.pb\"),\n",
    "    'metadata_file'  : os.path.join(globo.FSDSINET_PATH,\"fsd-sinet-vgg42-tlpf_aps-1.json\"),\n",
    "    \n",
    "    'audio_fs_input':22050,\n",
    "    'batchSize' : 64,\n",
    "    'lastPatchMode': 'repeat',\n",
    "    'patchHopSize' : 50,\n",
    "    \n",
    "    \n",
    "    'anom_labels' : [\"Alarm\",\"Boom\",\"Crowd\",\"Dog\",\"Drill\",\"Explosion\",\"Fire\",\"Gunshot and gunfire\",\"Hammer\",\"Screaming\",\"Screech\",\\\n",
    "                    \"Shatter\",\"Shout\",\"Siren\",\"Slam\",\"Squeak\",\"Yell\"],\n",
    "    'anom_labels_i' : [4,18,51,59,65,72,78,92,94,145,146,147,148,152,154,161,198],\n",
    "    \n",
    "    'anom_labels2' : [\"Boom\",\"Explosion\",\"Fire\",\"Gunshot and gunfire\",\"Screaming\",\\\n",
    "                    \"Shout\",\"Siren\",\"Yell\"],\n",
    "    'anom_labels_i2' : [18,72,78,92,147,148,152,198],\n",
    "    \n",
    "    'full_or_max' : 'max', #chose output to (timesteps,labels_total) ot (1,labels_total)\n",
    "    'labels_total' : 200\n",
    "    \n",
    "}\n",
    "CFG_WAV= {\n",
    "    \n",
    "    \"full_or_max\" : CFG_SINET[\"full_or_max\"],\n",
    "    \"sinet_aas_len\" : CFG_SINET[\"labels_total\"], \n",
    "    \n",
    "    \"shuffle\" : False,\n",
    "    \n",
    "    \"ativa\" : 'relu',\n",
    "    \"optima\" : 'sgd',\n",
    "    \"batch_type\" : 0,   # =0 all batch have frame_max or video length // =1 last batch has frame_max frames // =2 last batch has no repetead frames\n",
    "    \"frame_max\" : 8000,\n",
    "    \"ckpt_start\" : f\"{0:0>8}\",  #used in train_model: if 00000000 start from scratch, else start from ckpt with CFG_WAV stated\n",
    "    \n",
    "    \"epochs\" : 1,\n",
    "    \"batch_size\" : 1\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join(globo.AAS_PATH,f\"{CFG_SINET['sinet_version']}--fl_train.npz\"), allow_pickle=True)[\"data\"]\n",
    "\n",
    "p_es_arr_total = ([data[k]['p_es_array'] for k in range(len(data))])\n",
    "labels_total = [data[k]['label'] for k in range(len(data))]\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "p_es_arr_total = np.array(p_es_arr_total)\n",
    "labels_total = np.array(labels_total)\n",
    "\n",
    "# Check the shapes of the resulting NumPy arrays\n",
    "print(\"Shape of p_es_arr_total_np:\", np.shape(p_es_arr_total[1])[1])\n",
    "print(\"Shape of labels_total_np:\", labels_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def pad_arrays(arrays, pad_value=0):\n",
    "    max_shape = np.max([arr.shape for arr in arrays], axis=0)\n",
    "    padded_arrays = []\n",
    "\n",
    "    for arr in arrays:\n",
    "        pad_width = [(0, max_dim - dim) for dim, max_dim in zip(arr.shape, max_shape)]\n",
    "        padded_array = np.pad(arr, pad_width, mode='constant', constant_values=pad_value)\n",
    "        padded_arrays.append(padded_array)\n",
    "\n",
    "    return np.stack(padded_arrays)\n",
    "'''\n",
    "\n",
    "#p_es_arr_total = pad_arrays(p_es_arr_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_them_stats(total_array,total_labels):\n",
    "    nintervals = np.shape(total_array)[0] #, _, nclasses\n",
    "    nclasses = total_array[1].shape[1]\n",
    "    \n",
    "    maxx, avgg, meantopkmax = [None] * nintervals, [None] * nintervals, [None] * nintervals \n",
    "    k = 10\n",
    "    for i in range(nintervals):\n",
    "        #print(i,np.shape(total_array[i]))\n",
    "        # 1. Max probability\n",
    "        maxx[i] = np.max(total_array[i], axis=0)\n",
    "\n",
    "        # 3. top-interval max\n",
    "        # Sort the values along the time_steps axis (axis=0) for each class in descending order\n",
    "        sorted_values_per_class = np.sort(total_array[i], axis=0)[::-1]\n",
    "        # Select the top-k values for each class\n",
    "        top_k_values_per_class = sorted_values_per_class[:k, :]\n",
    "        # Calculate the mean of the top-k values for each class\n",
    "        meantopkmax[i] = np.mean(top_k_values_per_class, axis=0)\n",
    "        \n",
    "                \n",
    "        # 2. Average probability\n",
    "        avgg[i] = np.mean(total_array[i], axis=0)\n",
    "\n",
    "\n",
    "    # 9. Autocorrelation\n",
    "    #def autocorr(x):\n",
    "    #    result = np.correlate(x, x, mode='full')\n",
    "    #    return result[result.size // 2:]\n",
    "    #\n",
    "    #autocorrelations = np.array([[autocorr(total_array[j])] for j in range(nclasses)]).reshape(nintervals, total_array.shape[1])\n",
    "    \n",
    "    stats_dicts = {\n",
    "        \"maxx\": maxx,\n",
    "        \"avgg\": avgg,\n",
    "        \"meantopkmax\":meantopkmax\n",
    "        #\"std_dev\": std_devs\n",
    "    }\n",
    "    \n",
    "    print(np.shape(maxx),\\\n",
    "        np.shape(avgg),\\\n",
    "        np.shape(meantopkmax))\n",
    "    \n",
    "    return stats_dicts\n",
    "\n",
    "stats_dic = get_them_stats(p_es_arr_total,labels_total) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_colors(num_colors, cmap_name='viridis'):\n",
    "    cmap = plt.get_cmap(cmap_name)\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, num_colors)]\n",
    "    colors = ['#%02x%02x%02x' % (int(r * 255), int(g * 255), int(b * 255)) for r, g, b, _ in colors]\n",
    "    return colors\n",
    "\n",
    "\n",
    "def plot_class_stats(stats, labels_total, anom_labels, anom_labels_i):\n",
    "\n",
    "    for interval in range(len(stats[\"maxx\"])):\n",
    "        if labels_total[interval]:\n",
    "            # Create table data\n",
    "            header_values = ['Class', 'Max', 'Avg' , 'Mean TopKMax']\n",
    "            row_values = []\n",
    "\n",
    "            for i, cls in enumerate(anom_labels_i):\n",
    "                max_prob_single_value = stats[\"maxx\"][interval][cls]\n",
    "                avg_prob_single_value = stats[\"avgg\"][interval][cls]\n",
    "                meantopkmax_single_value = stats[\"meantopkmax\"][interval][cls]\n",
    "                row_values.append([anom_labels[i], max_prob_single_value, avg_prob_single_value , meantopkmax_single_value])\n",
    "\n",
    "            # Create table trace\n",
    "            table_trace = go.Table(\n",
    "                header=dict(values=header_values, line_color='darkslategray',\n",
    "                            fill_color='lightskyblue', font=dict(color='white', size=14)),\n",
    "                cells=dict(values=np.transpose(row_values), line_color='darkslategray',\n",
    "                        fill_color='lightcyan', font=dict(color='black', size=12))\n",
    "            )\n",
    "\n",
    "            # Create figure and add table trace\n",
    "            fig = go.Figure(data=[table_trace])\n",
    "            fig.update_layout(title_text=f'Stats @ Interval {interval} with label {labels_total[interval]} {np.shape(p_es_arr_total[interval])}')\n",
    "            fig.show()\n",
    "        \n",
    "        elif interval == 100: break\n",
    "\n",
    "plot_class_stats(stats_dic, labels_total, CFG_SINET[\"anom_labels\"], CFG_SINET[\"anom_labels_i\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(stats_dic[\"maxx\"])):\n",
    "    print(i, np.shape(stats_dic[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zugpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
