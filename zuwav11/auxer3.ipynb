{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random, logging , datetime , cv2 , csv , subprocess , json , math , glob , sys\n",
    "import numpy as np\n",
    "\n",
    "from utils import globo , xdv , tfh5 , sinet , yammet\n",
    "\n",
    "def enhance_probabilities2(probs, threshold , power=2):\n",
    "    #return np.where(probs < threshold, (probs ** power), 1 - (1 - probs) ** power) ## < th closer 0 | > th closer 1\n",
    "    return np.where(probs < threshold, probs, 1 - (1 - probs) ** power) ## > th closer 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wavtry with chuncked xdv_test_bg_train_a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = xdv.load_train_valdt_test_from_xdvtest_bg_train_a('train' , globo.CFG_WAV_TRAIN[\"sinet_fi_iter\"])\n",
    "data_vpath2 = [ data2[idx]['vpath'] for idx in range(len(data2))]\n",
    "data_pesarr2 =  [ data2[idx]['p_es_array'] for idx in range(len(data2))]\n",
    "data_sf2 =  [ data2[idx]['sf'] for idx in range(len(data2))]\n",
    "data_ef2 =  [ data2[idx]['ef'] for idx in range(len(data2))]\n",
    "data_label2 = [ data2[idx]['label'] for idx in range(len(data2))]\n",
    "\n",
    "classes_list2 = xdv.get_index_per_label_from_filelist(data_vpath2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'guns'\n",
    "class_letter = 'B2'\n",
    "\n",
    "#label = 'explosion'\n",
    "#class_letter = 'G'   \n",
    "print(\"XDV CLASS\",label,class_letter)\n",
    "\n",
    "\n",
    "def watch_this_interval2(idx, aas):\n",
    "    vpath = data_vpath2[idx]\n",
    "    sf = data_sf2[idx]\n",
    "    ef = data_ef2[idx]\n",
    "    label = data_label2[idx]\n",
    "    print(\"\\tWATCH THIS\",os.path.basename(vpath),sf,ef,label)\n",
    "    \n",
    "    ## watch stuff\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontScale = 0.5;thickness = 1;lineType = cv2.LINE_AA\n",
    "    green = (0, 255, 0);red = (0, 0, 255)\n",
    "    cap = cv2.VideoCapture(vpath)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:break\n",
    "\n",
    "        frame_count += 1\n",
    "        if sf <= frame_count <= ef:\n",
    "            cv2.putText(frame, str(label), (10, 30), font, fontScale, green, thickness, lineType)\n",
    "            cv2.putText(frame, str(aas), (10, 60), font, fontScale, red, thickness, lineType)\n",
    "            #cv2.imshow('Video', frame)\n",
    "            #if cv2.waitKey(25) & 0xFF == ord('q'):break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANOMALY | 1\n",
    "\n",
    "sin_tp , sin_fn = 0 , 0\n",
    "yam_tp , yam_fn = 0 , 0\n",
    "glob_tp , glob_fn = 0 , 0\n",
    "for i,idx in enumerate(classes_list2[class_letter]):\n",
    "    \n",
    "    vpath = data_vpath2[idx]\n",
    "    sf = data_sf2[idx]\n",
    "    ef = data_ef2[idx]\n",
    "    \n",
    "    p_es_arr = data_pesarr2[idx]\n",
    "    p_es_arr_max = np.max(p_es_arr,axis=0)\n",
    "    \n",
    "    p_es_arr_enh = enhance_probabilities2(p_es_arr , 0.4)\n",
    "    p_es_arr_enh_max = np.max(p_es_arr_enh,axis=0) \n",
    "    \n",
    "    p_yam_arr = yammet.get_sigmoid(vpath,sf,ef)\n",
    "    p_yam_arr_max = np.max(p_yam_arr,axis=0)\n",
    "    #sorted_idx = np.argsort(p_yam_arr_max)[::-1]\n",
    "    #for k in range(50):print('- {}: {:.4f}'.format(np.array(globo.CFG_YAMMET['labels'])[sorted_idx[k]], predictions[sorted_idx[k]]))\n",
    "    \n",
    "    \n",
    "    print(\"\\n\",os.path.basename(vpath))\n",
    "    print(\"YAMMET\")\n",
    "    p_yam_arr_anom = []\n",
    "    yam_tp_flag , yam_fn_flag = False , False\n",
    "    for kkk,anom_yam_k in enumerate(globo.CFG_YAMMET[\"anom_labels_i\"]):\n",
    "        if p_yam_arr_max[anom_yam_k] >= 0.4:\n",
    "            print('-TP- {}: {:.4f}'.format(np.array(globo.CFG_YAMMET['labels'])[anom_yam_k], p_yam_arr_max[anom_yam_k]))\n",
    "            yam_tp_flag = True\n",
    "            yam_fn_flag = False\n",
    "            break\n",
    "        else:\n",
    "            print('-FN- {}: {:.4f}'.format(np.array(globo.CFG_YAMMET['labels'])[anom_yam_k], p_yam_arr_max[anom_yam_k]))\n",
    "            yam_fn_flag = True\n",
    "            \n",
    "        p_yam_arr_anom.append(p_yam_arr_max[anom_yam_k])\n",
    "    \n",
    "    if yam_tp_flag: yam_tp += 1\n",
    "    if yam_fn_flag: yam_fn += 1\n",
    "    \n",
    "    print(\"SINET\")\n",
    "    p_sin_arr_anom = []\n",
    "    sin_tp_flag , sin_fn_flag = False , False\n",
    "    for kkk,anom_sin_k in enumerate(globo.CFG_SINET[\"anom_labels_i2\"]):\n",
    "        if p_es_arr_enh_max[anom_sin_k] >= 0.5:\n",
    "            print('-TP- {}: {:.4f}  ,  {:.4f}'.format(np.array(globo.CFG_SINET['labels'])[anom_sin_k], p_es_arr_max[anom_sin_k] , p_es_arr_enh_max[anom_sin_k]))\n",
    "            sin_tp_flag = True\n",
    "            sin_fn_flag = False\n",
    "            break\n",
    "        else :\n",
    "            print('-FN- {}: {:.4f}  ,  {:.4f}'.format(np.array(globo.CFG_SINET['labels'])[anom_sin_k], p_es_arr_max[anom_sin_k] , p_es_arr_enh_max[anom_sin_k]))\n",
    "            sin_fn_flag = True\n",
    "            \n",
    "        p_sin_arr_anom.append(p_es_arr_enh_max[anom_sin_k])\n",
    "    \n",
    "    if sin_tp_flag: sin_tp += 1\n",
    "    if sin_fn_flag: sin_fn += 1\n",
    "    \n",
    "    ## global\n",
    "    if yam_tp_flag or sin_tp_flag: glob_tp += 1\n",
    "    if yam_fn_flag and sin_fn_flag: glob_fn +=1\n",
    "    \n",
    "print(\"SINNET\\n\",\"tp\",sin_tp,\"fn\",sin_fn)\n",
    "print(\"YAMMET\\n\",\"tp\",yam_tp,\"fn\",yam_fn)\n",
    "print(\"GLOBAL\\n\",\"tp\",glob_tp,\"fn\",glob_fn)\n",
    "print(len(classes_list2[class_letter]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NORMAL\n",
    "\n",
    "tn0 , fp0 = 0 , 0\n",
    "tn1 , fp1 = 0 , 0\n",
    "\n",
    "for i,idx in enumerate(classes_list2['A']):\n",
    "    #print(\"\\n\",os.path.basename(data_vpath2[idx]))\n",
    "    \n",
    "    p_es_arr = data_pesarr2[idx]\n",
    "    #p_es_arr_enh = enhance_probabilities2(p_es_arr , 0.5)\n",
    "    \n",
    "    max = np.max(p_es_arr,axis=0)[iii]\n",
    "    #max_enh = np.max(p_es_arr_enh,axis=0)[iii]\n",
    "    \n",
    "    #print(os.path.basename(data_vpath2[idx]))\n",
    "    \n",
    "    if max >= 0.5: \n",
    "        fp0 += 1\n",
    "        print(\"FP\")\n",
    "        #for j in range(len(p_es_arr[:,iii])):\n",
    "        #    print(round(p_es_arr[j,iii],3))\n",
    "        watch_this_interval2(idx,round(max,3))\n",
    "    else: tn0 += 1\n",
    "       \n",
    "    #if max_enh >= 0.5: fp1 += 1\n",
    "    #else: tn1 += 1\n",
    " \n",
    "print(\"ORIGINAL\\n\",\"tn\",tn0,\"fp\",fp0)\n",
    "#print(\"ENHANCED\\n\",\"tn\",tn1,\"fp\",fp1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST BG WITHOUT CHUNCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'train'\n",
    "\n",
    "data1 = np.load(os.path.join(globo.AAS_PATH+\"/1_full_interval\",f\"{globo.CFG_SINET['sinet_version']}--fl1_{mode}.npz\"), allow_pickle=True)[\"data\"]\n",
    "data_vpath1 = [ data1[idx]['vpath'] for idx in range(len(data1))]\n",
    "data_pesarr1 =  [ data1[idx]['p_es_array'] for idx in range(len(data1))]\n",
    "data_sf1 =  [ data1[idx]['frame_interval'][0] for idx in range(len(data1))]\n",
    "data_ef1 =  [ data1[idx]['frame_interval'][1] for idx in range(len(data1))]\n",
    "data_label1 = [ data1[idx]['frame_interval'][2] for idx in range(len(data1))]\n",
    "\n",
    "classes_list1 = xdv.get_index_per_label_from_filelist(data_vpath1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def watch_this_interval1(idx, aas):\n",
    "    vpath = data_vpath1[idx]\n",
    "    sf = data_sf1[idx]\n",
    "    ef = data_ef1[idx]\n",
    "    label = data_label1[idx]\n",
    "    print(\"\\tWATCH THIS\",os.path.basename(vpath),sf,ef,label)\n",
    "    \n",
    "    ## watch stuff\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontScale = 0.5;thickness = 1;lineType = cv2.LINE_AA\n",
    "    green = (0, 255, 0);red = (0, 0, 255)\n",
    "    cap = cv2.VideoCapture(vpath)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:break\n",
    "\n",
    "        frame_count += 1\n",
    "        if sf <= frame_count <= ef:\n",
    "            cv2.putText(frame, str(label), (10, 30), font, fontScale, green, thickness, lineType)\n",
    "            cv2.putText(frame, str(aas), (10, 60), font, fontScale, red, thickness, lineType)\n",
    "            #cv2.imshow('Video', frame)\n",
    "            #if cv2.waitKey(1) & 0xFF == ord('q'):break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANOMALY | 1\n",
    "\n",
    "tp0 , fn0 = 0 , 0\n",
    "tp1 , fn1 = 0 , 0\n",
    "\n",
    "for i,idx in enumerate(classes_list1[class_letter]):\n",
    "    if data_label1[idx] == 1:\n",
    "        #print(\"\\n\",os.path.basename(data_vpath2[idx]))    \n",
    "        vpath = data_vpath1[idx]\n",
    "        \n",
    "        p_es_arr = data_pesarr1[idx]\n",
    "        p_es_arr_enh = enhance_probabilities(p_es_arr , 0.4)\n",
    "        \n",
    "        ## AVERAGE OF THE TOPK PROBS \n",
    "        p_es_arr_iii = p_es_arr[:,iii]\n",
    "        p_es_arr_iii_sorted = np.argsort(p_es_arr_iii)[::-1]\n",
    "        topk = int(len(p_es_arr_iii)/2)\n",
    "        p_es_arr_iii_sorted_topk=p_es_arr_iii_sorted[:topk]\n",
    "        avg_topk = np.mean(p_es_arr[p_es_arr_iii_sorted_topk, iii])\n",
    "\n",
    "        ## AVERAGE\n",
    "        avg = np.average(p_es_arr,axis=0)[iii]\n",
    "        \n",
    "        ## MAX\n",
    "        max = np.max(p_es_arr,axis=0)[iii]\n",
    "        max_enh = np.max(p_es_arr_enh,axis=0)[iii]\n",
    "        \n",
    "        #print(label,round(max,3),\"|\",round(max_enh,3))\n",
    "        \n",
    "        if max >= 0.5: tp0 += 1\n",
    "        else: fn0 += 1\n",
    "        \n",
    "        if max_enh >= 0.5: \n",
    "            tp1 += 1\n",
    "            #print(\"TP\",label,round(max,3),\"|\",round(max_enh,3))\n",
    "        else: \n",
    "            print(\"FN\",label,\\\n",
    "                  \"\\n\\tMAX\",round(max,3),\"|\",round(max_enh,3) ,\\\n",
    "                    \"\\n\\tAVG\",round(avg,3) , round(avg_topk,3))\n",
    "            #watch_this_interval1(idx,max_enh)\n",
    "            \n",
    "            fn1 += 1\n",
    " \n",
    "print(\"ORIGINAL\\n\",\"tp\",tp0,\"fn\",fn0)\n",
    "print(\"ENHANCED\\n\",\"tp\",tp1,\"fn\",fn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NORMAL\n",
    "\n",
    "tn0 , fp0 = 0 , 0\n",
    "tn1 , fp1 = 0 , 0\n",
    "\n",
    "for i,idx in enumerate(classes_list1['A']):\n",
    "    \n",
    "        print(\"\\n\",os.path.basename(data_vpath2[idx]))\n",
    "        \n",
    "        p_es_arr = data_pesarr1[idx]\n",
    "        p_es_arr_enh = enhance_probabilities(p_es_arr , 0.5)\n",
    "        \n",
    "        maxx = np.max(p_es_arr,axis=0)[iii]\n",
    "        max_enh = np.max(p_es_arr_enh,axis=0)[iii]\n",
    "        \n",
    "        #print(label,round(max,3),\"|\",round(max_enh,3))\n",
    "        \n",
    "        if maxx >= 0.5: fp0 += 1\n",
    "        else: tn0 += 1\n",
    "        \n",
    "        if max_enh >= 0.5: \n",
    "            fp1 += 1\n",
    "            print(\"FP\",label,round(maxx,3),\"|\",round(max_enh,3))\n",
    "        else: tn1 += 1\n",
    " \n",
    "print(\"ORIGINAL\\n\",\"tn\",tn0,\"fp\",fp0)\n",
    "print(\"ENHANCED\\n\",\"tn\",tn1,\"fp\",fp1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XDV TRAIN DATASET ORIGINAL , AUDIO RUN TRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
